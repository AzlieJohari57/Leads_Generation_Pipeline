{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "982b7eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import time\n",
    "import scrapy\n",
    "from scrapy_playwright.page import PageMethod\n",
    "from bs4 import BeautifulSoup\n",
    "import nest_asyncio\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "380182f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fresh_Leads_formatted = pd.read_csv(\"Golden_Data/Fresh_Leads_with_PhoneNumber_Nov11.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d5ad28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing duplicates:\n",
      "  Total rows: 105\n",
      "  Rows with Website URL: 64\n",
      "  Unique URLs: 64\n",
      "  Duplicate URLs: 0\n",
      "\n",
      "After removing duplicates:\n",
      "  Rows with Website URL: 64\n",
      "  Unique URLs: 64\n",
      "  Duplicates removed: 0\n",
      "  Rows with duplicate URLs set to NaN: 0\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate Website URLs - keep first occurrence, set duplicates to NaN\n",
    "if 'Website URL' in Fresh_Leads_formatted.columns:\n",
    "    # Count duplicates before removal\n",
    "    total_rows = len(Fresh_Leads_formatted)\n",
    "    valid_urls = Fresh_Leads_formatted['Website URL'].notna()\n",
    "    unique_urls_before = Fresh_Leads_formatted[valid_urls]['Website URL'].nunique()\n",
    "    duplicate_count = Fresh_Leads_formatted[valid_urls]['Website URL'].duplicated().sum()\n",
    "    \n",
    "    print(f\"Before removing duplicates:\")\n",
    "    print(f\"  Total rows: {total_rows}\")\n",
    "    print(f\"  Rows with Website URL: {valid_urls.sum()}\")\n",
    "    print(f\"  Unique URLs: {unique_urls_before}\")\n",
    "    print(f\"  Duplicate URLs: {duplicate_count}\")\n",
    "    \n",
    "    # Mark duplicates (keep first occurrence, mark subsequent as duplicates)\n",
    "    # Convert to string and normalize (lowercase, strip whitespace) for comparison\n",
    "    Fresh_Leads_formatted['Website URL_cleaned'] = Fresh_Leads_formatted['Website URL'].astype(str).str.strip().str.lower()\n",
    "    \n",
    "    # Find duplicates (keep first occurrence)\n",
    "    is_duplicate = Fresh_Leads_formatted['Website URL_cleaned'].duplicated(keep='first')\n",
    "    \n",
    "    # Set duplicate URLs to NaN (excluding rows where URL was already NaN)\n",
    "    mask_to_remove = is_duplicate & (Fresh_Leads_formatted['Website URL'].notna())\n",
    "    Fresh_Leads_formatted.loc[mask_to_remove, 'Website URL'] = pd.NA\n",
    "    \n",
    "    # Drop the temporary cleaning column\n",
    "    Fresh_Leads_formatted = Fresh_Leads_formatted.drop(columns=['Website URL_cleaned'])\n",
    "    \n",
    "    # Count after removal\n",
    "    valid_urls_after = Fresh_Leads_formatted['Website URL'].notna()\n",
    "    unique_urls_after = Fresh_Leads_formatted[valid_urls_after]['Website URL'].nunique()\n",
    "    \n",
    "    print(f\"\\nAfter removing duplicates:\")\n",
    "    print(f\"  Rows with Website URL: {valid_urls_after.sum()}\")\n",
    "    print(f\"  Unique URLs: {unique_urls_after}\")\n",
    "    print(f\"  Duplicates removed: {duplicate_count}\")\n",
    "    print(f\"  Rows with duplicate URLs set to NaN: {mask_to_remove.sum()}\")\n",
    "else:\n",
    "    print(\"Warning: 'Website URL' column not found in dataframe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27b04023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing: Facebook Page\n",
      "============================================================\n",
      "Before removing duplicates:\n",
      "  Rows with Facebook Page: 32\n",
      "  Unique values: 32\n",
      "  Duplicate values: 0\n",
      "\n",
      "After removing duplicates:\n",
      "  Rows with Facebook Page: 32\n",
      "  Unique values: 32\n",
      "  Duplicates removed: 0\n",
      "  ✅ Successfully removed 0 duplicate values\n",
      "\n",
      "============================================================\n",
      "Processing: Instagram URL\n",
      "============================================================\n",
      "Before removing duplicates:\n",
      "  Rows with Instagram URL: 22\n",
      "  Unique values: 22\n",
      "  Duplicate values: 0\n",
      "\n",
      "After removing duplicates:\n",
      "  Rows with Instagram URL: 22\n",
      "  Unique values: 22\n",
      "  Duplicates removed: 0\n",
      "  ✅ Successfully removed 0 duplicate values\n",
      "\n",
      "============================================================\n",
      "Processing: PIC 1 email address\n",
      "============================================================\n",
      "Before removing duplicates:\n",
      "  Rows with PIC 1 email address: 42\n",
      "  Unique values: 42\n",
      "  Duplicate values: 0\n",
      "\n",
      "After removing duplicates:\n",
      "  Rows with PIC 1 email address: 42\n",
      "  Unique values: 42\n",
      "  Duplicates removed: 0\n",
      "  ✅ Successfully removed 0 duplicate values\n",
      "\n",
      "============================================================\n",
      "Duplicate removal complete for Facebook Page, Instagram URL, and PIC 1 email address!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate Facebook Page, Instagram URL, and PIC 1 email address - keep first occurrence, set duplicates to NaN\n",
    "columns_to_clean = ['Facebook Page', 'Instagram URL', 'PIC 1 email address']\n",
    "\n",
    "for col_name in columns_to_clean:\n",
    "    if col_name in Fresh_Leads_formatted.columns:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Processing: {col_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Count duplicates before removal\n",
    "        valid_values = Fresh_Leads_formatted[col_name].notna()\n",
    "        unique_before = Fresh_Leads_formatted[valid_values][col_name].nunique()\n",
    "        duplicate_count = Fresh_Leads_formatted[valid_values][col_name].duplicated().sum()\n",
    "        \n",
    "        print(f\"Before removing duplicates:\")\n",
    "        print(f\"  Rows with {col_name}: {valid_values.sum()}\")\n",
    "        print(f\"  Unique values: {unique_before}\")\n",
    "        print(f\"  Duplicate values: {duplicate_count}\")\n",
    "        \n",
    "        # Normalize values for comparison (lowercase, strip whitespace)\n",
    "        temp_col = f'{col_name}_cleaned'\n",
    "        Fresh_Leads_formatted[temp_col] = Fresh_Leads_formatted[col_name].astype(str).str.strip().str.lower()\n",
    "        \n",
    "        # Find duplicates (keep first occurrence)\n",
    "        is_duplicate = Fresh_Leads_formatted[temp_col].duplicated(keep='first')\n",
    "        \n",
    "        # Set duplicate values to NaN (excluding rows where value was already NaN)\n",
    "        mask_to_remove = is_duplicate & (Fresh_Leads_formatted[col_name].notna())\n",
    "        Fresh_Leads_formatted.loc[mask_to_remove, col_name] = pd.NA\n",
    "        \n",
    "        # Drop the temporary cleaning column\n",
    "        Fresh_Leads_formatted = Fresh_Leads_formatted.drop(columns=[temp_col])\n",
    "        \n",
    "        # Count after removal\n",
    "        valid_after = Fresh_Leads_formatted[col_name].notna()\n",
    "        unique_after = Fresh_Leads_formatted[valid_after][col_name].nunique()\n",
    "        \n",
    "        print(f\"\\nAfter removing duplicates:\")\n",
    "        print(f\"  Rows with {col_name}: {valid_after.sum()}\")\n",
    "        print(f\"  Unique values: {unique_after}\")\n",
    "        print(f\"  Duplicates removed: {mask_to_remove.sum()}\")\n",
    "        print(f\"  ✅ Successfully removed {mask_to_remove.sum()} duplicate values\")\n",
    "    else:\n",
    "        print(f\"⚠️  Warning: '{col_name}' column not found in dataframe\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Duplicate removal complete for Facebook Page, Instagram URL, and PIC 1 email address!\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "164c7a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ePOS Code',\n",
       " 'Company Code',\n",
       " 'Date',\n",
       " 'ACRA REGISTERED NAME',\n",
       " 'Brand/Deal Name/Business Name',\n",
       " 'Sub Domain Link (If Lead is already available in Backend) Fill only when EPOS client',\n",
       " 'Tele Sales or MR (For KPI - Internal)',\n",
       " 'Name of the Market Researcher',\n",
       " 'Original Source (Marketing)',\n",
       " 'Marketing Source (Do not fill anything if the leads are from Hubspot, EPOS clients)',\n",
       " 'Company Registration date / Date Established',\n",
       " 'Company Registration Number (UEN)',\n",
       " 'Primary SSIC Code',\n",
       " 'Secondary SSIC Code',\n",
       " 'Hubspot ID (Company)',\n",
       " 'Hubspot ID(Deal)',\n",
       " 'Hubspot ID(Contact)',\n",
       " 'Website URL',\n",
       " 'Business Type',\n",
       " 'Facebook Page',\n",
       " 'Instagram URL',\n",
       " 'Linkedin URL',\n",
       " 'Tik Tok URL',\n",
       " 'Ownership Type',\n",
       " 'Parent Industry Type',\n",
       " 'Industry Type',\n",
       " 'Sub Industry',\n",
       " 'Business model',\n",
       " 'Presence of Multiple Outlets',\n",
       " 'Number of Outlets (Write in #)',\n",
       " 'Region',\n",
       " 'Planning Area',\n",
       " 'Business Location Type',\n",
       " 'Registered Address (Block & Street)',\n",
       " 'Registered Address  (Unit #)',\n",
       " 'Registered Address  (Postal code)',\n",
       " 'Operational Address \\n(Block & Street)',\n",
       " 'Operational Address \\n(Unit #)',\n",
       " 'Operational Address \\n(Postal Code)',\n",
       " 'Operational Address Type',\n",
       " 'First Name',\n",
       " 'Last Name',\n",
       " 'PIC Name 1 Designation',\n",
       " 'PIC NAME 1 Contact Number',\n",
       " 'PIC 1 email address',\n",
       " 'First Name 2',\n",
       " 'Last Name 2',\n",
       " 'PIC Name 2 Designation',\n",
       " 'PIC NAME 2 Contact Number',\n",
       " 'PIC 2 email address',\n",
       " 'First Name 3',\n",
       " 'Last Name 3',\n",
       " 'PIC Name Designation 3',\n",
       " 'PIC NAME 3 Contact Number',\n",
       " 'PIC 3 email address',\n",
       " 'FB/Insta/Tik Tok/Linkedin Contact',\n",
       " 'Current ePOS Client ?',\n",
       " 'If ePOS Client, which product they are using?',\n",
       " 'Is this deal part of the Gov List?',\n",
       " 'Source from Market Researcher',\n",
       " 'Contact Number from Lusha?',\n",
       " 'Phone number Verified ?']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fresh_Leads_formatted.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fe35ada2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGGRESSIVELY cleaning: 'Operational Address \n",
      "(Unit #)'\n",
      "\n",
      "Removing 0 date values...\n",
      "\n",
      "✅ Done! Removed 0 dates.\n",
      "Remaining non-null values: 96\n",
      "\n",
      "Sample of remaining values:\n",
      "   Operational Address \\n(Unit #)\n",
      "0                               4\n",
      "1                               8\n",
      "2                             590\n",
      "3                               1\n",
      "4                               3\n",
      "5                              76\n",
      "6                             02A\n",
      "7                             309\n",
      "8                               7\n",
      "9                               4\n",
      "10                            103\n",
      "11                            607\n",
      "12                             31\n",
      "13                              1\n",
      "14                              0\n"
     ]
    }
   ],
   "source": [
    "# AGGRESSIVE DATE REMOVAL for Operational Address (Unit #) - Remove ALL dates!\n",
    "# Find the column\n",
    "op_col = None\n",
    "for col in Fresh_Leads_formatted.columns:\n",
    "    if 'operational' in col.lower() and 'unit' in col.lower() and 'address' in col.lower():\n",
    "        op_col = col\n",
    "        break\n",
    "\n",
    "if op_col:\n",
    "    print(f\"AGGRESSIVELY cleaning: '{op_col}'\\n\")\n",
    "    s = Fresh_Leads_formatted[op_col].astype(str)\n",
    "    to_remove = []\n",
    "    month_names = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'sept', 'oct', 'nov', 'dec']\n",
    "    \n",
    "    for idx, val in s.items():\n",
    "        if pd.isna(val) or str(val).strip().lower() in ['nan', 'none', '', 'nat']:\n",
    "            continue\n",
    "        val_str = str(val).strip()\n",
    "        val_lower = val_str.lower()\n",
    "        \n",
    "        # KEEP only if it has a letter (02A, 12W, 330G) - these are unit numbers\n",
    "        if re.search(r'[A-Za-z]', val_str):\n",
    "            continue  # Has letter = unit number, KEEP IT\n",
    "        \n",
    "        # No letters - check if it's a date and REMOVE\n",
    "        is_date = False\n",
    "        \n",
    "        # Check for month names\n",
    "        for month in month_names:\n",
    "            if month in val_lower:\n",
    "                is_date = True\n",
    "                break\n",
    "        \n",
    "        # Check date patterns\n",
    "        if re.search(r'\\d{4}[-/]\\d{1,2}[-/]\\d{1,2}', val_str):\n",
    "            is_date = True\n",
    "        elif re.search(r'\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}', val_str):\n",
    "            is_date = True\n",
    "        elif re.match(r'^\\d{1,2}[-/]\\d{1,2}$', val_str):\n",
    "            # Could be MM/DD - check if ranges suggest date\n",
    "            parts = re.split(r'[-/]', val_str)\n",
    "            if len(parts) == 2:\n",
    "                try:\n",
    "                    p1, p2 = int(parts[0]), int(parts[1])\n",
    "                    if (1 <= p1 <= 31) and (1 <= p2 <= 12):\n",
    "                        is_date = True\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # Try pandas date parsing\n",
    "        if not is_date:\n",
    "            try:\n",
    "                pd.to_datetime(val_str, errors='raise')\n",
    "                is_date = True\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if is_date:\n",
    "            to_remove.append(idx)\n",
    "    \n",
    "    # Remove all dates\n",
    "    print(f\"Removing {len(to_remove)} date values...\")\n",
    "    if to_remove:\n",
    "        print(\"Examples of dates being removed:\")\n",
    "        for idx in to_remove[:15]:\n",
    "            print(f\"  Row {idx}: {s.loc[idx]}\")\n",
    "        if len(to_remove) > 15:\n",
    "            print(f\"  ... and {len(to_remove) - 15} more\")\n",
    "    \n",
    "    Fresh_Leads_formatted.loc[to_remove, op_col] = pd.NA\n",
    "    \n",
    "    print(f\"\\n✅ Done! Removed {len(to_remove)} dates.\")\n",
    "    print(f\"Remaining non-null values: {Fresh_Leads_formatted[op_col].notna().sum()}\")\n",
    "    print(\"\\nSample of remaining values:\")\n",
    "    print(Fresh_Leads_formatted[Fresh_Leads_formatted[op_col].notna()][[op_col]].head(15))\n",
    "else:\n",
    "    print(\"Column not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9879dae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ePOS Code</th>\n",
       "      <th>Company Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>ACRA REGISTERED NAME</th>\n",
       "      <th>Brand/Deal Name/Business Name</th>\n",
       "      <th>Sub Domain Link (If Lead is already available in Backend) Fill only when EPOS client</th>\n",
       "      <th>Tele Sales or MR (For KPI - Internal)</th>\n",
       "      <th>Name of the Market Researcher</th>\n",
       "      <th>Original Source (Marketing)</th>\n",
       "      <th>Marketing Source (Do not fill anything if the leads are from Hubspot, EPOS clients)</th>\n",
       "      <th>...</th>\n",
       "      <th>PIC Name Designation 3</th>\n",
       "      <th>PIC NAME 3 Contact Number</th>\n",
       "      <th>PIC 3 email address</th>\n",
       "      <th>FB/Insta/Tik Tok/Linkedin Contact</th>\n",
       "      <th>Current ePOS Client ?</th>\n",
       "      <th>If ePOS Client, which product they are using?</th>\n",
       "      <th>Is this deal part of the Gov List?</th>\n",
       "      <th>Source from Market Researcher</th>\n",
       "      <th>Contact Number from Lusha?</th>\n",
       "      <th>Phone number Verified ?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/11/2025</td>\n",
       "      <td>BELL 1 SINGAPORE PTE. LTD.</td>\n",
       "      <td>BELL 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Kalaivani</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA Google Searches</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/11/2025</td>\n",
       "      <td>THESEUS PROMOTER PTE. LTD.</td>\n",
       "      <td>THESEUS PROMOTER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Kalaivani</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA Google Searches</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/11/2025</td>\n",
       "      <td>MYFIT ENTERPRISE PTE. LTD.</td>\n",
       "      <td>MYFIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Kalaivani</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA Google Searches</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/11/2025</td>\n",
       "      <td>THE SINGAPORE FOOD AND WINE</td>\n",
       "      <td>THE FOOD AND WINE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Kalaivani</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA Google Searches</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/11/2025</td>\n",
       "      <td>SEA GUARDIAN MARINE (SINGAPORE) PTE. LTD.</td>\n",
       "      <td>SEA GUARDIAN MARINE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Kalaivani</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA Google Searches</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/11/2025</td>\n",
       "      <td>ULTRA GREAT PTE. LTD.</td>\n",
       "      <td>ULTRA GREAT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Kalaivani</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA Google Searches</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/11/2025</td>\n",
       "      <td>SWEE HUAT TAN KEE TRADING</td>\n",
       "      <td>SWEE HUAT TAN KEE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Kalaivani</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA Google Searches</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/11/2025</td>\n",
       "      <td>CC AVIATION SOLUTIONS PTE. LTD.</td>\n",
       "      <td>CC AVIATION SOLUTIONS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Kalaivani</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA Google Searches</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/11/2025</td>\n",
       "      <td>A&amp;K MARINE SUPPLIES PTE. LTD.</td>\n",
       "      <td>A&amp;K MARINE SUPPLIES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Kalaivani</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA Google Searches</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/11/2025</td>\n",
       "      <td>LAKESIDE FISHERY TRADING</td>\n",
       "      <td>LAKESIDE FISHERY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Kalaivani</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA Google Searches</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ePOS Code  Company Code        Date  \\\n",
       "0          NaN           NaN  10/11/2025   \n",
       "1          NaN           NaN  10/11/2025   \n",
       "2          NaN           NaN  10/11/2025   \n",
       "3          NaN           NaN  10/11/2025   \n",
       "4          NaN           NaN  10/11/2025   \n",
       "..         ...           ...         ...   \n",
       "100        NaN           NaN  10/11/2025   \n",
       "101        NaN           NaN  10/11/2025   \n",
       "102        NaN           NaN  10/11/2025   \n",
       "103        NaN           NaN  10/11/2025   \n",
       "104        NaN           NaN  10/11/2025   \n",
       "\n",
       "                          ACRA REGISTERED NAME Brand/Deal Name/Business Name  \\\n",
       "0                   BELL 1 SINGAPORE PTE. LTD.                        BELL 1   \n",
       "1                   THESEUS PROMOTER PTE. LTD.              THESEUS PROMOTER   \n",
       "2                   MYFIT ENTERPRISE PTE. LTD.                         MYFIT   \n",
       "3                  THE SINGAPORE FOOD AND WINE             THE FOOD AND WINE   \n",
       "4    SEA GUARDIAN MARINE (SINGAPORE) PTE. LTD.           SEA GUARDIAN MARINE   \n",
       "..                                         ...                           ...   \n",
       "100                      ULTRA GREAT PTE. LTD.                   ULTRA GREAT   \n",
       "101                  SWEE HUAT TAN KEE TRADING             SWEE HUAT TAN KEE   \n",
       "102            CC AVIATION SOLUTIONS PTE. LTD.         CC AVIATION SOLUTIONS   \n",
       "103              A&K MARINE SUPPLIES PTE. LTD.           A&K MARINE SUPPLIES   \n",
       "104                   LAKESIDE FISHERY TRADING              LAKESIDE FISHERY   \n",
       "\n",
       "     Sub Domain Link (If Lead is already available in Backend) Fill only when EPOS client  \\\n",
       "0                                                  NaN                                      \n",
       "1                                                  NaN                                      \n",
       "2                                                  NaN                                      \n",
       "3                                                  NaN                                      \n",
       "4                                                  NaN                                      \n",
       "..                                                 ...                                      \n",
       "100                                                NaN                                      \n",
       "101                                                NaN                                      \n",
       "102                                                NaN                                      \n",
       "103                                                NaN                                      \n",
       "104                                                NaN                                      \n",
       "\n",
       "    Tele Sales or MR (For KPI - Internal) Name of the Market Researcher  \\\n",
       "0                               TeleSales                     Kalaivani   \n",
       "1                               TeleSales                     Kalaivani   \n",
       "2                               TeleSales                     Kalaivani   \n",
       "3                               TeleSales                     Kalaivani   \n",
       "4                               TeleSales                     Kalaivani   \n",
       "..                                    ...                           ...   \n",
       "100                             TeleSales                     Kalaivani   \n",
       "101                             TeleSales                     Kalaivani   \n",
       "102                             TeleSales                     Kalaivani   \n",
       "103                             TeleSales                     Kalaivani   \n",
       "104                             TeleSales                     Kalaivani   \n",
       "\n",
       "    Original Source (Marketing)  \\\n",
       "0               Offline Sources   \n",
       "1               Offline Sources   \n",
       "2               Offline Sources   \n",
       "3               Offline Sources   \n",
       "4               Offline Sources   \n",
       "..                          ...   \n",
       "100             Offline Sources   \n",
       "101             Offline Sources   \n",
       "102             Offline Sources   \n",
       "103             Offline Sources   \n",
       "104             Offline Sources   \n",
       "\n",
       "    Marketing Source (Do not fill anything if the leads are from Hubspot, EPOS clients)  \\\n",
       "0                                        Web Scrapping                                    \n",
       "1                                        Web Scrapping                                    \n",
       "2                                        Web Scrapping                                    \n",
       "3                                        Web Scrapping                                    \n",
       "4                                        Web Scrapping                                    \n",
       "..                                                 ...                                    \n",
       "100                                      Web Scrapping                                    \n",
       "101                                      Web Scrapping                                    \n",
       "102                                      Web Scrapping                                    \n",
       "103                                      Web Scrapping                                    \n",
       "104                                      Web Scrapping                                    \n",
       "\n",
       "     ... PIC Name Designation 3 PIC NAME 3 Contact Number  \\\n",
       "0    ...                    NaN                       NaN   \n",
       "1    ...                    NaN                       NaN   \n",
       "2    ...                    NaN                       NaN   \n",
       "3    ...                    NaN                       NaN   \n",
       "4    ...                    NaN                       NaN   \n",
       "..   ...                    ...                       ...   \n",
       "100  ...                    NaN                       NaN   \n",
       "101  ...                    NaN                       NaN   \n",
       "102  ...                    NaN                       NaN   \n",
       "103  ...                    NaN                       NaN   \n",
       "104  ...                    NaN                       NaN   \n",
       "\n",
       "     PIC 3 email address  FB/Insta/Tik Tok/Linkedin Contact  \\\n",
       "0                    NaN                                NaN   \n",
       "1                    NaN                                NaN   \n",
       "2                    NaN                                NaN   \n",
       "3                    NaN                                NaN   \n",
       "4                    NaN                                NaN   \n",
       "..                   ...                                ...   \n",
       "100                  NaN                                NaN   \n",
       "101                  NaN                                NaN   \n",
       "102                  NaN                                NaN   \n",
       "103                  NaN                                NaN   \n",
       "104                  NaN                                NaN   \n",
       "\n",
       "     Current ePOS Client ?  If ePOS Client, which product they are using?  \\\n",
       "0                       No                                            NaN   \n",
       "1                       No                                            NaN   \n",
       "2                       No                                            NaN   \n",
       "3                       No                                            NaN   \n",
       "4                       No                                            NaN   \n",
       "..                     ...                                            ...   \n",
       "100                     No                                            NaN   \n",
       "101                     No                                            NaN   \n",
       "102                     No                                            NaN   \n",
       "103                     No                                            NaN   \n",
       "104                     No                                            NaN   \n",
       "\n",
       "     Is this deal part of the Gov List? Source from Market Researcher  \\\n",
       "0                              Gov List          ACRA Google Searches   \n",
       "1                              Gov List          ACRA Google Searches   \n",
       "2                              Gov List          ACRA Google Searches   \n",
       "3                              Gov List          ACRA Google Searches   \n",
       "4                              Gov List          ACRA Google Searches   \n",
       "..                                  ...                           ...   \n",
       "100                            Gov List          ACRA Google Searches   \n",
       "101                            Gov List          ACRA Google Searches   \n",
       "102                            Gov List          ACRA Google Searches   \n",
       "103                            Gov List          ACRA Google Searches   \n",
       "104                            Gov List          ACRA Google Searches   \n",
       "\n",
       "    Contact Number from Lusha? Phone number Verified ?  \n",
       "0                           No                     NaN  \n",
       "1                           No                     NaN  \n",
       "2                           No                     NaN  \n",
       "3                           No                     NaN  \n",
       "4                           No                     NaN  \n",
       "..                         ...                     ...  \n",
       "100                         No                     NaN  \n",
       "101                         No                     NaN  \n",
       "102                         No                     NaN  \n",
       "103                         No                     NaN  \n",
       "104                         No                     NaN  \n",
       "\n",
       "[105 rows x 62 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fresh_Leads_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a87299b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56b585af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fresh_Leads_formatted.to_csv(\"Golden_Data/Fresh_Leads_with_PhoneNumber_Nov11.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
