{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c095eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import glob\n",
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "968b615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 592 rows from ./Staging/Silver/New_Leads_17_Nov_2.parquet\n",
      "(592, 15)\n"
     ]
    }
   ],
   "source": [
    "parquet_path = \"./Staging/Silver/New_Leads_17_Nov_2.parquet\"\n",
    "if os.path.exists(parquet_path):\n",
    "    RecordOwl_Leads = pd.read_parquet(parquet_path, engine=\"fastparquet\")\n",
    "    print(f\"Loaded {len(RecordOwl_Leads)} rows from {parquet_path}\")\n",
    "    print(RecordOwl_Leads.shape)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Parquet file not found at {parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d95a0550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 15)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RecordOwl_Leads.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fdb576fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>Status</th>\n",
       "      <th>Error</th>\n",
       "      <th>Emails</th>\n",
       "      <th>Phones</th>\n",
       "      <th>Website</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Instagram</th>\n",
       "      <th>TikTok</th>\n",
       "      <th>RecordOwl_Link</th>\n",
       "      <th>operational_street</th>\n",
       "      <th>operational_unit</th>\n",
       "      <th>operational_postal_code</th>\n",
       "      <th>operational_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201727805K</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>+6567521170</td>\n",
       "      <td>https://www.mycareersfuture.gov.sg/job/educati...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/k-joy-educare-pt...</td>\n",
       "      <td>87 MARINE PARADE CENTRAL MARINE PARADE PROMENADE</td>\n",
       "      <td>03-213</td>\n",
       "      <td>440087</td>\n",
       "      <td>87 MARINE PARADE CENTRAL MARINE PARADE PROMENA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53363337X</td>\n",
       "      <td>success</td>\n",
       "      <td>None</td>\n",
       "      <td>[enquiry@edlab.sg]</td>\n",
       "      <td>+6581981320</td>\n",
       "      <td>https://edlab.sg/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/edlab.sg]</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/tungstan-edlab</td>\n",
       "      <td>23 FERNVALE LANE THE TOPIARY</td>\n",
       "      <td>02-29</td>\n",
       "      <td>797501</td>\n",
       "      <td>23 FERNVALE LANE THE TOPIARY 02-29 Singapore 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          UEN   Status Error              Emails       Phones  \\\n",
       "0  201727805K  success  None                None  +6567521170   \n",
       "1   53363337X  success  None  [enquiry@edlab.sg]  +6581981320   \n",
       "\n",
       "                                             Website Facebook LinkedIn  \\\n",
       "0  https://www.mycareersfuture.gov.sg/job/educati...     None     None   \n",
       "1                                  https://edlab.sg/     None     None   \n",
       "\n",
       "                              Instagram TikTok  \\\n",
       "0                                  None   None   \n",
       "1  [https://www.instagram.com/edlab.sg]   None   \n",
       "\n",
       "                                      RecordOwl_Link  \\\n",
       "0  https://recordowl.com/company/k-joy-educare-pt...   \n",
       "1       https://recordowl.com/company/tungstan-edlab   \n",
       "\n",
       "                                 operational_street operational_unit  \\\n",
       "0  87 MARINE PARADE CENTRAL MARINE PARADE PROMENADE           03-213   \n",
       "1                      23 FERNVALE LANE THE TOPIARY            02-29   \n",
       "\n",
       "  operational_postal_code                                operational_address  \n",
       "0                  440087  87 MARINE PARADE CENTRAL MARINE PARADE PROMENA...  \n",
       "1                  797501  23 FERNVALE LANE THE TOPIARY 02-29 Singapore 7...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RecordOwl_Leads.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a126b4a3",
   "metadata": {},
   "source": [
    "### Restructure to MasterDB Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e06776fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Fresh_Leads_format = pd.DataFrame(columns=[\n",
    "    \"ePOS Code\",\n",
    "    \"Company Code\",\n",
    "    \"Date\",\n",
    "    \"ACRA REGISTERED NAME\",\n",
    "    \"Brand/Deal Name/Business Name\",\n",
    "    \"Sub Domain Link (If Lead is already available in Backend) Fill only when EPOS client\",\n",
    "    \"Tele Sales or MR (For KPI - Internal)\",\n",
    "    \"Name of the Market Researcher\",\n",
    "    \"Original Source (Marketing)\",\n",
    "    \"Marketing Source (Do not fill anything if the leads are from Hubspot, EPOS clients)\",\n",
    "    \"Company Registration date / Date Established\",\n",
    "    \"Company Registration Number (UEN)\",\n",
    "    \"Primary SSIC Code\",\n",
    "    \"Secondary SSIC Code\",\n",
    "    \"Hubspot ID (Company)\",\n",
    "    \"Hubspot ID(Deal)\",\n",
    "    \"Hubspot ID(Contact)\",\n",
    "    \"Website URL\",\n",
    "    \"Business Type\",\n",
    "    \"Facebook Page\",\n",
    "    \"Instagram URL\",\n",
    "    \"Linkedin URL\",\n",
    "    \"Tik Tok URL\",\n",
    "    \"Ownership Type\",\n",
    "    \"Parent Industry Type\",\n",
    "    \"Industry Type\",\n",
    "    \"Sub Industry\",\n",
    "    \"Business model\",\n",
    "    \"Presence of Multiple Outlets\",\n",
    "    \"Number of Outlets (Write in #)\",\n",
    "    \"Region\",\n",
    "    \"Planning Area\",\n",
    "    \"Business Location Type\",\n",
    "    \"Registered Address (Block & Street)\",\n",
    "    \"Registered Address  (Unit #)\",\n",
    "    \"Registered Address  (Postal code)\",\n",
    "    \"Operational Address \\n(Block & Street)\",\n",
    "    \"Operational Address \\n(Unit #)\",\n",
    "    \"Operational Address \\n(Postal Code)\",\n",
    "    \"Operational Address Type\",\n",
    "    \"First Name\",\n",
    "    \"Last Name\",\n",
    "    \"PIC Name 1 Designation\",\n",
    "    \"PIC NAME 1 Contact Number\",\n",
    "    \"PIC 1 email address\",\n",
    "    \"First Name 2\",\n",
    "    \"Last Name 2\",\n",
    "    \"PIC Name 2 Designation\",\n",
    "    \"PIC NAME 2 Contact Number\",\n",
    "    \"PIC 2 email address\",\n",
    "    \"First Name 3\",\n",
    "    \"Last Name 3\",\n",
    "    \"PIC Name Designation 3\",\n",
    "    \"PIC NAME 3 Contact Number\",\n",
    "    \"PIC 3 email address\",\n",
    "    \"FB/Insta/Tik Tok/Linkedin Contact\",\n",
    "    \"Current ePOS Client ?\",\n",
    "    \"If ePOS Client, which product they are using?\",\n",
    "    \"Is this deal part of the Gov List?\",\n",
    "    \"Source from Market Researcher\",\n",
    "    \"Contact Number from Lusha?\",\n",
    "    \"Phone number Verified ?\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d449f2f2",
   "metadata": {},
   "source": [
    "### Mapping scrapped leads to Master DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "331b32ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Mapped: UEN ‚Üí Company Registration Number (UEN)\n",
      "‚úì Mapped: Phones ‚Üí PIC NAME 1 Contact Number\n",
      "‚úì Mapped: Emails ‚Üí PIC 1 email address\n",
      "‚úì Mapped: Website ‚Üí Website URL\n",
      "‚úì Mapped: Facebook ‚Üí Facebook Page\n",
      "‚úì Mapped: Instagram ‚Üí Instagram URL\n",
      "‚úì Mapped: TikTok ‚Üí Tik Tok URL\n",
      "‚úì Mapped: LinkedIn ‚Üí Linkedin URL\n",
      "‚úì Mapped: operational_address ‚Üí Operational Address \n",
      "(Block & Street)\n",
      "‚úì Mapped: operational_unit ‚Üí Operational Address \n",
      "(Unit #)\n",
      "‚úì Mapped: operational_postal_code ‚Üí Operational Address \n",
      "(Postal Code)\n"
     ]
    }
   ],
   "source": [
    "# Define mapping from RecordOwl_Leads -> Fresh_Leads_format\n",
    "cols_map = {\n",
    "    \"UEN\": \"Company Registration Number (UEN)\",\n",
    "    \"Phones\": \"PIC NAME 1 Contact Number\",\n",
    "    \"Emails\": \"PIC 1 email address\",\n",
    "    \"Website\": \"Website URL\",\n",
    "    \"Facebook\": \"Facebook Page\",\n",
    "    \"Instagram\": \"Instagram URL\",\n",
    "    \"TikTok\": \"Tik Tok URL\",\n",
    "    \"LinkedIn\": \"Linkedin URL\",\n",
    "    \"operational_address\": \"Operational Address \\n(Block & Street)\",\n",
    "    \"operational_unit\": \"Operational Address \\n(Unit #)\",\n",
    "    \"operational_postal_code\": \"Operational Address \\n(Postal Code)\",\n",
    "}\n",
    "\n",
    "# Columns that contain lists and need to be flattened (extract first element)\n",
    "# FIXED: Removed \"Phones\" because it contains strings, not lists\n",
    "list_columns = [\"Emails\", \"Facebook\", \"Instagram\", \"TikTok\", \"LinkedIn\"]\n",
    "\n",
    "# CRITICAL FIX: Initialize Fresh_Leads_format with the same number of rows as RecordOwl_Leads\n",
    "Fresh_Leads_format = Fresh_Leads_format.reindex(range(len(RecordOwl_Leads)))\n",
    "\n",
    "# Fill Fresh_Leads_format using mapping\n",
    "for src_col, dest_col in cols_map.items():\n",
    "    if src_col in RecordOwl_Leads.columns and dest_col in Fresh_Leads_format.columns:\n",
    "        # Check if column contains lists\n",
    "        if src_col in list_columns:\n",
    "            # Extract first element from list, handle None/NaN gracefully\n",
    "            Fresh_Leads_format[dest_col] = RecordOwl_Leads[src_col].apply(\n",
    "                lambda x: x[0] if isinstance(x, list) and len(x) > 0 else None\n",
    "            ).values\n",
    "        else:\n",
    "            # Direct mapping for non-list columns\n",
    "            Fresh_Leads_format[dest_col] = RecordOwl_Leads[src_col].values\n",
    "        print(f\"‚úì Mapped: {src_col} ‚Üí {dest_col}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Skipped: {src_col} ‚Üí {dest_col} (missing in one of the DataFrames)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8823c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Fresh_Leads_format[\"PIC NAME 1 Contact Number\"].dropna())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c6bf15",
   "metadata": {},
   "source": [
    "### Getting ACRA Data and Merging with SSIC Code Mapping & Generating Business Type Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ff9f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azlie\\AppData\\Local\\Temp\\ipykernel_22568\\3220291497.py:70: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'SME' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  acra_data.loc[mask, 'BUSINESS_TYPE'] = 'SME'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ ACRA Business Type classification completed!\n",
      "\n",
      "Business Type distribution:\n",
      "BUSINESS_TYPE\n",
      "SME                 378656\n",
      "Startbud            157078\n",
      "Large Enterprise      1436\n",
      "NaN                    158\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"Acra_Data\"\n",
    "\n",
    "# Get all CSV file paths inside the folder\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "# Read and combine all CSVs\n",
    "df = pd.concat((pd.read_csv(f, low_memory=False) for f in csv_files), ignore_index=True)\n",
    "\n",
    "df.columns = df.columns.str.upper()\n",
    "\n",
    "acra_data = df[[\n",
    "    \"UEN\",\n",
    "    \"ENTITY_NAME\",\n",
    "    \"BUSINESS_CONSTITUTION_DESCRIPTION\",\n",
    "    \"ENTITY_TYPE_DESCRIPTION\",\n",
    "    \"ENTITY_STATUS_DESCRIPTION\",\n",
    "    \"REGISTRATION_INCORPORATION_DATE\",\n",
    "    \"PRIMARY_SSIC_CODE\",\n",
    "    \"SECONDARY_SSIC_CODE\",\n",
    "    \"UNIT_NO\",\n",
    "    \"LEVEL_NO\",\n",
    "    \"BUILDING_NAME\",\n",
    "    \"BLOCK\",\n",
    "    \"STREET_NAME\",\n",
    "    \"POSTAL_CODE\"\n",
    "]].copy()\n",
    "\n",
    "# Convert to proper data types\n",
    "acra_data['UEN'] = acra_data['UEN'].astype('string')\n",
    "acra_data['ENTITY_NAME'] = acra_data['ENTITY_NAME'].astype('string')\n",
    "acra_data['BUSINESS_CONSTITUTION_DESCRIPTION'] = acra_data['BUSINESS_CONSTITUTION_DESCRIPTION'].astype('string')\n",
    "acra_data['ENTITY_TYPE_DESCRIPTION'] = acra_data['ENTITY_TYPE_DESCRIPTION'].astype('string')\n",
    "acra_data['ENTITY_STATUS_DESCRIPTION'] = acra_data['ENTITY_STATUS_DESCRIPTION'].astype('string')\n",
    "acra_data['BLOCK'] = acra_data['BLOCK'].astype('string')\n",
    "acra_data['STREET_NAME'] = acra_data['STREET_NAME'].astype('string')\n",
    "acra_data['POSTAL_CODE'] = acra_data['POSTAL_CODE'].astype('string')\n",
    "acra_data['UNIT_NO'] = acra_data['UNIT_NO'].astype('string')\n",
    "acra_data['LEVEL_NO'] = acra_data['LEVEL_NO'].astype('string')\n",
    "acra_data['BUILDING_NAME'] = acra_data['BUILDING_NAME'].astype('string')\n",
    "acra_data['PRIMARY_SSIC_CODE'] = pd.to_numeric(acra_data['PRIMARY_SSIC_CODE'], errors='coerce')\n",
    "acra_data['SECONDARY_SSIC_CODE'] = pd.to_numeric(acra_data['SECONDARY_SSIC_CODE'], errors='coerce')\n",
    "\n",
    "# Date column\n",
    "acra_data['REGISTRATION_INCORPORATION_DATE'] = pd.to_datetime(acra_data['REGISTRATION_INCORPORATION_DATE'], errors='coerce')\n",
    "\n",
    "# Clean string columns\n",
    "for col in ['UEN', 'ENTITY_NAME', 'BUSINESS_CONSTITUTION_DESCRIPTION', 'ENTITY_TYPE_DESCRIPTION', \n",
    "            'ENTITY_STATUS_DESCRIPTION', 'BLOCK', 'STREET_NAME', 'POSTAL_CODE', 'UNIT_NO', 'LEVEL_NO', 'BUILDING_NAME']:\n",
    "    acra_data[col] = acra_data[col].fillna('').str.strip().str.replace(r'\\s+', ' ', regex=True).str.upper()\n",
    "\n",
    "acra_data.replace(['NA', 'N/A', '-', ''], np.nan, inplace=True)\n",
    "acra_data['REGISTRATION_INCORPORATION_DATE'] = acra_data['REGISTRATION_INCORPORATION_DATE'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# Filter only live entities\n",
    "acra_data = acra_data[acra_data['ENTITY_STATUS_DESCRIPTION'].isin(['LIVE COMPANY', 'LIVE'])].reset_index(drop=True)\n",
    "\n",
    "# Exclude specific PRIMARY_SSIC_CODE values\n",
    "exclude_codes = [46900, 47719, 47749, 47539, 47536, 56123, 10711, 10712, 10719, 10732, 10733, 93209]\n",
    "acra_data = acra_data[~acra_data['PRIMARY_SSIC_CODE'].isin(exclude_codes)].reset_index(drop=True)\n",
    "\n",
    "# Classify BUSINESS_TYPE - Based on age + ownership type only\n",
    "reg_date = pd.to_datetime(acra_data['REGISTRATION_INCORPORATION_DATE'], format='%d-%m-%Y', errors='coerce', dayfirst=True)\n",
    "company_age_years = (pd.Timestamp.today() - reg_date).dt.days / 365.25\n",
    "ownership_type = acra_data['ENTITY_TYPE_DESCRIPTION'].astype(str)\n",
    "\n",
    "acra_data['BUSINESS_TYPE'] = np.nan\n",
    "\n",
    "# Rule 1: age > 3 AND (LOCAL COMPANY | LLP | SOLE PROPRIETORSHIP) ‚Üí SME\n",
    "mask = (company_age_years > 3) & ownership_type.str.contains('LOCAL COMPANY|LIMITED LIABILITY PARTNERSHIP|SOLE PROPRIETORSHIP/ PARTNERSHIP', case=False, na=False)\n",
    "acra_data.loc[mask, 'BUSINESS_TYPE'] = 'SME'\n",
    "\n",
    "# Rule 2: age > 5 AND FOREIGN COMPANY BRANCH ‚Üí Large Enterprise\n",
    "mask = (company_age_years > 5) & ownership_type.str.contains('FOREIGN COMPANY BRANCH', case=False, na=False) & acra_data['BUSINESS_TYPE'].isna()\n",
    "acra_data.loc[mask, 'BUSINESS_TYPE'] = 'Large Enterprise'\n",
    "\n",
    "# Rule 3: age > 5 AND (LOCAL COMPANY | LLP) ‚Üí Franchise\n",
    "mask = (company_age_years > 5) & ownership_type.str.contains('LOCAL COMPANY|LIMITED LIABILITY PARTNERSHIP', case=False, na=False) & acra_data['BUSINESS_TYPE'].isna()\n",
    "acra_data.loc[mask, 'BUSINESS_TYPE'] = 'Franchise'\n",
    "\n",
    "# Rule 4: age < 5 AND SOLE PROPRIETORSHIP ‚Üí Startup\n",
    "mask = (company_age_years < 5) & ownership_type.str.contains('SOLE PROPRIETORSHIP/ PARTNERSHIP', case=False, na=False) & acra_data['BUSINESS_TYPE'].isna()\n",
    "acra_data.loc[mask, 'BUSINESS_TYPE'] = 'Startbud'\n",
    "\n",
    "# Fallback rules based on age only\n",
    "# Startup: Age ‚â§ 4\n",
    "# SME: Age 5‚Äì10\n",
    "# Large Enterprise: Age ‚â• 11 OR (Foreign Company Branch with Age ‚â• 7)\n",
    "unclassified = acra_data['BUSINESS_TYPE'].isna()\n",
    "acra_data.loc[unclassified & (company_age_years >= 11), 'BUSINESS_TYPE'] = 'Large Enterprise'\n",
    "acra_data.loc[unclassified & (company_age_years >= 7) & ownership_type.str.contains('FOREIGN COMPANY BRANCH', case=False, na=False), 'BUSINESS_TYPE'] = 'Large Enterprise'\n",
    "acra_data.loc[unclassified & (company_age_years >= 5) & (company_age_years <= 10) & acra_data['BUSINESS_TYPE'].isna(), 'BUSINESS_TYPE'] = 'SME'\n",
    "acra_data.loc[unclassified & (company_age_years <= 4) & acra_data['BUSINESS_TYPE'].isna(), 'BUSINESS_TYPE'] = 'Startbud'\n",
    "\n",
    "# Getting SSIC Code\n",
    "file_path = \"./SSIC_Code/mapped_ssic_code.xlsx\"\n",
    "mapped_ssic_code = pd.read_excel(file_path)\n",
    "mapped_ssic_code.columns = mapped_ssic_code.columns.str.strip().str.upper().str.replace(\" \", \"_\")\n",
    "columns_to_keep = [\"PARENT_INDUSTRY\", \"INDUSTRY_TYPE\", \"SUB_INDUSTRY\", \"SSIC_CODES\", \"DESCRIPTION\"]\n",
    "mapped_ssic_code = mapped_ssic_code[columns_to_keep].copy()\n",
    "mapped_ssic_code[\"SSIC_CODES\"] = pd.to_numeric(mapped_ssic_code[\"SSIC_CODES\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "text_cols = [\"PARENT_INDUSTRY\", \"INDUSTRY_TYPE\", \"SUB_INDUSTRY\", \"DESCRIPTION\"]\n",
    "mapped_ssic_code[text_cols] = mapped_ssic_code[text_cols].apply(lambda col: col.astype(str).str.strip().str.title())\n",
    "mapped_ssic_code = mapped_ssic_code.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Merging\n",
    "acra_data[\"PRIMARY_SSIC_CODE\"] = pd.to_numeric(acra_data[\"PRIMARY_SSIC_CODE\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "acra_data[\"SECONDARY_SSIC_CODE\"] = pd.to_numeric(acra_data[\"SECONDARY_SSIC_CODE\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "acra_data_mapped = acra_data.merge(mapped_ssic_code, how=\"left\", left_on=\"PRIMARY_SSIC_CODE\", right_on=\"SSIC_CODES\")\n",
    "acra_data_mapped = acra_data_mapped.drop(columns=[\"SSIC_CODES\"], errors=\"ignore\")\n",
    "\n",
    "print(\"\\n‚úÖ ACRA Business Type classification completed!\")\n",
    "print(f\"\\nBusiness Type distribution:\\n{acra_data_mapped['BUSINESS_TYPE'].value_counts(dropna=False)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95860f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(537328, 19)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acra_data_mapped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958863e2",
   "metadata": {},
   "source": [
    "### Mapping Leads with ACRA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa5cfd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with ACRA data\n",
    "merged = Fresh_Leads_format.merge(\n",
    "    acra_data_mapped[[\n",
    "        \"UEN\",\n",
    "        \"ENTITY_NAME\",\n",
    "        \"PRIMARY_SSIC_CODE\",\n",
    "        \"SECONDARY_SSIC_CODE\",\n",
    "        \"REGISTRATION_INCORPORATION_DATE\",\n",
    "        \"ENTITY_TYPE_DESCRIPTION\",\n",
    "        \"BUSINESS_TYPE\",\n",
    "        \"PARENT_INDUSTRY\",\n",
    "        \"INDUSTRY_TYPE\",\n",
    "        \"SUB_INDUSTRY\",\n",
    "        \"BLOCK\",\n",
    "        \"STREET_NAME\",\n",
    "        \"UNIT_NO\",\n",
    "        \"POSTAL_CODE\"\n",
    "    ]],\n",
    "    left_on=\"Company Registration Number (UEN)\",\n",
    "    right_on=\"UEN\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Create combined address fields\n",
    "merged['REGISTERED_ADDRESS_COMBINED'] = (\n",
    "    merged['BLOCK'].fillna('').astype(str) + ' ' + \n",
    "    merged['STREET_NAME'].fillna('').astype(str)\n",
    ").str.strip().replace('', np.nan)\n",
    "\n",
    "# Map ACRA data to Fresh_Leads_format columns\n",
    "merged[\"ACRA REGISTERED NAME\"] = merged[\"ENTITY_NAME\"]\n",
    "merged[\"Brand/Deal Name/Business Name\"] = merged[\"ENTITY_NAME\"]\n",
    "merged[\"Primary SSIC Code\"] = merged[\"PRIMARY_SSIC_CODE\"]\n",
    "merged[\"Secondary SSIC Code\"] = merged[\"SECONDARY_SSIC_CODE\"]\n",
    "merged[\"Company Registration date / Date Established\"] = merged[\"REGISTRATION_INCORPORATION_DATE\"]\n",
    "merged[\"Ownership Type\"] = merged[\"ENTITY_TYPE_DESCRIPTION\"]\n",
    "merged[\"Business Type\"] = merged[\"BUSINESS_TYPE\"]\n",
    "merged[\"Parent Industry Type\"] = merged[\"PARENT_INDUSTRY\"]\n",
    "merged[\"Industry Type\"] = merged[\"INDUSTRY_TYPE\"]\n",
    "merged[\"Sub Industry\"] = merged[\"SUB_INDUSTRY\"]\n",
    "merged[\"Registered Address (Block & Street)\"] = merged['REGISTERED_ADDRESS_COMBINED']\n",
    "merged[\"Registered Address  (Unit #)\"] = merged[\"UNIT_NO\"]\n",
    "merged[\"Registered Address  (Postal code)\"] = merged[\"POSTAL_CODE\"]\n",
    "merged[\"Operational Address \\n(Unit #)\"] = merged[\"UNIT_NO\"]\n",
    "merged[\"Operational Address \\n(Postal Code)\"] = merged[\"POSTAL_CODE\"]\n",
    "\n",
    "# Keep ONLY the original Fresh_Leads_format columns and make a proper copy\n",
    "Fresh_Leads_formatted = merged[Fresh_Leads_format.columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0432a1f",
   "metadata": {},
   "source": [
    "### EPOS Backend Confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "304c7ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 592 names against 2343 ePOS backend organizations...\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Total matches found: 0 out of 592\n",
      "Rows marked as 'Yes': 0\n",
      "Rows marked as 'No': 592\n",
      "\n",
      "No matches found above the threshold.\n",
      "\n",
      "\n",
      "Updated Fresh_Leads_formatted with 'Current ePOS Client ?' column:\n",
      "                                 ACRA REGISTERED NAME Current ePOS Client ?\n",
      "0                             K-JOY EDUCARE PTE. LTD.                    No\n",
      "1                                      TUNGSTAN EDLAB                    No\n",
      "2         ADVENTURE TREE PRESCHOOL BRADDELL PTE. LTD.                    No\n",
      "3         GLOBAL ACHIEVERS EDUCATION CENTRE PTE. LTD.                    No\n",
      "4                     SG NOAH'S ARK EDUTECH PTE. LTD.                    No\n",
      "5           ELITE EDUCATION & TALENT CENTRE PTE. LTD.                    No\n",
      "6                THE LITTLE CHAMPIONS (TLC) PTE. LTD.                    No\n",
      "7                                    BRAIN MATTER LLP                    No\n",
      "8                  MAPLEBEAR KIDS ADVENTURE PTE. LTD.                    No\n",
      "9                            TNTTUTORS TUITION AGENCY                    No\n",
      "10      NEW VISION EDUCATION AND TECHNOLOGY PTE. LTD.                    No\n",
      "11                   BLOSSOM GENESIS CENTRE PTE. LTD.                    No\n",
      "12                           STARRY EDUCARE PTE. LTD.                    No\n",
      "13                            LANGUAGE LOFT PTE. LTD.                    No\n",
      "14                    CARPE DIEM STARLETS 2 PTE. LTD.                    No\n",
      "15                SUPERLAND PRE-SCHOOL (BT) PTE. LTD.                    No\n",
      "16  ILEAP LEARNING CENTRE LIMITED LIABILITY PARTNE...                    No\n",
      "17          THE UNIVERSE CLASSROOM (BRANCH) PTE. LTD.                    No\n",
      "18      SWEETLANDS CHILDCARE WOODLANDS 896B PTE. LTD.                    No\n",
      "19                        HWAYANG EDUCATION PTE. LTD.                    No\n"
     ]
    }
   ],
   "source": [
    "epos_backend_df = pd.read_csv(\n",
    "    \"./Epos_Backend/organizations_export.csv\",\n",
    "    on_bad_lines=\"skip\"  # skips rows with too many or too few fields\n",
    ")\n",
    "\n",
    "epos_backend_df = epos_backend_df.loc[\n",
    "    epos_backend_df[\"status\"] == \"Active\",\n",
    "    [\"organization_name\", \"status\"]\n",
    "]\n",
    "\n",
    "epos_backend_df\n",
    "\n",
    "# Initialize \"Current ePOS Client ?\" column with \"No\" for all rows\n",
    "Fresh_Leads_formatted['Current ePOS Client ?'] = 'No'\n",
    "\n",
    "# Clean and prepare the data for matching\n",
    "# Convert to string and strip, but keep all rows (including NaN)\n",
    "Fresh_Leads_formatted['ACRA REGISTERED NAME_cleaned'] = Fresh_Leads_formatted['ACRA REGISTERED NAME'].astype(str).str.strip()\n",
    "epos_backend_names = epos_backend_df['organization_name'].dropna().astype(str).str.strip().tolist()\n",
    "\n",
    "# Set similarity threshold (100% match - exact match only)\n",
    "THRESHOLD = 100\n",
    "\n",
    "# Track matches\n",
    "matches_found = []\n",
    "matched_indices = []\n",
    "\n",
    "# Get rows with valid (non-null, non-nan) names\n",
    "valid_name_mask = (\n",
    "    Fresh_Leads_formatted['ACRA REGISTERED NAME'].notna() & \n",
    "    (Fresh_Leads_formatted['ACRA REGISTERED NAME_cleaned'] != 'nan') &\n",
    "    (Fresh_Leads_formatted['ACRA REGISTERED NAME_cleaned'] != '')\n",
    ")\n",
    "\n",
    "valid_rows = Fresh_Leads_formatted[valid_name_mask]\n",
    "print(f\"Checking {len(valid_rows)} names against {len(epos_backend_names)} ePOS backend organizations...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# For each row with a valid name, check if it exists in ePOS backend\n",
    "for idx, row in valid_rows.iterrows():\n",
    "    name = row['ACRA REGISTERED NAME_cleaned']\n",
    "    \n",
    "    # Find the best match using fuzzy matching\n",
    "    best_match = process.extractOne(\n",
    "        name, \n",
    "        epos_backend_names,\n",
    "        scorer=fuzz.token_sort_ratio\n",
    "    )\n",
    "    \n",
    "    if best_match and best_match[1] >= THRESHOLD:\n",
    "        matches_found.append({\n",
    "            'Fresh Lead Name': name,\n",
    "            'Matched ePOS Name': best_match[0],\n",
    "            'Similarity Score': best_match[1]\n",
    "        })\n",
    "        matched_indices.append(idx)  # Store the original index\n",
    "        # Update the dataframe: set \"Current ePOS Client ?\" to \"Yes\" for this row\n",
    "        Fresh_Leads_formatted.at[idx, 'Current ePOS Client ?'] = 'Yes'\n",
    "        print(f\"yes there's exist!\")\n",
    "        print(f\"  Fresh Lead: {name}\")\n",
    "        print(f\"  Matched with: {best_match[0]}\")\n",
    "        print(f\"  Similarity: {best_match[1]}%\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Drop the temporary cleaned column\n",
    "Fresh_Leads_formatted = Fresh_Leads_formatted.drop(columns=['ACRA REGISTERED NAME_cleaned'])\n",
    "\n",
    "print(f\"\\n\\nTotal matches found: {len(matches_found)} out of {len(valid_rows)}\")\n",
    "print(f\"Rows marked as 'Yes': {len(matched_indices)}\")\n",
    "print(f\"Rows marked as 'No': {len(Fresh_Leads_formatted) - len(matched_indices)}\")\n",
    "\n",
    "# Create a summary DataFrame\n",
    "if matches_found:\n",
    "    matches_df = pd.DataFrame(matches_found)\n",
    "    print(\"\\nSummary of matches:\")\n",
    "    print(matches_df)\n",
    "else:\n",
    "    print(\"\\nNo matches found above the threshold.\")\n",
    "\n",
    "# Display the updated dataframe with the new column\n",
    "print(\"\\n\\nUpdated Fresh_Leads_formatted with 'Current ePOS Client ?' column:\")\n",
    "print(Fresh_Leads_formatted[['ACRA REGISTERED NAME', 'Current ePOS Client ?']].head(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cf9656",
   "metadata": {},
   "source": [
    "### Prefil Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "810a1528",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fresh_Leads_formatted['Date'] = pd.Timestamp.today().normalize()\n",
    "Fresh_Leads_formatted['Date'] = Fresh_Leads_formatted['Date'].dt.strftime(\"%d,%m,%Y\")\n",
    "\n",
    "# fill specific columns with given values\n",
    "Fresh_Leads_formatted[\"Tele Sales or MR (For KPI - Internal)\"] = \"TeleSales\"\n",
    "Fresh_Leads_formatted[\"Name of the Market Researcher\"] = \"Shafiqah\"\n",
    "Fresh_Leads_formatted[\"Original Source (Marketing)\"] = \"Offline Sources\"\n",
    "Fresh_Leads_formatted[\"Marketing Source (Do not fill anything if the leads are from Hubspot, EPOS clients)\"] = \"Web Scrapping\"\n",
    "Fresh_Leads_formatted[\"Is this deal part of the Gov List?\"] = \"Gov List\"\n",
    "Fresh_Leads_formatted[\"Contact Number from Lusha?\"] = \"No\"\n",
    "Fresh_Leads_formatted[\"Source from Market Researcher\"] = [[\"ACRA\", \"Google Searches\"]] * len(Fresh_Leads_formatted)\n",
    "Fresh_Leads_formatted[\"Business model\"] = [[\"B2C\", \"Offline\"]] * len(Fresh_Leads_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d151e467",
   "metadata": {},
   "source": [
    "### Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e045129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìã DATA CLEANING SUMMARY\n",
      "======================================================================\n",
      "‚úÖ UEN Duplicates: None\n",
      "‚úÖ Phone Duplicates: None\n",
      "\n",
      "‚úÖ All columns cleaned successfully\n",
      "   (Excluded: ACRA REGISTERED NAME, UEN)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPREHENSIVE DATA CLEANING MODULE\n",
    "# ============================================================================\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1. COMPANY NAME CLEANING\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def clean_company_name(name):\n",
    "    \"\"\"\n",
    "    Remove common company suffixes and clean company names.\n",
    "    Handles Singapore, Malaysia, and international suffixes.\n",
    "    \"\"\"\n",
    "    if pd.isna(name) or str(name).strip() == '':\n",
    "        return name\n",
    "    \n",
    "    name = str(name).strip()\n",
    "    \n",
    "    # Remove common company suffixes (expanded list)\n",
    "    name = re.sub(\n",
    "        r'\\b(PTE\\.?\\s*LTD\\.?|PTE\\.?|LTD\\.?|LIMITED|SDN\\.?\\s*BHD\\.?|SDN\\.?|BHD\\.?|'\n",
    "        r'INC\\.?|INCORPORATED|CORP\\.?|CORPORATION|LLP|LLC|PLC|'\n",
    "        r'CO\\.?|COMPANY|COMPANIES|ENTERPRISE|ENTERPRISES|TRADING|'\n",
    "        r'PLT|SINGAPORE|SG|HOLDINGS?|HOLDING|GROUP|'\n",
    "        r'PRIVATE|PUBLIC|INTERNATIONAL|INTL\\.?|GLOBAL|'\n",
    "        r'SERVICES?|SOLUTIONS?|SYSTEMS?|TECHNOLOGIES|TECH)\\b',\n",
    "        '', name, flags=re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    # Remove extra punctuation but keep meaningful characters (hyphen at end to avoid range error)\n",
    "    name = re.sub(r'[^\\w\\s&@#+\\-]', '', name)  # Keep alphanumeric, &, @, #, +, -, spaces\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    \n",
    "    # Remove trailing/leading special characters (hyphen at end)\n",
    "    name = re.sub(r'^[&@#+\\-\\s]+|[&@#+\\-\\s]+$', '', name).strip()\n",
    "    \n",
    "    return name if name else pd.NA\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2. PHONE NUMBER CLEANING & FORMATTING\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def clean_phone_number(phone):\n",
    "    \"\"\"\n",
    "    Clean and format phone numbers to Singapore standard: 65 XXXX XXXX\n",
    "    Handles various input formats and validates phone numbers.\n",
    "    \"\"\"\n",
    "    if pd.isna(phone) or str(phone).strip() in ['', 'nan', 'None', 'null']:\n",
    "        return pd.NA\n",
    "    \n",
    "    # Convert to string and extract all digits\n",
    "    digits = re.sub(r'\\D', '', str(phone))\n",
    "    \n",
    "    if not digits:\n",
    "        return pd.NA\n",
    "    \n",
    "    # Remove leading zeros\n",
    "    digits = digits.lstrip('0')\n",
    "    \n",
    "    # Handle country codes\n",
    "    if digits.startswith('65'):\n",
    "        # Singapore number with country code\n",
    "        local_part = digits[2:]\n",
    "        if len(local_part) >= 8:\n",
    "            # Format: 65 XXXX XXXX\n",
    "            return f\"65 {local_part[:4]} {local_part[4:8]}\"\n",
    "        elif len(local_part) >= 4:\n",
    "            return f\"65 {local_part}\"\n",
    "        else:\n",
    "            return pd.NA  # Invalid Singapore number\n",
    "    \n",
    "    elif len(digits) == 8:\n",
    "        # Local Singapore number without country code\n",
    "        return f\"65 {digits[:4]} {digits[4:]}\"\n",
    "    \n",
    "    elif len(digits) == 10 and digits.startswith('65'):\n",
    "        # 65XXXXXXXX format\n",
    "        return f\"65 {digits[2:6]} {digits[6:10]}\"\n",
    "    \n",
    "    elif len(digits) > 8:\n",
    "        # Assume first part is country code, take last 8 digits as local number\n",
    "        local_part = digits[-8:]\n",
    "        return f\"65 {local_part[:4]} {local_part[4:]}\"\n",
    "    \n",
    "    else:\n",
    "        # Less than 8 digits - likely invalid or incomplete\n",
    "        return pd.NA\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3. EMAIL CLEANING\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def clean_email(email):\n",
    "    \"\"\"\n",
    "    Clean and validate email addresses.\n",
    "    Remove brackets, quotes, and validate format.\n",
    "    \"\"\"\n",
    "    if pd.isna(email) or str(email).strip() in ['', 'nan', 'None', 'null']:\n",
    "        return pd.NA\n",
    "    \n",
    "    email = str(email).strip()\n",
    "    \n",
    "    # Remove brackets, quotes, and other unwanted characters\n",
    "    email = re.sub(r'[\\[\\]\\'\\\"+,]', '', email)\n",
    "    email = email.strip().lower()\n",
    "    \n",
    "    # Basic email validation\n",
    "    if re.match(r'^[a-z0-9][a-z0-9._-]*@[a-z0-9][a-z0-9.-]+\\.[a-z]{2,}$', email):\n",
    "        return email\n",
    "    else:\n",
    "        return pd.NA\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4. URL CLEANING (for social media and websites)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def clean_url(url):\n",
    "    \"\"\"\n",
    "    Clean URLs by removing brackets, quotes, and validating format.\n",
    "    \"\"\"\n",
    "    if pd.isna(url) or str(url).strip() in ['', 'nan', 'None', 'null']:\n",
    "        return pd.NA\n",
    "    \n",
    "    url = str(url).strip()\n",
    "    \n",
    "    # Remove brackets, quotes, commas\n",
    "    url = re.sub(r'[\\[\\]\\'\\\"+,]', '', url)\n",
    "    url = url.strip()\n",
    "    \n",
    "    # Basic URL validation (starts with http/https or www or common domains)\n",
    "    if re.match(r'^(https?://|www\\.|[a-z]+\\.(com|sg|net|org|co))', url, re.IGNORECASE):\n",
    "        return url\n",
    "    else:\n",
    "        return pd.NA\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5. LIST/ARRAY COLUMN CLEANING\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "def clean_list_column(value):\n",
    "    \"\"\"\n",
    "    Clean columns that contain list/array values.\n",
    "    Handles both actual Python lists and stringified lists.\n",
    "    Returns as comma-separated string.\n",
    "    \"\"\"\n",
    "    # Handle actual None/NaN values\n",
    "    if value is None:\n",
    "        return pd.NA\n",
    "    \n",
    "    # Check if it's already a pandas NA\n",
    "    try:\n",
    "        if pd.isna(value):\n",
    "            return pd.NA\n",
    "    except (ValueError, TypeError):\n",
    "        # If pd.isna() fails (for lists), continue processing\n",
    "        pass\n",
    "    \n",
    "    # If it's already a list, convert to comma-separated string\n",
    "    if isinstance(value, list):\n",
    "        if len(value) == 0:\n",
    "            return pd.NA\n",
    "        # Clean each item in the list\n",
    "        cleaned_items = [str(item).strip() for item in value if item is not None and str(item).strip() not in ['', 'nan', 'None', 'null']]\n",
    "        if cleaned_items:\n",
    "            return ', '.join(cleaned_items)\n",
    "        else:\n",
    "            return pd.NA\n",
    "    \n",
    "    # Convert to string for string-based processing\n",
    "    value_str = str(value).strip()\n",
    "    \n",
    "    # Check for empty or null strings\n",
    "    if value_str in ['', 'nan', 'None', 'null']:\n",
    "        return pd.NA\n",
    "    \n",
    "    # Remove brackets and quotes from stringified lists\n",
    "    value_str = re.sub(r'[\\[\\]\\'\\\"+]', '', value_str)\n",
    "    \n",
    "    # Clean up commas and spaces\n",
    "    value_str = re.sub(r'\\s*,\\s*', ', ', value_str).strip()\n",
    "    \n",
    "    return value_str if value_str else pd.NA\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6. APPLY CLEANING TO ALL COLUMNS (SILENT MODE)\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# Clean Company/Brand Names (ONLY Brand/Deal Name, NOT ACRA REGISTERED NAME)\n",
    "if \"Brand/Deal Name/Business Name\" in Fresh_Leads_formatted.columns:\n",
    "    Fresh_Leads_formatted[\"Brand/Deal Name/Business Name\"] = Fresh_Leads_formatted[\"Brand/Deal Name/Business Name\"].apply(clean_company_name)\n",
    "\n",
    "# Clean Phone Numbers\n",
    "phone_columns = [\"PIC NAME 1 Contact Number\", \"PIC NAME 2 Contact Number\", \"PIC NAME 3 Contact Number\", \"Contact Number from Lusha?\"]\n",
    "for col in phone_columns:\n",
    "    if col in Fresh_Leads_formatted.columns:\n",
    "        Fresh_Leads_formatted[col] = Fresh_Leads_formatted[col].apply(clean_phone_number)\n",
    "\n",
    "# Clean Emails\n",
    "email_columns = [\"PIC 1 email address\", \"PIC 2 email address\", \"PIC 3 email address\"]\n",
    "for col in email_columns:\n",
    "    if col in Fresh_Leads_formatted.columns:\n",
    "        Fresh_Leads_formatted[col] = Fresh_Leads_formatted[col].apply(clean_email)\n",
    "\n",
    "# Clean URLs (Social Media & Websites)\n",
    "url_columns = [\"Website URL\", \"Facebook Page\", \"Instagram URL\", \"Linkedin URL\", \"Tik Tok URL\", \n",
    "               \"Sub Domain Link (If Lead is already available in Backend) Fill only when EPOS client\"]\n",
    "for col in url_columns:\n",
    "    if col in Fresh_Leads_formatted.columns:\n",
    "        Fresh_Leads_formatted[col] = Fresh_Leads_formatted[col].apply(clean_url)\n",
    "\n",
    "# Clean List/Array Columns\n",
    "list_columns = [\"Source from Market Researcher\", \"Business model\", \"FB/Insta/Tik Tok/Linkedin Contact\"]\n",
    "for col in list_columns:\n",
    "    if col in Fresh_Leads_formatted.columns:\n",
    "        Fresh_Leads_formatted[col] = Fresh_Leads_formatted[col].apply(clean_list_column)\n",
    "\n",
    "# Clean Text Columns (General)\n",
    "text_columns = [\"First Name\", \"Last Name\", \"First Name 2\", \"Last Name 2\", \"First Name 3\", \"Last Name 3\",\n",
    "                \"PIC Name 1 Designation\", \"PIC Name 2 Designation\", \"PIC Name Designation 3\",\n",
    "                \"Name of the Market Researcher\", \"Tele Sales or MR (For KPI - Internal)\"]\n",
    "for col in text_columns:\n",
    "    if col in Fresh_Leads_formatted.columns:\n",
    "        Fresh_Leads_formatted[col] = Fresh_Leads_formatted[col].apply(\n",
    "            lambda x: str(x).strip() if pd.notna(x) and str(x).strip() not in ['', 'nan', 'None'] else pd.NA\n",
    "        )\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 7. CORE INDICATORS - CLEANING STATUS & DUPLICATES\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üìã DATA CLEANING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for duplicate UENs\n",
    "uen_has_duplicates = False\n",
    "if \"Company Registration Number (UEN)\" in Fresh_Leads_formatted.columns:\n",
    "    uen_duplicates = Fresh_Leads_formatted[Fresh_Leads_formatted.duplicated(subset=[\"Company Registration Number (UEN)\"], keep=False)]\n",
    "    uen_dup_count = len(uen_duplicates)\n",
    "    if uen_dup_count > 0:\n",
    "        uen_has_duplicates = True\n",
    "        print(f\"‚ö†Ô∏è  UEN Duplicates: {uen_dup_count} rows ({uen_duplicates['Company Registration Number (UEN)'].nunique()} unique UENs)\")\n",
    "    else:\n",
    "        print(f\"‚úÖ UEN Duplicates: None\")\n",
    "\n",
    "# Check for duplicate Phone Numbers\n",
    "phone_has_duplicates = False\n",
    "if \"PIC NAME 1 Contact Number\" in Fresh_Leads_formatted.columns:\n",
    "    phone_duplicates = Fresh_Leads_formatted[\n",
    "        Fresh_Leads_formatted.duplicated(subset=[\"PIC NAME 1 Contact Number\"], keep=False) &\n",
    "        Fresh_Leads_formatted[\"PIC NAME 1 Contact Number\"].notna()\n",
    "    ]\n",
    "    phone_dup_count = len(phone_duplicates)\n",
    "    if phone_dup_count > 0:\n",
    "        phone_has_duplicates = True\n",
    "        print(f\"‚ö†Ô∏è  Phone Duplicates: {phone_dup_count} rows ({phone_duplicates['PIC NAME 1 Contact Number'].nunique()} unique numbers)\")\n",
    "    else:\n",
    "        print(f\"‚úÖ Phone Duplicates: None\")\n",
    "\n",
    "# Cleaning completion status\n",
    "print(f\"\\n‚úÖ All columns cleaned successfully\")\n",
    "print(f\"   (Excluded: ACRA REGISTERED NAME, UEN)\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16d5da26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 62)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fresh_Leads_formatted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b3efed40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ePOS Code</th>\n",
       "      <th>Company Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>ACRA REGISTERED NAME</th>\n",
       "      <th>Brand/Deal Name/Business Name</th>\n",
       "      <th>Sub Domain Link (If Lead is already available in Backend) Fill only when EPOS client</th>\n",
       "      <th>Tele Sales or MR (For KPI - Internal)</th>\n",
       "      <th>Name of the Market Researcher</th>\n",
       "      <th>Original Source (Marketing)</th>\n",
       "      <th>Marketing Source (Do not fill anything if the leads are from Hubspot, EPOS clients)</th>\n",
       "      <th>...</th>\n",
       "      <th>PIC Name Designation 3</th>\n",
       "      <th>PIC NAME 3 Contact Number</th>\n",
       "      <th>PIC 3 email address</th>\n",
       "      <th>FB/Insta/Tik Tok/Linkedin Contact</th>\n",
       "      <th>Current ePOS Client ?</th>\n",
       "      <th>If ePOS Client, which product they are using?</th>\n",
       "      <th>Is this deal part of the Gov List?</th>\n",
       "      <th>Source from Market Researcher</th>\n",
       "      <th>Contact Number from Lusha?</th>\n",
       "      <th>Phone number Verified ?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19,11,2025</td>\n",
       "      <td>K-JOY EDUCARE PTE. LTD.</td>\n",
       "      <td>K-JOY EDUCARE</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Shafiqah</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA, Google Searches</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19,11,2025</td>\n",
       "      <td>TUNGSTAN EDLAB</td>\n",
       "      <td>TUNGSTAN EDLAB</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Shafiqah</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA, Google Searches</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19,11,2025</td>\n",
       "      <td>ADVENTURE TREE PRESCHOOL BRADDELL PTE. LTD.</td>\n",
       "      <td>ADVENTURE TREE PRESCHOOL BRADDELL</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Shafiqah</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA, Google Searches</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19,11,2025</td>\n",
       "      <td>GLOBAL ACHIEVERS EDUCATION CENTRE PTE. LTD.</td>\n",
       "      <td>ACHIEVERS EDUCATION CENTRE</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Shafiqah</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA, Google Searches</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19,11,2025</td>\n",
       "      <td>SG NOAH'S ARK EDUTECH PTE. LTD.</td>\n",
       "      <td>NOAHS ARK EDUTECH</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Shafiqah</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA, Google Searches</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19,11,2025</td>\n",
       "      <td>PLANTLOVE STUDIO PTE. LTD.</td>\n",
       "      <td>PLANTLOVE STUDIO</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Shafiqah</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA, Google Searches</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19,11,2025</td>\n",
       "      <td>AREXEVAN RACING PTE. LTD.</td>\n",
       "      <td>AREXEVAN RACING</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Shafiqah</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA, Google Searches</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19,11,2025</td>\n",
       "      <td>BELVEDERE BRITISH EDUCATION PTE. LTD.</td>\n",
       "      <td>BELVEDERE BRITISH EDUCATION</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Shafiqah</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA, Google Searches</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19,11,2025</td>\n",
       "      <td>IRATOS SINGAPORE PTE. LTD.</td>\n",
       "      <td>IRATOS</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Shafiqah</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA, Google Searches</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19,11,2025</td>\n",
       "      <td>ELIE CONSULTANCY</td>\n",
       "      <td>ELIE CONSULTANCY</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>TeleSales</td>\n",
       "      <td>Shafiqah</td>\n",
       "      <td>Offline Sources</td>\n",
       "      <td>Web Scrapping</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gov List</td>\n",
       "      <td>ACRA, Google Searches</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>592 rows √ó 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ePOS Code Company Code        Date  \\\n",
       "0         NaN          NaN  19,11,2025   \n",
       "1         NaN          NaN  19,11,2025   \n",
       "2         NaN          NaN  19,11,2025   \n",
       "3         NaN          NaN  19,11,2025   \n",
       "4         NaN          NaN  19,11,2025   \n",
       "..        ...          ...         ...   \n",
       "587       NaN          NaN  19,11,2025   \n",
       "588       NaN          NaN  19,11,2025   \n",
       "589       NaN          NaN  19,11,2025   \n",
       "590       NaN          NaN  19,11,2025   \n",
       "591       NaN          NaN  19,11,2025   \n",
       "\n",
       "                            ACRA REGISTERED NAME  \\\n",
       "0                        K-JOY EDUCARE PTE. LTD.   \n",
       "1                                 TUNGSTAN EDLAB   \n",
       "2    ADVENTURE TREE PRESCHOOL BRADDELL PTE. LTD.   \n",
       "3    GLOBAL ACHIEVERS EDUCATION CENTRE PTE. LTD.   \n",
       "4                SG NOAH'S ARK EDUTECH PTE. LTD.   \n",
       "..                                           ...   \n",
       "587                   PLANTLOVE STUDIO PTE. LTD.   \n",
       "588                    AREXEVAN RACING PTE. LTD.   \n",
       "589        BELVEDERE BRITISH EDUCATION PTE. LTD.   \n",
       "590                   IRATOS SINGAPORE PTE. LTD.   \n",
       "591                             ELIE CONSULTANCY   \n",
       "\n",
       "         Brand/Deal Name/Business Name  \\\n",
       "0                        K-JOY EDUCARE   \n",
       "1                       TUNGSTAN EDLAB   \n",
       "2    ADVENTURE TREE PRESCHOOL BRADDELL   \n",
       "3           ACHIEVERS EDUCATION CENTRE   \n",
       "4                    NOAHS ARK EDUTECH   \n",
       "..                                 ...   \n",
       "587                   PLANTLOVE STUDIO   \n",
       "588                    AREXEVAN RACING   \n",
       "589        BELVEDERE BRITISH EDUCATION   \n",
       "590                             IRATOS   \n",
       "591                   ELIE CONSULTANCY   \n",
       "\n",
       "    Sub Domain Link (If Lead is already available in Backend) Fill only when EPOS client  \\\n",
       "0                                                 <NA>                                     \n",
       "1                                                 <NA>                                     \n",
       "2                                                 <NA>                                     \n",
       "3                                                 <NA>                                     \n",
       "4                                                 <NA>                                     \n",
       "..                                                 ...                                     \n",
       "587                                               <NA>                                     \n",
       "588                                               <NA>                                     \n",
       "589                                               <NA>                                     \n",
       "590                                               <NA>                                     \n",
       "591                                               <NA>                                     \n",
       "\n",
       "    Tele Sales or MR (For KPI - Internal) Name of the Market Researcher  \\\n",
       "0                               TeleSales                      Shafiqah   \n",
       "1                               TeleSales                      Shafiqah   \n",
       "2                               TeleSales                      Shafiqah   \n",
       "3                               TeleSales                      Shafiqah   \n",
       "4                               TeleSales                      Shafiqah   \n",
       "..                                    ...                           ...   \n",
       "587                             TeleSales                      Shafiqah   \n",
       "588                             TeleSales                      Shafiqah   \n",
       "589                             TeleSales                      Shafiqah   \n",
       "590                             TeleSales                      Shafiqah   \n",
       "591                             TeleSales                      Shafiqah   \n",
       "\n",
       "    Original Source (Marketing)  \\\n",
       "0               Offline Sources   \n",
       "1               Offline Sources   \n",
       "2               Offline Sources   \n",
       "3               Offline Sources   \n",
       "4               Offline Sources   \n",
       "..                          ...   \n",
       "587             Offline Sources   \n",
       "588             Offline Sources   \n",
       "589             Offline Sources   \n",
       "590             Offline Sources   \n",
       "591             Offline Sources   \n",
       "\n",
       "    Marketing Source (Do not fill anything if the leads are from Hubspot, EPOS clients)  \\\n",
       "0                                        Web Scrapping                                    \n",
       "1                                        Web Scrapping                                    \n",
       "2                                        Web Scrapping                                    \n",
       "3                                        Web Scrapping                                    \n",
       "4                                        Web Scrapping                                    \n",
       "..                                                 ...                                    \n",
       "587                                      Web Scrapping                                    \n",
       "588                                      Web Scrapping                                    \n",
       "589                                      Web Scrapping                                    \n",
       "590                                      Web Scrapping                                    \n",
       "591                                      Web Scrapping                                    \n",
       "\n",
       "     ... PIC Name Designation 3 PIC NAME 3 Contact Number  \\\n",
       "0    ...                   <NA>                      <NA>   \n",
       "1    ...                   <NA>                      <NA>   \n",
       "2    ...                   <NA>                      <NA>   \n",
       "3    ...                   <NA>                      <NA>   \n",
       "4    ...                   <NA>                      <NA>   \n",
       "..   ...                    ...                       ...   \n",
       "587  ...                   <NA>                      <NA>   \n",
       "588  ...                   <NA>                      <NA>   \n",
       "589  ...                   <NA>                      <NA>   \n",
       "590  ...                   <NA>                      <NA>   \n",
       "591  ...                   <NA>                      <NA>   \n",
       "\n",
       "     PIC 3 email address  FB/Insta/Tik Tok/Linkedin Contact  \\\n",
       "0                   <NA>                               <NA>   \n",
       "1                   <NA>                               <NA>   \n",
       "2                   <NA>                               <NA>   \n",
       "3                   <NA>                               <NA>   \n",
       "4                   <NA>                               <NA>   \n",
       "..                   ...                                ...   \n",
       "587                 <NA>                               <NA>   \n",
       "588                 <NA>                               <NA>   \n",
       "589                 <NA>                               <NA>   \n",
       "590                 <NA>                               <NA>   \n",
       "591                 <NA>                               <NA>   \n",
       "\n",
       "    Current ePOS Client ? If ePOS Client, which product they are using?  \\\n",
       "0                      No                                           NaN   \n",
       "1                      No                                           NaN   \n",
       "2                      No                                           NaN   \n",
       "3                      No                                           NaN   \n",
       "4                      No                                           NaN   \n",
       "..                    ...                                           ...   \n",
       "587                    No                                           NaN   \n",
       "588                    No                                           NaN   \n",
       "589                    No                                           NaN   \n",
       "590                    No                                           NaN   \n",
       "591                    No                                           NaN   \n",
       "\n",
       "    Is this deal part of the Gov List? Source from Market Researcher  \\\n",
       "0                             Gov List         ACRA, Google Searches   \n",
       "1                             Gov List         ACRA, Google Searches   \n",
       "2                             Gov List         ACRA, Google Searches   \n",
       "3                             Gov List         ACRA, Google Searches   \n",
       "4                             Gov List         ACRA, Google Searches   \n",
       "..                                 ...                           ...   \n",
       "587                           Gov List         ACRA, Google Searches   \n",
       "588                           Gov List         ACRA, Google Searches   \n",
       "589                           Gov List         ACRA, Google Searches   \n",
       "590                           Gov List         ACRA, Google Searches   \n",
       "591                           Gov List         ACRA, Google Searches   \n",
       "\n",
       "    Contact Number from Lusha? Phone number Verified ?  \n",
       "0                         <NA>                     NaN  \n",
       "1                         <NA>                     NaN  \n",
       "2                         <NA>                     NaN  \n",
       "3                         <NA>                     NaN  \n",
       "4                         <NA>                     NaN  \n",
       "..                         ...                     ...  \n",
       "587                       <NA>                     NaN  \n",
       "588                       <NA>                     NaN  \n",
       "589                       <NA>                     NaN  \n",
       "590                       <NA>                     NaN  \n",
       "591                       <NA>                     NaN  \n",
       "\n",
       "[592 rows x 62 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fresh_Leads_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "99762ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fresh_Leads_formatted.to_parquet(\"./Staging/Gold/cleaned_second_592.parquet\", index=False, engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7632c6fa",
   "metadata": {},
   "source": [
    "### Examine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f21540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = Fresh_Leads_formatted[[\n",
    "#     \"ACRA REGISTERED NAME\",\n",
    "#     \"Brand/Deal Name/Business Name\",\n",
    "#     \"PIC NAME 1 Contact Number\",\n",
    "#     \"Business Type\",\n",
    "#     \"Registered Address (Block & Street)\", \n",
    "#     \"Registered Address  (Unit #)\", \n",
    "#     \"Registered Address  (Postal code)\", \n",
    "#     \"Operational Address \\n(Postal Code)\",\n",
    "# ]]\n",
    "# x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a974a11",
   "metadata": {},
   "source": [
    "### Separate by Qualified Phones, Facebook & Website URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b0dfdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Phone not NaN and not empty\n",
    "# leads_by_Phone = RecordOwl_Leads[\n",
    "# RecordOwl_Leads[\"Phones\"].notna() &\n",
    "# (RecordOwl_Leads[\"Phones\"].astype(str).str.strip() != \"\")\n",
    "# ]\n",
    "\n",
    "\n",
    "# # 2. Facebook only (Facebook not empty, Phone empty, Website empty)\n",
    "# df_facebook_only = RecordOwl_Leads[\n",
    "# (\n",
    "# RecordOwl_Leads[\"Phones\"].isna() |\n",
    "# (RecordOwl_Leads[\"Phones\"].astype(str).str.strip() == \"\")\n",
    "# )\n",
    "# &\n",
    "# (\n",
    "# RecordOwl_Leads[\"Website\"].isna() |\n",
    "# (RecordOwl_Leads[\"Website\"].astype(str).str.strip() == \"\")\n",
    "# )\n",
    "# &\n",
    "# (RecordOwl_Leads[\"Facebook\"].notna()) &\n",
    "# (RecordOwl_Leads[\"Facebook\"].astype(str).str.strip() != \"\")\n",
    "# ]\n",
    "\n",
    "\n",
    "# # 3. Website only (Website not empty, Phone empty, Facebook empty)\n",
    "# df_website_only = RecordOwl_Leads[\n",
    "# (RecordOwl_Leads[\"Website\"].notna()) &\n",
    "# (RecordOwl_Leads[\"Website\"].astype(str).str.strip() != \"\")\n",
    "# &\n",
    "# (\n",
    "# RecordOwl_Leads[\"Phones\"].isna() |\n",
    "# (RecordOwl_Leads[\"Phones\"].astype(str).str.strip() == \"\")\n",
    "# )\n",
    "# &\n",
    "# (\n",
    "# RecordOwl_Leads[\"Facebook\"].isna() |\n",
    "# (RecordOwl_Leads[\"Facebook\"].astype(str).str.strip() == \"\")\n",
    "# )\n",
    "# ]\n",
    "\n",
    "\n",
    "# # Show shapes of all 3\n",
    "# df_phone.shape, df_facebook_only.shape, df_website_only.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
