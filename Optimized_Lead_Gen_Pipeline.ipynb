{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "328e86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from apify_client import ApifyClient\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from requests.exceptions import HTTPError, ConnectionError\n",
    "from urllib3.exceptions import ProtocolError\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767bf86c",
   "metadata": {},
   "source": [
    "### Getting Master DB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa7f0eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ACRA_REGISTERED_NAME</th>\n",
       "      <th>BRAND_NAME</th>\n",
       "      <th>SSIC_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04799400B</td>\n",
       "      <td>AIK BEE TEXTILE CO</td>\n",
       "      <td>AIK BEE TEXTILE CO</td>\n",
       "      <td>46411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03376200K</td>\n",
       "      <td>SERANGOON GARDEN CLINIC AND DISPENSARY</td>\n",
       "      <td>GARDEN CLINIC</td>\n",
       "      <td>550263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06239600E</td>\n",
       "      <td>SALON DE BENZIMEN</td>\n",
       "      <td>SALON DE BENZIMEN</td>\n",
       "      <td>96021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06952000C</td>\n",
       "      <td>SU LAN LADIES FASHION</td>\n",
       "      <td>SU LAN LADIES FASHION</td>\n",
       "      <td>14103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10381600C</td>\n",
       "      <td>SIN HAI PRINTING SERVICE</td>\n",
       "      <td>SIN HAI PRINTING SERVICE</td>\n",
       "      <td>18113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7444</th>\n",
       "      <td>201734006N</td>\n",
       "      <td>MISTER MOBILE HOUGANG PTE. LTD.</td>\n",
       "      <td>MISTER MOBILE (HOUGANG)</td>\n",
       "      <td>95120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7445</th>\n",
       "      <td>202210879W</td>\n",
       "      <td>MISTER MOBILE CHINATOWN PTE. LTD.</td>\n",
       "      <td>MISTER MOBILE (CHINATOWN)</td>\n",
       "      <td>47411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7446</th>\n",
       "      <td>202205507G</td>\n",
       "      <td>MISTER MOBILE PTE. LTD.</td>\n",
       "      <td>MISTER MOBILE HQ</td>\n",
       "      <td>64202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7454</th>\n",
       "      <td>53473046M</td>\n",
       "      <td>BLOONIES</td>\n",
       "      <td>BLOONIES</td>\n",
       "      <td>47742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7455</th>\n",
       "      <td>53478373B</td>\n",
       "      <td>BLOOMSNBALLOONS</td>\n",
       "      <td>BLOOMS AND BALLOONS</td>\n",
       "      <td>47742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6734 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             UEN                    ACRA_REGISTERED_NAME  \\\n",
       "0      04799400B                      AIK BEE TEXTILE CO   \n",
       "1      03376200K  SERANGOON GARDEN CLINIC AND DISPENSARY   \n",
       "2      06239600E                       SALON DE BENZIMEN   \n",
       "3      06952000C                   SU LAN LADIES FASHION   \n",
       "4      10381600C                SIN HAI PRINTING SERVICE   \n",
       "...          ...                                     ...   \n",
       "7444  201734006N         MISTER MOBILE HOUGANG PTE. LTD.   \n",
       "7445  202210879W       MISTER MOBILE CHINATOWN PTE. LTD.   \n",
       "7446  202205507G                 MISTER MOBILE PTE. LTD.   \n",
       "7454   53473046M                                BLOONIES   \n",
       "7455   53478373B                         BLOOMSNBALLOONS   \n",
       "\n",
       "                     BRAND_NAME  SSIC_CODE  \n",
       "0            AIK BEE TEXTILE CO      46411  \n",
       "1                 GARDEN CLINIC     550263  \n",
       "2             SALON DE BENZIMEN      96021  \n",
       "3         SU LAN LADIES FASHION      14103  \n",
       "4      SIN HAI PRINTING SERVICE      18113  \n",
       "...                         ...        ...  \n",
       "7444    MISTER MOBILE (HOUGANG)      95120  \n",
       "7445  MISTER MOBILE (CHINATOWN)      47411  \n",
       "7446           MISTER MOBILE HQ      64202  \n",
       "7454                   BLOONIES      47742  \n",
       "7455        BLOOMS AND BALLOONS      47742  \n",
       "\n",
       "[6734 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- CONFIG ---\n",
    "file_path = \"./Master DB/Master_DB_oct22.xlsx\"\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def clean_uen(u: str) -> str | None:\n",
    "    if pd.isna(u):\n",
    "        return None\n",
    "    return re.sub(r\"[^A-Z0-9]\", \"\", str(u).upper().strip())\n",
    "\n",
    "def clean_text(text: str) -> str | None:\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    text = str(text).strip().upper()\n",
    "    return None if text == \"NAN\" else text\n",
    "\n",
    "def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert all column names to uppercase, replace non-alphanumeric with single underscore, remove trailing underscores.\"\"\"\n",
    "    new_cols = []\n",
    "    for col in df.columns:\n",
    "        col_std = re.sub(r\"[^A-Z0-9]\", \"_\", col.upper().strip())\n",
    "        col_std = re.sub(r\"_+\", \"_\", col_std)  # Replace multiple underscores with single\n",
    "        col_std = col_std.strip(\"_\")  # Remove leading/trailing underscores\n",
    "        new_cols.append(col_std)\n",
    "    df.columns = new_cols\n",
    "    return df\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "master_db_df = pd.read_excel(file_path)\n",
    "\n",
    "# --- SELECT RELEVANT COLUMNS ---\n",
    "columns_to_keep = [\n",
    "    \"Company Registration Number (UEN)\",\n",
    "    \"ACRA REGISTERED NAME\",\n",
    "    \"Brand/Deal Name/Business Name\",\n",
    "    \"Primary SSIC Code\",\n",
    "    \"PIC NAME 1 Contact Number\",\n",
    "    \"PIC 1 email address\",\n",
    "    \"Website URL\",\n",
    "    \"Parent Industry Type\",\n",
    "    \"Sub Industry\"\n",
    "]\n",
    "master_db_df = master_db_df[columns_to_keep].copy()\n",
    "\n",
    "# --- STANDARDIZE COLUMN NAMES ---\n",
    "master_db_df = standardize_columns(master_db_df)\n",
    "\n",
    "# --- CLEANING & RENAME SPECIFIC COLUMNS ---\n",
    "# Dynamically find the UEN column (first column containing 'UEN')\n",
    "uen_col = [c for c in master_db_df.columns if \"UEN\" in c][0]\n",
    "master_db_df[\"UEN\"] = master_db_df[uen_col].apply(clean_uen)\n",
    "master_db_df = master_db_df.drop(columns=[uen_col])\n",
    "\n",
    "# Rename other columns consistently\n",
    "rename_map = {\n",
    "    \"BRAND_DEAL_NAME_BUSINESS_NAME\": \"BRAND_NAME\",\n",
    "    \"PRIMARY_SSIC_CODE\": \"SSIC_CODE\",\n",
    "    \"ACRA_REGISTERED_NAME\": \"ACRA_REGISTERED_NAME\"\n",
    "}\n",
    "master_db_df = master_db_df.rename(columns={k: v for k, v in rename_map.items() if k in master_db_df.columns})\n",
    "\n",
    "# Clean text columns\n",
    "for col in [\"ACRA_REGISTERED_NAME\", \"BRAND_NAME\"]:\n",
    "    if col in master_db_df.columns:\n",
    "        master_db_df[col] = master_db_df[col].apply(clean_text)\n",
    "\n",
    "# Convert SSIC_CODE to integer if exists\n",
    "if \"SSIC_CODE\" in master_db_df.columns:\n",
    "    master_db_df[\"SSIC_CODE\"] = master_db_df[\"SSIC_CODE\"].astype(\"Int64\")\n",
    "\n",
    "# Keep only required columns if they exist\n",
    "required_cols = [\"UEN\", \"ACRA_REGISTERED_NAME\", \"BRAND_NAME\", \"SSIC_CODE\"]\n",
    "master_db_df = master_db_df[[c for c in required_cols if c in master_db_df.columns]]\n",
    "\n",
    "# Filter out rows with missing or empty UEN\n",
    "master_db_df = master_db_df[master_db_df[\"UEN\"].notna() & (master_db_df[\"UEN\"].str.strip() != \"\")]\n",
    "\n",
    "master_db_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e98cff",
   "metadata": {},
   "source": [
    "### Getting ACRA Data (Filter by Live, Live Company only & non relevant ssic code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e678fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Folder containing your CSVs\n",
    "# -------------------------------------------------------------\n",
    "folder_path = \"Acra_Data\"\n",
    "\n",
    "# Get all CSV file paths inside the folder\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "# Read and combine all CSVs\n",
    "# Using low_memory=False to avoid DtypeWarning for mixed types\n",
    "df = pd.concat((pd.read_csv(f, low_memory=False) for f in csv_files), ignore_index=True)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Convert all column names to uppercase\n",
    "# -------------------------------------------------------------\n",
    "df.columns = df.columns.str.upper()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Select relevant columns (now in uppercase)\n",
    "# -------------------------------------------------------------\n",
    "acra_data = df[[\n",
    "    \"UEN\",\n",
    "    \"ENTITY_NAME\",\n",
    "    \"BUSINESS_CONSTITUTION_DESCRIPTION\",\n",
    "    \"ENTITY_TYPE_DESCRIPTION\",\n",
    "    \"ENTITY_STATUS_DESCRIPTION\",\n",
    "    \"REGISTRATION_INCORPORATION_DATE\",\n",
    "    \"PRIMARY_SSIC_CODE\",\n",
    "    \"STREET_NAME\",\n",
    "    \"POSTAL_CODE\"\n",
    "]].copy()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Convert to proper data types\n",
    "# -------------------------------------------------------------\n",
    "acra_data['UEN'] = acra_data['UEN'].astype('string')\n",
    "acra_data['ENTITY_NAME'] = acra_data['ENTITY_NAME'].astype('string')\n",
    "acra_data['BUSINESS_CONSTITUTION_DESCRIPTION'] = acra_data['BUSINESS_CONSTITUTION_DESCRIPTION'].astype('string')\n",
    "acra_data['ENTITY_TYPE_DESCRIPTION'] = acra_data['ENTITY_TYPE_DESCRIPTION'].astype('string')\n",
    "acra_data['ENTITY_STATUS_DESCRIPTION'] = acra_data['ENTITY_STATUS_DESCRIPTION'].astype('string')\n",
    "acra_data['REGISTRATION_INCORPORATION_DATE'] = pd.to_datetime(acra_data['REGISTRATION_INCORPORATION_DATE'], errors='coerce')\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Clean string columns — trim, remove extra spaces, uppercase\n",
    "# -------------------------------------------------------------\n",
    "for col in [\n",
    "    'UEN',\n",
    "    'ENTITY_NAME',\n",
    "    'BUSINESS_CONSTITUTION_DESCRIPTION',\n",
    "    'ENTITY_TYPE_DESCRIPTION',\n",
    "    'ENTITY_STATUS_DESCRIPTION',\n",
    "    'STREET_NAME',\n",
    "    'POSTAL_CODE'\n",
    "]:\n",
    "    acra_data[col] = (\n",
    "        acra_data[col]\n",
    "        .fillna('')\n",
    "        .str.strip()\n",
    "        .str.replace(r'\\s+', ' ', regex=True)\n",
    "        .str.upper()\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Replace placeholders with NaN for standardization\n",
    "# -------------------------------------------------------------\n",
    "acra_data.replace(['NA', 'N/A', '-', ''], np.nan, inplace=True)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Convert registration date to dd-mm-yyyy string (optional)\n",
    "# -------------------------------------------------------------\n",
    "acra_data['REGISTRATION_INCORPORATION_DATE'] = acra_data['REGISTRATION_INCORPORATION_DATE'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Filter only live entities (LIVE COMPANY or LIVE)\n",
    "# -------------------------------------------------------------\n",
    "acra_data = acra_data[\n",
    "    acra_data['ENTITY_STATUS_DESCRIPTION'].isin(['LIVE COMPANY', 'LIVE'])\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Exclude specific PRIMARY_SSIC_CODE values (supposedly the data would be 600k plus but when we exclude this would lessen)\n",
    "# -------------------------------------------------------------\n",
    "exclude_codes = [\n",
    "    46900, 47719, 47749, 47539, 47536, 56123,\n",
    "    10711, 10712, 10719, 10732, 10733, 93209\n",
    "]\n",
    "\n",
    "acra_data = acra_data[~acra_data['PRIMARY_SSIC_CODE'].isin(exclude_codes)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "37b264bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ENTITY_NAME</th>\n",
       "      <th>BUSINESS_CONSTITUTION_DESCRIPTION</th>\n",
       "      <th>ENTITY_TYPE_DESCRIPTION</th>\n",
       "      <th>ENTITY_STATUS_DESCRIPTION</th>\n",
       "      <th>REGISTRATION_INCORPORATION_DATE</th>\n",
       "      <th>PRIMARY_SSIC_CODE</th>\n",
       "      <th>STREET_NAME</th>\n",
       "      <th>POSTAL_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00182000A</td>\n",
       "      <td>AIK SENG HENG</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>07-02-1975</td>\n",
       "      <td>46302</td>\n",
       "      <td>FISHERY PORT ROAD</td>\n",
       "      <td>619742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00233500W</td>\n",
       "      <td>ASIA STORE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>28-10-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>SIMS AVENUE</td>\n",
       "      <td>387509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00733000J</td>\n",
       "      <td>AIK CHE HIONG</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>02-11-1974</td>\n",
       "      <td>32909</td>\n",
       "      <td>ANG MO KIO INDUSTRIAL PARK 2A</td>\n",
       "      <td>568049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00927000X</td>\n",
       "      <td>A WALIMOHAMED BROS</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>12-11-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>JELLICOE ROAD</td>\n",
       "      <td>208767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01173000E</td>\n",
       "      <td>ANG TECK MOH DEPARTMENT STORE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>30-10-1974</td>\n",
       "      <td>47711</td>\n",
       "      <td>WOODLANDS STREET 12</td>\n",
       "      <td>738623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537323</th>\n",
       "      <td>T25LL0518K</td>\n",
       "      <td>ZEUS BARBERS LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>16-05-2025</td>\n",
       "      <td>96021</td>\n",
       "      <td>KELANTAN LANE</td>\n",
       "      <td>200031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537324</th>\n",
       "      <td>T25LL0858C</td>\n",
       "      <td>ZENSE SPACE LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>01-08-2025</td>\n",
       "      <td>43301</td>\n",
       "      <td>YISHUN INDUSTRIAL STREET 1</td>\n",
       "      <td>768161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537325</th>\n",
       "      <td>T25LL0870A</td>\n",
       "      <td>ZIQZEQ PROCUREMENT LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>04-08-2025</td>\n",
       "      <td>70209</td>\n",
       "      <td>SIN MING LANE</td>\n",
       "      <td>573969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537326</th>\n",
       "      <td>T25LL1049B</td>\n",
       "      <td>ZHONG XIN TRAVEL LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>08-09-2025</td>\n",
       "      <td>79102</td>\n",
       "      <td>JALAN BAHAGIA</td>\n",
       "      <td>320034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537327</th>\n",
       "      <td>T25LL1066B</td>\n",
       "      <td>ZDT DRIVES LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>14-09-2025</td>\n",
       "      <td>47533</td>\n",
       "      <td>FERNVALE ROAD</td>\n",
       "      <td>792466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537328 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               UEN                    ENTITY_NAME  \\\n",
       "0        00182000A                  AIK SENG HENG   \n",
       "1        00233500W                     ASIA STORE   \n",
       "2        00733000J                  AIK CHE HIONG   \n",
       "3        00927000X             A WALIMOHAMED BROS   \n",
       "4        01173000E  ANG TECK MOH DEPARTMENT STORE   \n",
       "...            ...                            ...   \n",
       "537323  T25LL0518K               ZEUS BARBERS LLP   \n",
       "537324  T25LL0858C                ZENSE SPACE LLP   \n",
       "537325  T25LL0870A         ZIQZEQ PROCUREMENT LLP   \n",
       "537326  T25LL1049B           ZHONG XIN TRAVEL LLP   \n",
       "537327  T25LL1066B                 ZDT DRIVES LLP   \n",
       "\n",
       "       BUSINESS_CONSTITUTION_DESCRIPTION           ENTITY_TYPE_DESCRIPTION  \\\n",
       "0                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "1                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "2                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "3                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "4                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "...                                  ...                               ...   \n",
       "537323                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537324                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537325                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537326                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537327                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "\n",
       "       ENTITY_STATUS_DESCRIPTION REGISTRATION_INCORPORATION_DATE  \\\n",
       "0                           LIVE                      07-02-1975   \n",
       "1                           LIVE                      28-10-1974   \n",
       "2                           LIVE                      02-11-1974   \n",
       "3                           LIVE                      12-11-1974   \n",
       "4                           LIVE                      30-10-1974   \n",
       "...                          ...                             ...   \n",
       "537323                      LIVE                      16-05-2025   \n",
       "537324                      LIVE                      01-08-2025   \n",
       "537325                      LIVE                      04-08-2025   \n",
       "537326                      LIVE                      08-09-2025   \n",
       "537327                      LIVE                      14-09-2025   \n",
       "\n",
       "        PRIMARY_SSIC_CODE                    STREET_NAME POSTAL_CODE  \n",
       "0                   46302              FISHERY PORT ROAD      619742  \n",
       "1                   46411                    SIMS AVENUE      387509  \n",
       "2                   32909  ANG MO KIO INDUSTRIAL PARK 2A      568049  \n",
       "3                   46411                  JELLICOE ROAD      208767  \n",
       "4                   47711            WOODLANDS STREET 12      738623  \n",
       "...                   ...                            ...         ...  \n",
       "537323              96021                  KELANTAN LANE      200031  \n",
       "537324              43301     YISHUN INDUSTRIAL STREET 1      768161  \n",
       "537325              70209                  SIN MING LANE      573969  \n",
       "537326              79102                  JALAN BAHAGIA      320034  \n",
       "537327              47533                  FERNVALE ROAD      792466  \n",
       "\n",
       "[537328 rows x 9 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acra_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec969fc",
   "metadata": {},
   "source": [
    "### Getting SSIC Industry code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "32f4bc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARENT_INDUSTRY</th>\n",
       "      <th>INDUSTRY_TYPE</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>SSIC_CODES</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47711</td>\n",
       "      <td>Retail Sale Of Clothing For Adults</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47712</td>\n",
       "      <td>Retail Sale Of Children And Infants' Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47715</td>\n",
       "      <td>Retail Sale Of Sewing And Clothing Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47719</td>\n",
       "      <td>Retail Sale Of Clothing, Footwear And Leather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47510</td>\n",
       "      <td>Retail Sale Of Textiles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PARENT_INDUSTRY INDUSTRY_TYPE       SUB_INDUSTRY  SSIC_CODES  \\\n",
       "0          Retail        Retail  Fashion & Apparel       47711   \n",
       "1          Retail        Retail  Fashion & Apparel       47712   \n",
       "2          Retail        Retail  Fashion & Apparel       47715   \n",
       "3          Retail        Retail  Fashion & Apparel       47719   \n",
       "4          Retail        Retail  Fashion & Apparel       47510   \n",
       "\n",
       "                                         DESCRIPTION  \n",
       "0                 Retail Sale Of Clothing For Adults  \n",
       "1      Retail Sale Of Children And Infants' Clothing  \n",
       "2     Retail Sale Of Sewing And Clothing Accessories  \n",
       "3  Retail Sale Of Clothing, Footwear And Leather ...  \n",
       "4                            Retail Sale Of Textiles  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "file_path = \"./SSIC_Code/mapped_ssic_code.xlsx\"\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "mapped_ssic_code = pd.read_excel(file_path)\n",
    "\n",
    "# --- STANDARDIZE COLUMN NAMES ---\n",
    "# Uppercase, strip spaces, replace spaces with underscores\n",
    "mapped_ssic_code.columns = (\n",
    "    mapped_ssic_code.columns\n",
    "    .str.strip()\n",
    "    .str.upper()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")\n",
    "\n",
    "# --- KEEP ONLY DESIRED COLUMNS ---\n",
    "columns_to_keep = [\"PARENT_INDUSTRY\", \"INDUSTRY_TYPE\", \"SUB_INDUSTRY\", \"SSIC_CODES\", \"DESCRIPTION\"]\n",
    "mapped_ssic_code = mapped_ssic_code[columns_to_keep].copy()\n",
    "\n",
    "# --- CLEAN SSIC_CODES COLUMN ---\n",
    "mapped_ssic_code[\"SSIC_CODES\"] = (\n",
    "    pd.to_numeric(mapped_ssic_code[\"SSIC_CODES\"], errors=\"coerce\")  # safely convert to numeric\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# --- CLEAN TEXT COLUMNS ---\n",
    "text_cols = [\"PARENT_INDUSTRY\", \"INDUSTRY_TYPE\", \"SUB_INDUSTRY\", \"DESCRIPTION\"]\n",
    "mapped_ssic_code[text_cols] = mapped_ssic_code[text_cols].apply(\n",
    "    lambda col: col.astype(str).str.strip().str.title()\n",
    ")\n",
    "\n",
    "# --- REMOVE DUPLICATES & RESET INDEX ---\n",
    "mapped_ssic_code = mapped_ssic_code.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "mapped_ssic_code.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac763a73",
   "metadata": {},
   "source": [
    "### Merge ACRA data with SSIC code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0e62740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PRIMARY_SSIC_CODE to int\n",
    "acra_data[\"PRIMARY_SSIC_CODE\"] = (\n",
    "    pd.to_numeric(acra_data[\"PRIMARY_SSIC_CODE\"], errors=\"coerce\")\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# Merge based on SSIC code\n",
    "acra_data_filtered = acra_data.merge(\n",
    "    mapped_ssic_code,\n",
    "    how=\"left\",\n",
    "    left_on=\"PRIMARY_SSIC_CODE\",\n",
    "    right_on=\"SSIC_CODES\"\n",
    ")\n",
    "\n",
    "# Optional: drop the duplicate 'SSIC CODES' column (keep only PRIMARY_SSIC_CODE)\n",
    "acra_data_filtered = acra_data_filtered.drop(columns=[\"SSIC_CODES\"], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ede8f881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ENTITY_NAME</th>\n",
       "      <th>BUSINESS_CONSTITUTION_DESCRIPTION</th>\n",
       "      <th>ENTITY_TYPE_DESCRIPTION</th>\n",
       "      <th>ENTITY_STATUS_DESCRIPTION</th>\n",
       "      <th>REGISTRATION_INCORPORATION_DATE</th>\n",
       "      <th>PRIMARY_SSIC_CODE</th>\n",
       "      <th>STREET_NAME</th>\n",
       "      <th>POSTAL_CODE</th>\n",
       "      <th>PARENT_INDUSTRY</th>\n",
       "      <th>INDUSTRY_TYPE</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00182000A</td>\n",
       "      <td>AIK SENG HENG</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>07-02-1975</td>\n",
       "      <td>46302</td>\n",
       "      <td>FISHERY PORT ROAD</td>\n",
       "      <td>619742</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Food, Beverages &amp; Tobacco</td>\n",
       "      <td>Wholesale Of Livestock, Meat, Poultry, Eggs An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00233500W</td>\n",
       "      <td>ASIA STORE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>28-10-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>SIMS AVENUE</td>\n",
       "      <td>387509</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Textiles And Leathers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00733000J</td>\n",
       "      <td>AIK CHE HIONG</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>02-11-1974</td>\n",
       "      <td>32909</td>\n",
       "      <td>ANG MO KIO INDUSTRIAL PARK 2A</td>\n",
       "      <td>568049</td>\n",
       "      <td>Others</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Other Specialised Manufacturing &amp; Distribution</td>\n",
       "      <td>Other Manufacturing Industries N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00927000X</td>\n",
       "      <td>A WALIMOHAMED BROS</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>12-11-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>JELLICOE ROAD</td>\n",
       "      <td>208767</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Textiles And Leathers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01173000E</td>\n",
       "      <td>ANG TECK MOH DEPARTMENT STORE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>30-10-1974</td>\n",
       "      <td>47711</td>\n",
       "      <td>WOODLANDS STREET 12</td>\n",
       "      <td>738623</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>Retail Sale Of Clothing For Adults</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537323</th>\n",
       "      <td>T25LL0518K</td>\n",
       "      <td>ZEUS BARBERS LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>16-05-2025</td>\n",
       "      <td>96021</td>\n",
       "      <td>KELANTAN LANE</td>\n",
       "      <td>200031</td>\n",
       "      <td>Services</td>\n",
       "      <td>Services</td>\n",
       "      <td>Hair Salons &amp; Barbershops</td>\n",
       "      <td>Hairdressing Salons/Shops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537324</th>\n",
       "      <td>T25LL0858C</td>\n",
       "      <td>ZENSE SPACE LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>01-08-2025</td>\n",
       "      <td>43301</td>\n",
       "      <td>YISHUN INDUSTRIAL STREET 1</td>\n",
       "      <td>768161</td>\n",
       "      <td>Others</td>\n",
       "      <td>Built Environment &amp; Infrastructure</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Renovation Contractors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537325</th>\n",
       "      <td>T25LL0870A</td>\n",
       "      <td>ZIQZEQ PROCUREMENT LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>04-08-2025</td>\n",
       "      <td>70209</td>\n",
       "      <td>SIN MING LANE</td>\n",
       "      <td>573969</td>\n",
       "      <td>Others</td>\n",
       "      <td>Finance, Legal &amp; Real Estate</td>\n",
       "      <td>Legal, Accounting &amp; Consultancy Activities</td>\n",
       "      <td>Management Consultancy Services N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537326</th>\n",
       "      <td>T25LL1049B</td>\n",
       "      <td>ZHONG XIN TRAVEL LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>08-09-2025</td>\n",
       "      <td>79102</td>\n",
       "      <td>JALAN BAHAGIA</td>\n",
       "      <td>320034</td>\n",
       "      <td>Others</td>\n",
       "      <td>Tourism, Agency</td>\n",
       "      <td>Travel Agencies &amp; Tour Operators</td>\n",
       "      <td>Travel Agencies And Tour Operators (Mainly Out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537327</th>\n",
       "      <td>T25LL1066B</td>\n",
       "      <td>ZDT DRIVES LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>14-09-2025</td>\n",
       "      <td>47533</td>\n",
       "      <td>FERNVALE ROAD</td>\n",
       "      <td>792466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537328 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               UEN                    ENTITY_NAME  \\\n",
       "0        00182000A                  AIK SENG HENG   \n",
       "1        00233500W                     ASIA STORE   \n",
       "2        00733000J                  AIK CHE HIONG   \n",
       "3        00927000X             A WALIMOHAMED BROS   \n",
       "4        01173000E  ANG TECK MOH DEPARTMENT STORE   \n",
       "...            ...                            ...   \n",
       "537323  T25LL0518K               ZEUS BARBERS LLP   \n",
       "537324  T25LL0858C                ZENSE SPACE LLP   \n",
       "537325  T25LL0870A         ZIQZEQ PROCUREMENT LLP   \n",
       "537326  T25LL1049B           ZHONG XIN TRAVEL LLP   \n",
       "537327  T25LL1066B                 ZDT DRIVES LLP   \n",
       "\n",
       "       BUSINESS_CONSTITUTION_DESCRIPTION           ENTITY_TYPE_DESCRIPTION  \\\n",
       "0                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "1                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "2                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "3                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "4                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "...                                  ...                               ...   \n",
       "537323                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537324                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537325                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537326                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537327                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "\n",
       "       ENTITY_STATUS_DESCRIPTION REGISTRATION_INCORPORATION_DATE  \\\n",
       "0                           LIVE                      07-02-1975   \n",
       "1                           LIVE                      28-10-1974   \n",
       "2                           LIVE                      02-11-1974   \n",
       "3                           LIVE                      12-11-1974   \n",
       "4                           LIVE                      30-10-1974   \n",
       "...                          ...                             ...   \n",
       "537323                      LIVE                      16-05-2025   \n",
       "537324                      LIVE                      01-08-2025   \n",
       "537325                      LIVE                      04-08-2025   \n",
       "537326                      LIVE                      08-09-2025   \n",
       "537327                      LIVE                      14-09-2025   \n",
       "\n",
       "        PRIMARY_SSIC_CODE                    STREET_NAME POSTAL_CODE  \\\n",
       "0                   46302              FISHERY PORT ROAD      619742   \n",
       "1                   46411                    SIMS AVENUE      387509   \n",
       "2                   32909  ANG MO KIO INDUSTRIAL PARK 2A      568049   \n",
       "3                   46411                  JELLICOE ROAD      208767   \n",
       "4                   47711            WOODLANDS STREET 12      738623   \n",
       "...                   ...                            ...         ...   \n",
       "537323              96021                  KELANTAN LANE      200031   \n",
       "537324              43301     YISHUN INDUSTRIAL STREET 1      768161   \n",
       "537325              70209                  SIN MING LANE      573969   \n",
       "537326              79102                  JALAN BAHAGIA      320034   \n",
       "537327              47533                  FERNVALE ROAD      792466   \n",
       "\n",
       "       PARENT_INDUSTRY                       INDUSTRY_TYPE  \\\n",
       "0               Others                     Wholesale Trade   \n",
       "1               Others                     Wholesale Trade   \n",
       "2               Others                       Manufacturing   \n",
       "3               Others                     Wholesale Trade   \n",
       "4               Retail                              Retail   \n",
       "...                ...                                 ...   \n",
       "537323        Services                            Services   \n",
       "537324          Others  Built Environment & Infrastructure   \n",
       "537325          Others        Finance, Legal & Real Estate   \n",
       "537326          Others                     Tourism, Agency   \n",
       "537327             NaN                                 NaN   \n",
       "\n",
       "                                          SUB_INDUSTRY  \\\n",
       "0                            Food, Beverages & Tobacco   \n",
       "1                                      Household Goods   \n",
       "2       Other Specialised Manufacturing & Distribution   \n",
       "3                                      Household Goods   \n",
       "4                                    Fashion & Apparel   \n",
       "...                                                ...   \n",
       "537323                       Hair Salons & Barbershops   \n",
       "537324                                    Construction   \n",
       "537325      Legal, Accounting & Consultancy Activities   \n",
       "537326                Travel Agencies & Tour Operators   \n",
       "537327                                             NaN   \n",
       "\n",
       "                                              DESCRIPTION  \n",
       "0       Wholesale Of Livestock, Meat, Poultry, Eggs An...  \n",
       "1                      Wholesale Of Textiles And Leathers  \n",
       "2                   Other Manufacturing Industries N.E.C.  \n",
       "3                      Wholesale Of Textiles And Leathers  \n",
       "4                      Retail Sale Of Clothing For Adults  \n",
       "...                                                   ...  \n",
       "537323                          Hairdressing Salons/Shops  \n",
       "537324                             Renovation Contractors  \n",
       "537325             Management Consultancy Services N.E.C.  \n",
       "537326  Travel Agencies And Tour Operators (Mainly Out...  \n",
       "537327                                                NaN  \n",
       "\n",
       "[537328 rows x 13 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acra_data_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9289e8b3",
   "metadata": {},
   "source": [
    "### FIlter Acra data with Master DB to get list of companies havent been researched  by MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2c28478d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533824, 13)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Ensure both UEN columns are strings for accurate matching\n",
    "acra_data_filtered['UEN'] = acra_data_filtered['UEN'].astype(str).str.strip().str.upper()\n",
    "master_db_df['UEN'] = master_db_df['UEN'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Filter out rows in acra_data_filtered whose UEN is already in master_db_df\n",
    "acra_data_filtered = acra_data_filtered[~acra_data_filtered['UEN'].isin(master_db_df['UEN'])]\n",
    "\n",
    "acra_data_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd24ab",
   "metadata": {},
   "source": [
    "### Filter by  Industry (Tuition/training service/child care)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aa058f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ENTITY_NAME</th>\n",
       "      <th>BUSINESS_CONSTITUTION_DESCRIPTION</th>\n",
       "      <th>ENTITY_TYPE_DESCRIPTION</th>\n",
       "      <th>ENTITY_STATUS_DESCRIPTION</th>\n",
       "      <th>REGISTRATION_INCORPORATION_DATE</th>\n",
       "      <th>PRIMARY_SSIC_CODE</th>\n",
       "      <th>STREET_NAME</th>\n",
       "      <th>POSTAL_CODE</th>\n",
       "      <th>PARENT_INDUSTRY</th>\n",
       "      <th>INDUSTRY_TYPE</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>198900817R</td>\n",
       "      <td>ALPHABET PLAYHOUSE CHILD CARE AND LEARNING CEN...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>02-03-1989</td>\n",
       "      <td>88911</td>\n",
       "      <td>SAM LEONG ROAD</td>\n",
       "      <td>207922</td>\n",
       "      <td>Others</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Social Services (Without Accommodations)</td>\n",
       "      <td>Infant Care Services; Child Minding Services F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>199004029M</td>\n",
       "      <td>ACEWORLD HOLDINGS PTE LTD</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>17-08-1990</td>\n",
       "      <td>88911</td>\n",
       "      <td>SIAN TUAN AVENUE</td>\n",
       "      <td>588270</td>\n",
       "      <td>Others</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Social Services (Without Accommodations)</td>\n",
       "      <td>Infant Care Services; Child Minding Services F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>199102118N</td>\n",
       "      <td>AVERBEL CHILD DEVELOPMENT CENTRE PTE LTD</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>09-05-1991</td>\n",
       "      <td>88911</td>\n",
       "      <td>YISHUN AVENUE 5</td>\n",
       "      <td>760742</td>\n",
       "      <td>Others</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Social Services (Without Accommodations)</td>\n",
       "      <td>Infant Care Services; Child Minding Services F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>199609311Z</td>\n",
       "      <td>ALBERTON MANAGEMENT INSTITUTE PTE. LTD.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>28-12-1996</td>\n",
       "      <td>85501</td>\n",
       "      <td>SIN MING LANE</td>\n",
       "      <td>573969</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Industry-Specific Vocational &amp; Professional Tr...</td>\n",
       "      <td>Training Courses For Construction, Real Estate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>199901279H</td>\n",
       "      <td>AAYTOZEE @ HILLVIEW PTE. LTD.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>17-03-1999</td>\n",
       "      <td>88911</td>\n",
       "      <td>JALAN DERMAWAN</td>\n",
       "      <td>668947</td>\n",
       "      <td>Others</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Social Services (Without Accommodations)</td>\n",
       "      <td>Infant Care Services; Child Minding Services F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537047</th>\n",
       "      <td>53497327B</td>\n",
       "      <td>ZYNTELLECT ADVISORY</td>\n",
       "      <td>SOLE-PROPRIETOR</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>07-01-2025</td>\n",
       "      <td>85509</td>\n",
       "      <td>CHESTNUT AVENUE</td>\n",
       "      <td>679524</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537084</th>\n",
       "      <td>53501816M</td>\n",
       "      <td>ZAVIER TUITION SERVICES</td>\n",
       "      <td>SOLE-PROPRIETOR</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>28-03-2025</td>\n",
       "      <td>85509</td>\n",
       "      <td>UPPER THOMSON ROAD</td>\n",
       "      <td>574364</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537208</th>\n",
       "      <td>T10LL0717A</td>\n",
       "      <td>ZEUS COMMUNICATIONS LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>27-04-2010</td>\n",
       "      <td>96094</td>\n",
       "      <td>UPPER THOMSON ROAD</td>\n",
       "      <td>574329</td>\n",
       "      <td>Services</td>\n",
       "      <td>Services</td>\n",
       "      <td>Other Personal Service Activities</td>\n",
       "      <td>Training Of Pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537226</th>\n",
       "      <td>T13LL0369C</td>\n",
       "      <td>ZEUS TALK LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>03-03-2013</td>\n",
       "      <td>96094</td>\n",
       "      <td>UPPER THOMSON ROAD</td>\n",
       "      <td>574329</td>\n",
       "      <td>Services</td>\n",
       "      <td>Services</td>\n",
       "      <td>Other Personal Service Activities</td>\n",
       "      <td>Training Of Pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537314</th>\n",
       "      <td>T24LL0738H</td>\n",
       "      <td>ZURA TECHNOLOGIES LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>01-07-2024</td>\n",
       "      <td>85509</td>\n",
       "      <td>CHOA CHU KANG LOOP</td>\n",
       "      <td>689686</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6764 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               UEN                                        ENTITY_NAME  \\\n",
       "859     198900817R  ALPHABET PLAYHOUSE CHILD CARE AND LEARNING CEN...   \n",
       "983     199004029M                          ACEWORLD HOLDINGS PTE LTD   \n",
       "1040    199102118N           AVERBEL CHILD DEVELOPMENT CENTRE PTE LTD   \n",
       "1786    199609311Z            ALBERTON MANAGEMENT INSTITUTE PTE. LTD.   \n",
       "2090    199901279H                      AAYTOZEE @ HILLVIEW PTE. LTD.   \n",
       "...            ...                                                ...   \n",
       "537047   53497327B                                ZYNTELLECT ADVISORY   \n",
       "537084   53501816M                            ZAVIER TUITION SERVICES   \n",
       "537208  T10LL0717A                            ZEUS COMMUNICATIONS LLP   \n",
       "537226  T13LL0369C                                      ZEUS TALK LLP   \n",
       "537314  T24LL0738H                              ZURA TECHNOLOGIES LLP   \n",
       "\n",
       "       BUSINESS_CONSTITUTION_DESCRIPTION           ENTITY_TYPE_DESCRIPTION  \\\n",
       "859                                 <NA>                     LOCAL COMPANY   \n",
       "983                                 <NA>                     LOCAL COMPANY   \n",
       "1040                                <NA>                     LOCAL COMPANY   \n",
       "1786                                <NA>                     LOCAL COMPANY   \n",
       "2090                                <NA>                     LOCAL COMPANY   \n",
       "...                                  ...                               ...   \n",
       "537047                   SOLE-PROPRIETOR  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "537084                   SOLE-PROPRIETOR  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "537208                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537226                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537314                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "\n",
       "       ENTITY_STATUS_DESCRIPTION REGISTRATION_INCORPORATION_DATE  \\\n",
       "859                 LIVE COMPANY                      02-03-1989   \n",
       "983                 LIVE COMPANY                      17-08-1990   \n",
       "1040                LIVE COMPANY                      09-05-1991   \n",
       "1786                LIVE COMPANY                      28-12-1996   \n",
       "2090                LIVE COMPANY                      17-03-1999   \n",
       "...                          ...                             ...   \n",
       "537047                      LIVE                      07-01-2025   \n",
       "537084                      LIVE                      28-03-2025   \n",
       "537208                      LIVE                      27-04-2010   \n",
       "537226                      LIVE                      03-03-2013   \n",
       "537314                      LIVE                      01-07-2024   \n",
       "\n",
       "        PRIMARY_SSIC_CODE         STREET_NAME POSTAL_CODE PARENT_INDUSTRY  \\\n",
       "859                 88911      SAM LEONG ROAD      207922          Others   \n",
       "983                 88911    SIAN TUAN AVENUE      588270          Others   \n",
       "1040                88911     YISHUN AVENUE 5      760742          Others   \n",
       "1786                85501       SIN MING LANE      573969          Others   \n",
       "2090                88911      JALAN DERMAWAN      668947          Others   \n",
       "...                   ...                 ...         ...             ...   \n",
       "537047              85509     CHESTNUT AVENUE      679524          Others   \n",
       "537084              85509  UPPER THOMSON ROAD      574364          Others   \n",
       "537208              96094  UPPER THOMSON ROAD      574329        Services   \n",
       "537226              96094  UPPER THOMSON ROAD      574329        Services   \n",
       "537314              85509  CHOA CHU KANG LOOP      689686          Others   \n",
       "\n",
       "       INDUSTRY_TYPE                                       SUB_INDUSTRY  \\\n",
       "859         Hospital           Social Services (Without Accommodations)   \n",
       "983         Hospital           Social Services (Without Accommodations)   \n",
       "1040        Hospital           Social Services (Without Accommodations)   \n",
       "1786     Educational  Industry-Specific Vocational & Professional Tr...   \n",
       "2090        Hospital           Social Services (Without Accommodations)   \n",
       "...              ...                                                ...   \n",
       "537047   Educational                       Tuition & Enrichment Centers   \n",
       "537084   Educational                       Tuition & Enrichment Centers   \n",
       "537208      Services                  Other Personal Service Activities   \n",
       "537226      Services                  Other Personal Service Activities   \n",
       "537314   Educational                       Tuition & Enrichment Centers   \n",
       "\n",
       "                                              DESCRIPTION  \n",
       "859     Infant Care Services; Child Minding Services F...  \n",
       "983     Infant Care Services; Child Minding Services F...  \n",
       "1040    Infant Care Services; Child Minding Services F...  \n",
       "1786    Training Courses For Construction, Real Estate...  \n",
       "2090    Infant Care Services; Child Minding Services F...  \n",
       "...                                                   ...  \n",
       "537047                            Training Courses N.E.C.  \n",
       "537084                            Training Courses N.E.C.  \n",
       "537208                                   Training Of Pets  \n",
       "537226                                   Training Of Pets  \n",
       "537314                            Training Courses N.E.C.  \n",
       "\n",
       "[6764 rows x 13 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wholesale data\n",
    "ssic_codes = [\n",
    "    \"85332\",\"8536\",\"85360\",\"85403\",\"85404\",\"855\",\"8550\",\"85501\",\"85502\",\n",
    "    \"85503\",\"85504\",\"85505\",\"85506\",\"85507\",\"85508\",\"85509\",\"856\",\"8560\",\n",
    "    \"85601\",\"85602\",\"85609\",\"87022\",\"8891\",\"88911\",\"88912\",\"88991\",\"96094\"\n",
    "]\n",
    "\n",
    "\n",
    "acra_data_filtered_by_industry = acra_data_filtered[\n",
    "    (\n",
    "        (acra_data_filtered[\"ENTITY_STATUS_DESCRIPTION\"].str.lower() == \"live\") |\n",
    "        (acra_data_filtered[\"ENTITY_STATUS_DESCRIPTION\"].str.lower() == \"live company\")\n",
    "    )\n",
    "    &\n",
    "    (acra_data_filtered[\"PRIMARY_SSIC_CODE\"].astype(str).isin(ssic_codes))\n",
    "]\n",
    "\n",
    "\n",
    "acra_data_filtered_by_industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6edf012",
   "metadata": {},
   "source": [
    "### Filter with Fresh Leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "87dc3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Copy to avoid SettingWithCopyWarning ---\n",
    "# acra_data_filtered_wholesale = acra_data_filtered_wholesale.copy()\n",
    "\n",
    "# # --- UPDATE HERE: Remove rows if UEN exists in recordowl_results.xlsx ---\n",
    "# recordowl_results = pd.read_excel(\"Fresh_Leads.xlsx\")\n",
    "# # Ensure both dataframes have a 'UEN' column\n",
    "# if \"UEN\" in recordowl_results.columns and \"UEN\" in acra_data_filtered_wholesale.columns:\n",
    "#     filtered = acra_data_filtered_wholesale[~acra_data_filtered_wholesale[\"UEN\"].isin(recordowl_results[\"UEN\"])]\n",
    "# else:\n",
    "#     raise ValueError(\"Column 'UEN' not found in one of the dataframes.\")\n",
    "\n",
    "# # sample data \n",
    "# acra_data_filtered_wholesale = filtered.sample(n=50, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# acra_data_filtered_wholesale.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b530343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# acra_data_filtered_wholesale = pd.DataFrame({\n",
    "#     \"UEN\": [\"201625008K\"]\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a6f2b7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ENTITY_NAME</th>\n",
       "      <th>BUSINESS_CONSTITUTION_DESCRIPTION</th>\n",
       "      <th>ENTITY_TYPE_DESCRIPTION</th>\n",
       "      <th>ENTITY_STATUS_DESCRIPTION</th>\n",
       "      <th>REGISTRATION_INCORPORATION_DATE</th>\n",
       "      <th>PRIMARY_SSIC_CODE</th>\n",
       "      <th>STREET_NAME</th>\n",
       "      <th>POSTAL_CODE</th>\n",
       "      <th>PARENT_INDUSTRY</th>\n",
       "      <th>INDUSTRY_TYPE</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202527176G</td>\n",
       "      <td>T &amp; S ASPIRE PTE. LTD.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>24-06-2025</td>\n",
       "      <td>88912</td>\n",
       "      <td>LAVENDER STREET</td>\n",
       "      <td>338729</td>\n",
       "      <td>Others</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Social Services (Without Accommodations)</td>\n",
       "      <td>Student Care Services; Child Minding Services ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53462945L</td>\n",
       "      <td>REVISION BUDDY EDUTECH</td>\n",
       "      <td>SOLE-PROPRIETOR</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>14-02-2023</td>\n",
       "      <td>85509</td>\n",
       "      <td>NEW BRIDGE ROAD</td>\n",
       "      <td>059413</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53414477B</td>\n",
       "      <td>KUTTIES CHUTTIES</td>\n",
       "      <td>SOLE-PROPRIETOR</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>05-06-2020</td>\n",
       "      <td>85509</td>\n",
       "      <td>TAMPINES AVENUE 9</td>\n",
       "      <td>524601</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202409709K</td>\n",
       "      <td>HO KAANG INTERNATIONAL EDUCATION &amp; CONSULTANCY...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>12-03-2024</td>\n",
       "      <td>85509</td>\n",
       "      <td>TEMASEK BOULEVARD</td>\n",
       "      <td>038987</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53502930J</td>\n",
       "      <td>AVERIE PLAYHOUSE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>22-04-2025</td>\n",
       "      <td>88911</td>\n",
       "      <td>YISHUN AVENUE 11</td>\n",
       "      <td>760417</td>\n",
       "      <td>Others</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Social Services (Without Accommodations)</td>\n",
       "      <td>Infant Care Services; Child Minding Services F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202210514D</td>\n",
       "      <td>KEYPATH EDUCATION SINGAPORE PTE. LTD.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>28-03-2022</td>\n",
       "      <td>85509</td>\n",
       "      <td>STRAITS VIEW</td>\n",
       "      <td>18937</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53459592L</td>\n",
       "      <td>CREATIVE CAMPUS (EAST)</td>\n",
       "      <td>SOLE-PROPRIETOR</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>01-12-2022</td>\n",
       "      <td>85509</td>\n",
       "      <td>MARINE PARADE ROAD</td>\n",
       "      <td>449269</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202016352N</td>\n",
       "      <td>LEARN WITH US PTE. LTD.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>11-06-2020</td>\n",
       "      <td>85509</td>\n",
       "      <td>ANG MO KIO INDUSTRIAL PARK 2A</td>\n",
       "      <td>567760</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>201418890W</td>\n",
       "      <td>LERUS ASIA PTE. LTD.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>30-06-2014</td>\n",
       "      <td>88991</td>\n",
       "      <td>UBI CRESCENT</td>\n",
       "      <td>408568</td>\n",
       "      <td>Others</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Social Services (Without Accommodations)</td>\n",
       "      <td>Job Training And Vocational Rehabilitation Ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>201109789R</td>\n",
       "      <td>'X-FACTOR'! QUOTIENT PTE. LTD.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>25-04-2011</td>\n",
       "      <td>85509</td>\n",
       "      <td>UPPER THOMSON ROAD</td>\n",
       "      <td>574424</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          UEN                                        ENTITY_NAME  \\\n",
       "0  202527176G                             T & S ASPIRE PTE. LTD.   \n",
       "1   53462945L                             REVISION BUDDY EDUTECH   \n",
       "2   53414477B                                   KUTTIES CHUTTIES   \n",
       "3  202409709K  HO KAANG INTERNATIONAL EDUCATION & CONSULTANCY...   \n",
       "4   53502930J                                   AVERIE PLAYHOUSE   \n",
       "5  202210514D              KEYPATH EDUCATION SINGAPORE PTE. LTD.   \n",
       "6   53459592L                             CREATIVE CAMPUS (EAST)   \n",
       "7  202016352N                            LEARN WITH US PTE. LTD.   \n",
       "8  201418890W                               LERUS ASIA PTE. LTD.   \n",
       "9  201109789R                     'X-FACTOR'! QUOTIENT PTE. LTD.   \n",
       "\n",
       "  BUSINESS_CONSTITUTION_DESCRIPTION           ENTITY_TYPE_DESCRIPTION  \\\n",
       "0                              <NA>                     LOCAL COMPANY   \n",
       "1                   SOLE-PROPRIETOR  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "2                   SOLE-PROPRIETOR  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "3                              <NA>                     LOCAL COMPANY   \n",
       "4                       PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "5                              <NA>                     LOCAL COMPANY   \n",
       "6                   SOLE-PROPRIETOR  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "7                              <NA>                     LOCAL COMPANY   \n",
       "8                              <NA>                     LOCAL COMPANY   \n",
       "9                              <NA>                     LOCAL COMPANY   \n",
       "\n",
       "  ENTITY_STATUS_DESCRIPTION REGISTRATION_INCORPORATION_DATE  \\\n",
       "0              LIVE COMPANY                      24-06-2025   \n",
       "1                      LIVE                      14-02-2023   \n",
       "2                      LIVE                      05-06-2020   \n",
       "3              LIVE COMPANY                      12-03-2024   \n",
       "4                      LIVE                      22-04-2025   \n",
       "5              LIVE COMPANY                      28-03-2022   \n",
       "6                      LIVE                      01-12-2022   \n",
       "7              LIVE COMPANY                      11-06-2020   \n",
       "8              LIVE COMPANY                      30-06-2014   \n",
       "9              LIVE COMPANY                      25-04-2011   \n",
       "\n",
       "   PRIMARY_SSIC_CODE                    STREET_NAME POSTAL_CODE  \\\n",
       "0              88912                LAVENDER STREET      338729   \n",
       "1              85509                NEW BRIDGE ROAD      059413   \n",
       "2              85509              TAMPINES AVENUE 9      524601   \n",
       "3              85509              TEMASEK BOULEVARD      038987   \n",
       "4              88911               YISHUN AVENUE 11      760417   \n",
       "5              85509                   STRAITS VIEW       18937   \n",
       "6              85509             MARINE PARADE ROAD      449269   \n",
       "7              85509  ANG MO KIO INDUSTRIAL PARK 2A      567760   \n",
       "8              88991                   UBI CRESCENT      408568   \n",
       "9              85509             UPPER THOMSON ROAD      574424   \n",
       "\n",
       "  PARENT_INDUSTRY INDUSTRY_TYPE                              SUB_INDUSTRY  \\\n",
       "0          Others      Hospital  Social Services (Without Accommodations)   \n",
       "1          Others   Educational              Tuition & Enrichment Centers   \n",
       "2          Others   Educational              Tuition & Enrichment Centers   \n",
       "3          Others   Educational              Tuition & Enrichment Centers   \n",
       "4          Others      Hospital  Social Services (Without Accommodations)   \n",
       "5          Others   Educational              Tuition & Enrichment Centers   \n",
       "6          Others   Educational              Tuition & Enrichment Centers   \n",
       "7          Others   Educational              Tuition & Enrichment Centers   \n",
       "8          Others      Hospital  Social Services (Without Accommodations)   \n",
       "9          Others   Educational              Tuition & Enrichment Centers   \n",
       "\n",
       "                                         DESCRIPTION  \n",
       "0  Student Care Services; Child Minding Services ...  \n",
       "1                            Training Courses N.E.C.  \n",
       "2                            Training Courses N.E.C.  \n",
       "3                            Training Courses N.E.C.  \n",
       "4  Infant Care Services; Child Minding Services F...  \n",
       "5                            Training Courses N.E.C.  \n",
       "6                            Training Courses N.E.C.  \n",
       "7                            Training Courses N.E.C.  \n",
       "8  Job Training And Vocational Rehabilitation Ser...  \n",
       "9                            Training Courses N.E.C.  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data \n",
    "acra_data_filtered_pilot = acra_data_filtered_by_industry.sample(n=10, random_state=42).reset_index(drop=True)\n",
    "\n",
    "acra_data_filtered_pilot.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040bb97",
   "metadata": {},
   "source": [
    "### Get Data from RecordOwl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3cd46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Processing 202527176G (1/10)\n",
      "  📡 Starting Apify run for 202527176G (attempt 1/5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> 2025-11-06T05:18:55.773Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> 2025-11-06T05:18:55.782Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> 2025-11-06T05:18:55.813Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> 2025-11-06T05:18:56.000Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> 2025-11-06T05:18:57.373Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> 2025-11-06T05:18:57.493Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> 2025-11-06T05:18:58.284Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> 2025-11-06T05:18:58.363Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> 2025-11-06T05:19:05.684Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Detected a session error, rotating session...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> 2025-11-06T05:19:05.685Z net::ERR_TUNNEL_CONNECTION_FAILED at https://recordowl.com/\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> 2025-11-06T05:19:05.687Z\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> 2025-11-06T05:19:05.689Z \u001b[90m {\"id\":\"XsOj8IqwoXyWgRx\",\"url\":\"https://recordowl.com/\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> 2025-11-06T05:19:18.757Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Visiting RecordOwl for UEN: 202527176G\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> 2025-11-06T05:19:52.838Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:jiDkDRdgLfbqQP0Ky]\u001b[0m -> Status: SUCCEEDED, Message: Finished! Total 1 requests: 1 succeeded, 0 failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ❌ Apify call failed for 202527176G: Apify call failed: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "🔎 Processing 53462945L (2/10)\n",
      "  📡 Starting Apify run for 53462945L (attempt 1/5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> 2025-11-06T05:20:09.307Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> 2025-11-06T05:20:09.312Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> 2025-11-06T05:20:11.835Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> 2025-11-06T05:20:12.362Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> 2025-11-06T05:20:13.282Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> 2025-11-06T05:20:13.530Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> 2025-11-06T05:20:14.237Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> 2025-11-06T05:20:14.379Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> 2025-11-06T05:20:23.878Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Visiting RecordOwl for UEN: 53462945L\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> 2025-11-06T05:20:39.404Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> 2025-11-06T05:20:39.728Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":1,\"requestsFailed\":0,\"retryHistogram\":[1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":24719,\"requestsFinishedPerMinute\":2,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":24719,\"requestsTotal\":1,\"crawlerRuntimeMillis\":25582}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> 2025-11-06T05:20:39.739Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Finished! Total 1 requests: 1 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> Status: RUNNING, Message: Finished! Total 1 requests: 1 succeeded, 0 failed.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hVxDYcusXZYqzY0Qb]\u001b[0m -> 2025-11-06T05:20:39.750Z \u001b[32mINFO\u001b[39m  Puppeteer Scraper finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ⏳ Waiting for run to complete...\n",
      "  ✅ Run succeeded with data\n",
      "  ⏳ Waiting for dataset to be ready...\n",
      "  📊 Dataset has 1 item(s)\n",
      "  ✅ Successfully scraped 53462945L (1473254 chars of HTML)\n",
      "  🔍 Searching for phone numbers...\n",
      "  📋 Found 19 dt tags\n",
      "  🔎 No phones found yet, searching entire content...\n",
      "  ⚠️ WARNING: No phone numbers found for 53462945L\n",
      "  📄 Showing first 500 chars of parent HTML for debugging:\n",
      "<div class=\"max-w-7xl mx-auto lg:py-6 sm:px-6 lg:px-8\" style=\"height: auto !important;\">\n",
      " <div class=\"flex flex-col lg:flex-row\" style=\"height: auto !important;\">\n",
      "  <div class=\"w-full lg:w-2/3 lg:pr-8\" style=\"height: auto !important;\">\n",
      "   <div class=\"lg:mb-4 border-b border-gray-200\">\n",
      "    <ul class=\"flex flex-nowrap overflow-x-auto -mb-px text-sm font-medium text-center scrollbar-hide\" id=\"companyTabs\" role=\"tablist\">\n",
      "     <li class=\"mr-2\" role=\"presentation\">\n",
      "      <button aria-controls=\"overvi...\n",
      "  ✅ Processed 53462945L: 0 emails, 0 phones\n",
      "  💤 Sleeping for 27s before next request...\n",
      "\n",
      "🔎 Processing 53414477B (3/10)\n",
      "  📡 Starting Apify run for 53414477B (attempt 1/5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:fLsA6DNaZ5RUe5wLQ]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:fLsA6DNaZ5RUe5wLQ]\u001b[0m -> 2025-11-06T05:21:22.901Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fLsA6DNaZ5RUe5wLQ]\u001b[0m -> 2025-11-06T05:21:22.903Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fLsA6DNaZ5RUe5wLQ]\u001b[0m -> 2025-11-06T05:21:23.034Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fLsA6DNaZ5RUe5wLQ]\u001b[0m -> 2025-11-06T05:21:23.405Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fLsA6DNaZ5RUe5wLQ]\u001b[0m -> 2025-11-06T05:21:24.212Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fLsA6DNaZ5RUe5wLQ]\u001b[0m -> 2025-11-06T05:21:24.344Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fLsA6DNaZ5RUe5wLQ]\u001b[0m -> 2025-11-06T05:21:24.939Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fLsA6DNaZ5RUe5wLQ]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fLsA6DNaZ5RUe5wLQ]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fLsA6DNaZ5RUe5wLQ]\u001b[0m -> 2025-11-06T05:21:25.054Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "client = ApifyClient(\"apify_api_yNR85etaHpLtBzPoVozVVXUsCZe54u2Ffog1\")\n",
    "\n",
    "SOCIAL_MEDIA_DOMAINS = [\n",
    "    \"facebook.com\", \"linkedin.com\", \"instagram.com\", \"youtube.com\",\n",
    "    \"tiktok.com\", \"twitter.com\", \"x.com\", \"pinterest.com\"\n",
    "]\n",
    "\n",
    "def fetch_dataset_items_safe(dataset_client, max_retries=5, initial_wait=3):\n",
    "    \"\"\"Safely fetch dataset items with multiple retry strategies.\"\"\"\n",
    "    dataset_items = []\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Strategy 1: Try using iterate_items() (streaming)\n",
    "            try:\n",
    "                dataset_items = list(dataset_client.iterate_items())\n",
    "                if dataset_items:\n",
    "                    return dataset_items\n",
    "            except (HTTPError, ConnectionError, ProtocolError, Exception) as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = initial_wait * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"  ⚠️ Iteration method failed (attempt {attempt + 1}/{max_retries}), trying direct fetch in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  ⚠️ Iteration method failed after all retries, trying direct fetch...\")\n",
    "            \n",
    "            # Strategy 2: Try using list_items() (direct pagination)\n",
    "            try:\n",
    "                offset = 0\n",
    "                limit = 100\n",
    "                while True:\n",
    "                    page = dataset_client.list_items(offset=offset, limit=limit, clean=True)\n",
    "                    if not page.items:\n",
    "                        break\n",
    "                    dataset_items.extend(page.items)\n",
    "                    if len(page.items) < limit:\n",
    "                        break\n",
    "                    offset += limit\n",
    "                \n",
    "                if dataset_items:\n",
    "                    return dataset_items\n",
    "            except (HTTPError, ConnectionError, ProtocolError, Exception) as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = initial_wait * (2 ** attempt)\n",
    "                    print(f\"  ⚠️ Direct fetch failed (attempt {attempt + 1}/{max_retries}), retrying in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  ❌ All fetch methods failed: {e}\")\n",
    "                    return []\n",
    "                    \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = initial_wait * (2 ** attempt)\n",
    "                print(f\"  ⚠️ Unexpected error (attempt {attempt + 1}/{max_retries}), retrying in {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"  ❌ Failed after all retries: {e}\")\n",
    "                return []\n",
    "    \n",
    "    return dataset_items\n",
    "\n",
    "def run_apify_with_retry(client, run_input, uen, max_retries=3):\n",
    "    \"\"\"Run Apify with exponential backoff on 403 errors AND verify dataset has items.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"  📡 Starting Apify run for {uen} (attempt {attempt + 1}/{max_retries})...\")\n",
    "            run = client.actor(\"apify/puppeteer-scraper\").call(run_input=run_input)\n",
    "            \n",
    "            print(f\"  ⏳ Waiting for run to complete...\")\n",
    "            run_client = client.run(run[\"id\"])\n",
    "            run_info = run_client.wait_for_finish()\n",
    "            \n",
    "            # CRITICAL FIX: Check if run actually scraped pages, not just if it \"succeeded\"\n",
    "            if run_info and \"status\" in run_info:\n",
    "                status = run_info.get(\"status\")\n",
    "                \n",
    "                # Even if status is \"SUCCEEDED\", verify dataset actually has items\n",
    "                if status == \"SUCCEEDED\" and \"defaultDatasetId\" in run:\n",
    "                    # Quick check if dataset has any items\n",
    "                    try:\n",
    "                        dataset_check = client.dataset(run[\"defaultDatasetId\"])\n",
    "                        time.sleep(2)  # Brief wait for dataset to be ready\n",
    "                        test_items = dataset_check.list_items(limit=1, clean=True)\n",
    "                        \n",
    "                        if test_items.items and len(test_items.items) > 0:\n",
    "                            # Dataset has items - true success!\n",
    "                            print(f\"  ✅ Run succeeded with data\")\n",
    "                            return run, None\n",
    "                        else:\n",
    "                            # Status says \"SUCCEEDED\" but dataset is EMPTY - this is a failure!\n",
    "                            print(f\"  ⚠️ Run completed but dataset is empty (likely 403 block)\")\n",
    "                            # Treat as 403 and retry\n",
    "                            if attempt < max_retries - 1:\n",
    "                                wait_time = 30 * (2 ** attempt)\n",
    "                                print(f\"  🔄 Retrying in {wait_time}s...\")\n",
    "                                time.sleep(wait_time)\n",
    "                                continue\n",
    "                            else:\n",
    "                                return None, \"Dataset empty after all retries (403 blocking)\"\n",
    "                    except Exception as e:\n",
    "                        print(f\"  ⚠️ Could not verify dataset: {e}\")\n",
    "                        # If we can't check dataset, try to use the run anyway\n",
    "                        return run, None\n",
    "                \n",
    "                elif status != \"SUCCEEDED\":\n",
    "                    # Check error message for 403\n",
    "                    error_msg = str(run_info)\n",
    "                    if \"403\" in error_msg or \"blocked\" in error_msg.lower():\n",
    "                        if attempt < max_retries - 1:\n",
    "                            wait_time = 30 * (2 ** attempt)  # 30s, 60s, 120s\n",
    "                            print(f\"  🚫 Request blocked (403), waiting {wait_time}s before retry...\")\n",
    "                            time.sleep(wait_time)\n",
    "                            continue\n",
    "            \n",
    "            return run, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            if \"403\" in error_str or \"blocked\" in error_str.lower():\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = 30 * (2 ** attempt)\n",
    "                    print(f\"  🚫 Request blocked (403), waiting {wait_time}s before retry...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "            return None, f\"Apify call failed: {str(e)}\"\n",
    "    \n",
    "    return None, \"Max retries exceeded due to 403 blocking\"\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for idx, (i, row) in enumerate(acra_data_filtered_pilot.iterrows(), 1):\n",
    "    uen = str(row[\"UEN\"]).strip()\n",
    "    print(f\"\\n🔎 Processing {uen} ({idx}/{len(acra_data_filtered_pilot)})\")\n",
    "\n",
    "    # Build pageFunction with proper escaping\n",
    "    page_function = f\"\"\"\n",
    "    async function pageFunction(context) {{\n",
    "        const {{ page, log, request }} = context;\n",
    "        const uen = \"{uen}\";\n",
    "        log.info(\"Visiting RecordOwl for UEN: \" + uen);\n",
    "\n",
    "        try {{\n",
    "            await page.waitForSelector(\"input[placeholder='Search company name, industry, or address']\", {{ timeout: 30000 }});\n",
    "            const input = await page.$(\"input[placeholder='Search company name, industry, or address']\");\n",
    "            await input.click({{ clickCount: 3 }});\n",
    "            await input.type(uen, {{ delay: 100 }});\n",
    "\n",
    "            await Promise.all([\n",
    "                page.waitForNavigation({{ waitUntil: 'networkidle2', timeout: 60000 }}).catch(() => null),\n",
    "                page.click(\"button[type='submit']\")\n",
    "            ]);\n",
    "\n",
    "            // Wait for results with longer timeout\n",
    "            try {{\n",
    "                await page.waitForSelector(\"a[href*='/company/']\", {{ timeout: 45000 }});\n",
    "            }} catch (e) {{\n",
    "                log.info(\"No company links found, might be not found\");\n",
    "                return {{ status: 'not_found', uen }};\n",
    "            }}\n",
    "\n",
    "            const companyLink = await page.$$eval(\"a[href*='/company/']\", (links, uen) => {{\n",
    "                for (const a of links) {{\n",
    "                    const text = a.innerText || \"\";\n",
    "                    const href = a.href || \"\";\n",
    "                    if (text.includes(uen) || href.includes(uen.toLowerCase())) return a.href;\n",
    "                }}\n",
    "                return links.length > 0 ? links[0].href : null;\n",
    "            }}, uen);\n",
    "\n",
    "            if (!companyLink) return {{ status: 'not_found', uen }};\n",
    "\n",
    "            if (page.url() !== companyLink) {{\n",
    "                await page.goto(companyLink, {{ waitUntil: 'networkidle2', timeout: 60000 }});\n",
    "            }}\n",
    "\n",
    "            // Wait for critical content to load - phone numbers are often in dt/dd tags\n",
    "            await Promise.race([\n",
    "                page.waitForSelector('dt', {{ timeout: 10000 }}).catch(() => null),\n",
    "                new Promise(r => setTimeout(r, 8000)) // Increased from 3s to 8s\n",
    "            ]);\n",
    "            \n",
    "            // Additional wait to ensure all dynamic content loads\n",
    "            await new Promise(r => setTimeout(r, 5000));\n",
    "            \n",
    "            const html_content = await page.content();\n",
    "            const title = await page.title();\n",
    "            const url = page.url();\n",
    "\n",
    "            return {{ status: 'success', uen, url, title, html_content }};\n",
    "        }} catch (err) {{\n",
    "            log.error(\"Error in pageFunction: \" + err.message);\n",
    "            return {{ status: 'error', uen, error: err.message }};\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    run_input = {\n",
    "        \"startUrls\": [{\"url\": \"https://recordowl.com/\"}],\n",
    "        \"useChrome\": True,\n",
    "        \"headless\": True,\n",
    "        \"stealth\": True,\n",
    "        \"pageFunction\": page_function,\n",
    "        \"ignoreSslErrors\": False,\n",
    "        \"ignoreCorsAndCsp\": False,\n",
    "        \"maxRequestRetries\": 3,  # Increased retry attempts\n",
    "        \"maxRequestsPerCrawl\": 1,  # One page per run\n",
    "        \"maxConcurrency\": 1,  # No parallel requests\n",
    "        \"pageLoadTimeoutSecs\": 90,  # Optimized timeout\n",
    "        \"pageFunctionTimeoutSecs\": 180,  # 3 minutes for pageFunction\n",
    "        \"waitUntil\": [\"networkidle2\"],  # Wait for network to be idle\n",
    "        # OPTIMIZED: Residential proxies with recommended rotation\n",
    "        \"proxyConfiguration\": {\n",
    "            \"useApifyProxy\": True,\n",
    "            \"apifyProxyGroups\": [\"RESIDENTIAL\"],  # Residential IPs less likely to be blocked\n",
    "        },\n",
    "        \"proxyRotation\": \"RECOMMENDED\",  # Optimal proxy rotation strategy\n",
    "    }\n",
    "\n",
    "    # Use retry logic for 403 errors (5 attempts = more chances to recover)\n",
    "    run, error = run_apify_with_retry(client, run_input, uen, max_retries=5)\n",
    "\n",
    "    if error or not run:\n",
    "        print(f\"  ❌ Apify call failed for {uen}: {error}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": None,\n",
    "            \"Error\": error or \"No run returned\"\n",
    "        })\n",
    "        time.sleep(10)  # Longer sleep after failure\n",
    "        continue\n",
    "\n",
    "    if not run or \"defaultDatasetId\" not in run:\n",
    "        print(f\"  ⚠️ No valid dataset returned for {uen}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": None,\n",
    "            \"Error\": \"No dataset returned\"\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Wait for dataset to be ready with progressive checking\n",
    "    print(f\"  ⏳ Waiting for dataset to be ready...\")\n",
    "    time.sleep(5)  # Initial wait\n",
    "    \n",
    "    # Try to fetch dataset with progressive waits\n",
    "    dataset_client = client.dataset(run[\"defaultDatasetId\"])\n",
    "    for check_attempt in range(3):\n",
    "        try:\n",
    "            # Quick check if dataset has items\n",
    "            test_fetch = dataset_client.list_items(limit=1, clean=True)\n",
    "            if test_fetch.items:\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if check_attempt < 2:\n",
    "            additional_wait = 3 * (check_attempt + 1)\n",
    "            print(f\"  ⏳ Dataset not ready, waiting {additional_wait}s more...\")\n",
    "            time.sleep(additional_wait)\n",
    "    \n",
    "    scraped_html, record_owl_url = None, None\n",
    "    \n",
    "    # Fetch dataset items with improved error handling\n",
    "    dataset_items = fetch_dataset_items_safe(\n",
    "        dataset_client,\n",
    "        max_retries=5,\n",
    "        initial_wait=5  # Increased from 3 to 5\n",
    "    )\n",
    "    \n",
    "    # Process items\n",
    "    if not dataset_items:\n",
    "        print(f\"  ⚠️ Dataset is empty - no items returned!\")\n",
    "    else:\n",
    "        print(f\"  📊 Dataset has {len(dataset_items)} item(s)\")\n",
    "    \n",
    "    for item in dataset_items:\n",
    "        if item.get(\"status\") == \"success\":\n",
    "            scraped_html = item.get(\"html_content\", \"\")\n",
    "            record_owl_url = item.get(\"url\")\n",
    "            if scraped_html:\n",
    "                print(f\"  ✅ Successfully scraped {uen} ({len(scraped_html)} chars of HTML)\")\n",
    "            else:\n",
    "                print(f\"  ⚠️ Status is 'success' but html_content is empty for {uen}\")\n",
    "        elif item.get(\"status\") == \"not_found\":\n",
    "            print(f\"  ⚠️ Company not found for UEN {uen}\")\n",
    "        elif item.get(\"status\") == \"error\":\n",
    "            print(f\"  ❌ Error for {uen}: {item.get('error')}\")\n",
    "        else:\n",
    "            print(f\"  ⚠️ Unknown item status for {uen}: {item.get('status')}\")\n",
    "            print(f\"  📋 Item keys: {list(item.keys())}\")\n",
    "\n",
    "    if not scraped_html:\n",
    "        # Determine the specific reason for failure\n",
    "        if not dataset_items:\n",
    "            error_reason = \"Dataset empty (likely 403 block at Apify level)\"\n",
    "            print(f\"  ❌ {error_reason}\")\n",
    "        elif any(item.get(\"status\") == \"not_found\" for item in dataset_items):\n",
    "            error_reason = \"Company not found on RecordOwl\"\n",
    "            print(f\"  ❌ {error_reason}\")\n",
    "        elif any(item.get(\"status\") == \"error\" for item in dataset_items):\n",
    "            error_details = [item.get(\"error\", \"Unknown\") for item in dataset_items if item.get(\"status\") == \"error\"]\n",
    "            error_reason = f\"Scraping error: {error_details[0] if error_details else 'Unknown'}\"\n",
    "            print(f\"  ❌ {error_reason}\")\n",
    "        else:\n",
    "            error_reason = \"No HTML content retrieved (unknown reason)\"\n",
    "            print(f\"  ⚠️ {error_reason}\")\n",
    "            # Debug: show what's in dataset items\n",
    "            if dataset_items:\n",
    "                print(f\"  🔍 DEBUG - First item: {dataset_items[0]}\")\n",
    "        \n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": record_owl_url or None,\n",
    "            \"Error\": error_reason\n",
    "        })\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "\n",
    "    # Parse HTML\n",
    "    try:\n",
    "        soup = BeautifulSoup(scraped_html, \"html.parser\")\n",
    "        parent = soup.select_one(\"div.max-w-7xl.mx-auto.lg\\\\:py-6.sm\\\\:px-6.lg\\\\:px-8\")\n",
    "\n",
    "        emails, phones, website = [], [], None\n",
    "        facebook_links, linkedin_links, instagram_links, tiktok_links = [], [], [], []\n",
    "\n",
    "        if parent:\n",
    "            # Extract emails\n",
    "            for a in parent.select(\"a[href^=mailto]\"):\n",
    "                email = a.get(\"href\", \"\").replace(\"mailto:\", \"\").strip()\n",
    "                if email and email not in emails and \"@\" in email:\n",
    "                    emails.append(email)\n",
    "\n",
    "            # ========== COMPREHENSIVE PHONE EXTRACTION ==========\n",
    "            # This extracts Singapore phone numbers with ANY spacing/formatting:\n",
    "            # - \"65 63 19 2960\" (spaces between digits)\n",
    "            # - \"6563192960\" (no spaces)\n",
    "            # - \"+65-6319-2960\" (dashes)\n",
    "            # - \"65 6 3 1 9 2 9 6 0\" (space between every digit)\n",
    "            # - \"(65) 6319 2960\" (with parentheses)\n",
    "            # Method: Extract ALL digits first, then validate pattern\n",
    "            print(f\"  🔍 Searching for phone numbers...\")\n",
    "            \n",
    "            # Method 1: Look for tel: links (most reliable)\n",
    "            tel_links = parent.select(\"a[href^='tel:'], a[href^='tel']\")\n",
    "            if tel_links:\n",
    "                print(f\"  📱 Found {len(tel_links)} tel: links\")\n",
    "            \n",
    "            for a in tel_links:\n",
    "                tel_href = a.get(\"href\", \"\").replace(\"tel:\", \"\").strip()\n",
    "                tel_text = a.get_text(strip=True)\n",
    "                print(f\"  📞 Tel link - href: '{tel_href}', text: '{tel_text}'\")\n",
    "                \n",
    "                # Extract all digits from tel link\n",
    "                digits_only = re.sub(r\"\\D\", \"\", tel_href)\n",
    "                print(f\"  🔢 Tel digits: {digits_only}\")\n",
    "                \n",
    "                # Handle different digit lengths\n",
    "                if len(digits_only) == 10 and digits_only.startswith(\"65\") and digits_only[2] in \"689\":\n",
    "                    # 10 digits starting with 65 (e.g., \"6563192960\")\n",
    "                    formatted = \"+\" + digits_only\n",
    "                    if formatted not in phones:\n",
    "                        phones.append(formatted)\n",
    "                        print(f\"  ✅ Added from tel link (10 digits): {formatted}\")\n",
    "                elif len(digits_only) == 8 and digits_only[0] in \"689\":\n",
    "                    # 8 digits starting with 6/8/9 (e.g., \"63192960\")\n",
    "                    formatted = \"+65\" + digits_only\n",
    "                    if formatted not in phones:\n",
    "                        phones.append(formatted)\n",
    "                        print(f\"  ✅ Added from tel link (8 digits): {formatted}\")\n",
    "                elif len(digits_only) > 10:\n",
    "                    # More than 10 digits, try to find valid pattern\n",
    "                    print(f\"  🔍 Searching within {len(digits_only)} digits for valid pattern...\")\n",
    "                    found = False\n",
    "                    # Look for 65 followed by 6/8/9\n",
    "                    for i in range(len(digits_only) - 9):\n",
    "                        if digits_only[i:i+2] == \"65\" and digits_only[i+2] in \"689\":\n",
    "                            formatted = \"+\" + digits_only[i:i+10]\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from tel link (extracted): {formatted}\")\n",
    "                            found = True\n",
    "                            break\n",
    "                    if not found:\n",
    "                        # Try last 8 digits if they start with 6/8/9\n",
    "                        if digits_only[-8] in \"689\":\n",
    "                            formatted = \"+65\" + digits_only[-8:]\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from tel link (last 8 digits): {formatted}\")\n",
    "            \n",
    "            # Method 2: Look in dt/dd structure with broader keywords\n",
    "            dt_tags = parent.select(\"dt\")\n",
    "            if dt_tags:\n",
    "                print(f\"  📋 Found {len(dt_tags)} dt tags\")\n",
    "            \n",
    "            for dt in dt_tags:\n",
    "                dt_text = dt.get_text(strip=True).lower()\n",
    "                # Check for phone-related keywords but exclude non-phone fields\n",
    "                exclude_keywords = [\"officer\", \"charge\", \"employee\", \"shareholder\", \"director\", \"registration\"]\n",
    "                phone_keywords = [\"contact number\", \"phone\", \"tel\", \"mobile\", \"call\", \"contact no\"]\n",
    "                \n",
    "                is_phone_field = any(kw in dt_text for kw in phone_keywords)\n",
    "                is_excluded = any(excl in dt_text for excl in exclude_keywords)\n",
    "                \n",
    "                if is_phone_field and not is_excluded:\n",
    "                    dd = dt.find_next_sibling(\"dd\")\n",
    "                    if dd:\n",
    "                        number_text = dd.get_text(\" \", strip=True)\n",
    "                        print(f\"  📝 Field '{dt_text}': {number_text}\")\n",
    "                        \n",
    "                        # Extract all digits and check if it forms a valid phone number\n",
    "                        all_digits = re.sub(r\"\\D\", \"\", number_text)\n",
    "                        print(f\"  🔢 Extracted digits: {all_digits}\")\n",
    "                        \n",
    "                        # Check for Singapore phone patterns in the digits\n",
    "                        # Pattern 1: 10 digits starting with 65\n",
    "                        if len(all_digits) == 10 and all_digits.startswith(\"65\") and all_digits[2] in \"689\":\n",
    "                            formatted = \"+\" + all_digits\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from dt/dd (10 digits): {formatted}\")\n",
    "                        # Pattern 2: 8 digits starting with 6, 8, or 9\n",
    "                        elif len(all_digits) == 8 and all_digits[0] in \"689\":\n",
    "                            formatted = \"+65\" + all_digits\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from dt/dd (8 digits): {formatted}\")\n",
    "                        # Pattern 3: More than 10 digits, try to extract 10-digit number starting with 65\n",
    "                        elif len(all_digits) > 10:\n",
    "                            # Look for 65 followed by 6/8/9 in the digit string\n",
    "                            for i in range(len(all_digits) - 9):\n",
    "                                if all_digits[i:i+2] == \"65\" and all_digits[i+2] in \"689\":\n",
    "                                    potential_number = all_digits[i:i+10]\n",
    "                                    formatted = \"+\" + potential_number\n",
    "                                    if formatted not in phones:\n",
    "                                        phones.append(formatted)\n",
    "                                        print(f\"  ✅ Added from dt/dd (extracted): {formatted}\")\n",
    "                                    break\n",
    "            \n",
    "            # Method 3: Search entire parent for phone patterns if none found\n",
    "            if not phones:\n",
    "                print(f\"  🔎 No phones found yet, searching entire content...\")\n",
    "                full_text = parent.get_text()\n",
    "                \n",
    "                # Ultra-comprehensive patterns to catch ALL spacing variations\n",
    "                # These patterns allow unlimited spaces/dashes between digits\n",
    "                patterns = [\n",
    "                    # Pattern 1: +65 with any spacing (e.g., \"+65 6 3 1 9 2 9 6 0\", \"+65-6319-2960\")\n",
    "                    r\"\\+[\\s\\-]*65[\\s\\-]+[689][\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d\",\n",
    "                    # Pattern 2: (65) with any spacing\n",
    "                    r\"\\([\\s\\-]*65[\\s\\-]*\\)[\\s\\-]*[689][\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d\",\n",
    "                    # Pattern 3: 65 without + or () but with space/dash (e.g., \"65 6 3 1 9 2 9 6 0\", \"65-6319-2960\")\n",
    "                    r\"(?<!\\d)65[\\s\\-]+[689][\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d(?!\\d)\",\n",
    "                    # Pattern 4: Just 8 digits starting with 6/8/9 with any spacing\n",
    "                    r\"(?<!\\d)[689][\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d(?!\\d)\",\n",
    "                ]\n",
    "                \n",
    "                for pattern_idx, pattern in enumerate(patterns, 1):\n",
    "                    matches = re.findall(pattern, full_text)\n",
    "                    if matches:\n",
    "                        print(f\"  🔍 Pattern {pattern_idx} found {len(matches)} potential matches\")\n",
    "                    \n",
    "                    for match in matches:\n",
    "                        # Extract only digits\n",
    "                        digits = re.sub(r\"\\D\", \"\", match)\n",
    "                        print(f\"  🔢 Pattern {pattern_idx} match: '{match.strip()}' → digits: '{digits}'\")\n",
    "                        \n",
    "                        # Validate and format\n",
    "                        if len(digits) == 10 and digits.startswith(\"65\") and digits[2] in \"689\":\n",
    "                            formatted = \"+\" + digits\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from pattern {pattern_idx} (10 digits): {formatted}\")\n",
    "                        elif len(digits) == 8 and digits[0] in \"689\":\n",
    "                            formatted = \"+65\" + digits\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from pattern {pattern_idx} (8 digits): {formatted}\")\n",
    "                        elif len(digits) > 10:\n",
    "                            # Try to find a valid 10-digit number within\n",
    "                            for i in range(len(digits) - 9):\n",
    "                                if digits[i:i+2] == \"65\" and digits[i+2] in \"689\":\n",
    "                                    potential = digits[i:i+10]\n",
    "                                    formatted = \"+\" + potential\n",
    "                                    if formatted not in phones:\n",
    "                                        phones.append(formatted)\n",
    "                                        print(f\"  ✅ Added from pattern {pattern_idx} (extracted): {formatted}\")\n",
    "                                    break\n",
    "            \n",
    "            if phones:\n",
    "                print(f\"  ✅ Total phones found: {phones}\")\n",
    "            else:\n",
    "                print(f\"  ⚠️ WARNING: No phone numbers found for {uen}\")\n",
    "                print(f\"  📄 Showing first 500 chars of parent HTML for debugging:\")\n",
    "                print(parent.prettify()[:500] + \"...\")\n",
    "            # ========== END PHONE EXTRACTION ==========\n",
    "\n",
    "            # Extract website\n",
    "            valid_websites = []\n",
    "            for a in parent.select(\"a[href^=http]\"):\n",
    "                href = a.get(\"href\", \"\").strip()\n",
    "                href_lower = href.lower()\n",
    "                if not any(domain in href_lower for domain in SOCIAL_MEDIA_DOMAINS):\n",
    "                    if not any(skip in href_lower for skip in [\"recordowl\", \"apify.com\"]):\n",
    "                        if any(tld in href for tld in [\".com\", \".sg\", \".net\", \".org\", \".co\"]):\n",
    "                            valid_websites.append(href)\n",
    "            website = valid_websites[0] if valid_websites else None\n",
    "\n",
    "        # Extract social media links from entire page\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            href = a[\"href\"].strip().lower()\n",
    "            if \"facebook.com\" in href and href not in facebook_links:\n",
    "                facebook_links.append(href)\n",
    "            elif \"linkedin.com\" in href and href not in linkedin_links:\n",
    "                linkedin_links.append(href)\n",
    "            elif \"instagram.com\" in href and href not in instagram_links:\n",
    "                instagram_links.append(href)\n",
    "            elif \"tiktok.com\" in href and href not in tiktok_links:\n",
    "                tiktok_links.append(href)\n",
    "\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": emails if emails else None,\n",
    "            \"Phones\": phones if phones else None,\n",
    "            \"Website\": website,\n",
    "            \"Facebook\": list(set(facebook_links)) if facebook_links else None,\n",
    "            \"LinkedIn\": list(set(linkedin_links)) if linkedin_links else None,\n",
    "            \"Instagram\": list(set(instagram_links)) if instagram_links else None,\n",
    "            \"TikTok\": list(set(tiktok_links)) if tiktok_links else None,\n",
    "            \"RecordOwl_Link\": record_owl_url,\n",
    "        })\n",
    "        print(f\"  ✅ Processed {uen}: {len(emails) if emails else 0} emails, {len(phones) if phones else 0} phones\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error parsing HTML for {uen}: {e}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": record_owl_url or None,\n",
    "            \"Error\": f\"HTML parsing error: {str(e)}\"\n",
    "        })\n",
    "\n",
    "    # Dynamic sleep time to avoid rate limiting and 403 blocks\n",
    "    # Longer delays reduce detection and blocking\n",
    "    base_sleep = 20  # Increased from 10\n",
    "    random_addition = (idx % 10) + 5  # 5-14 seconds random\n",
    "    sleep_time = base_sleep + random_addition  # 25-34 seconds total\n",
    "\n",
    "    print(f\"  💤 Sleeping for {sleep_time}s before next request...\")\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "    # Extra delay after every 5th request to further avoid detection\n",
    "    if idx % 5 == 0:\n",
    "        extra_wait = 30\n",
    "        print(f\"  🛑 Checkpoint pause: waiting extra {extra_wait}s...\")\n",
    "        time.sleep(extra_wait)\n",
    "\n",
    "New_Fresh_Leads = pd.DataFrame(all_results)\n",
    "print(\"\\n✅ Scraping complete!\")\n",
    "print(f\"\\n📊 Results summary:\")\n",
    "print(f\"   Total processed: {len(New_Fresh_Leads)}\")\n",
    "print(f\"   With emails: {New_Fresh_Leads['Emails'].notna().sum()}\")\n",
    "print(f\"   With phones: {New_Fresh_Leads['Phones'].notna().sum()}\")\n",
    "print(f\"   With websites: {New_Fresh_Leads['Website'].notna().sum()}\")\n",
    "New_Fresh_Leads.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce63aaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Fresh_Leads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78537b1",
   "metadata": {},
   "source": [
    "### Append and save into exel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load both Excel files\n",
    "# file_path_1 = \"Fresh_Leads.xlsx\"\n",
    "# Fresh_Leads = pd.read_excel(file_path_1)\n",
    "\n",
    "# # file_path_2 = \"recordowl_results_4.xlsx\"\n",
    "# # recordowl_results_4 = pd.read_excel(file_path_2)\n",
    "\n",
    "# # Append (combine) them\n",
    "# combined_df = pd.concat([Fresh_Leads, Fresh_Leads_with_phones], ignore_index=True)\n",
    "\n",
    "# # Optional: Save to a new Excel file\n",
    "# combined_df.to_excel(\"Fresh_Leads_New.xlsx\", index=False)\n",
    "\n",
    "# # Preview\n",
    "# combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257fbbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_non_nan = combined_df['Phones'].notna().sum()\n",
    "# print(count_non_nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a4e0f",
   "metadata": {},
   "source": [
    "### Website Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccaea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "\n",
    "# =====================================================\n",
    "# Validate Website (only if no phone number)\n",
    "# =====================================================\n",
    "async def check_url(url: str) -> bool:\n",
    "    \"\"\"Return True if the URL is reachable (status < 400).\"\"\"\n",
    "    if not url:\n",
    "        return False\n",
    "    try:\n",
    "        async with httpx.AsyncClient(follow_redirects=True, timeout=5) as client:\n",
    "            response = await client.head(url)\n",
    "            return response.status_code < 400\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "async def validate_if_needed(df):\n",
    "    \"\"\"Validate websites only if phone number is missing.\"\"\"\n",
    "    for i, row in df.iterrows():\n",
    "        url = row.get(\"Website\")\n",
    "        phone = row.get(\"Phones\")\n",
    "\n",
    "        # Skip validation if phone exists\n",
    "        if phone:\n",
    "            df.at[i, \"Website_Valid\"] = None\n",
    "            continue\n",
    "\n",
    "        # Validate website if no phone\n",
    "        if url:\n",
    "            is_valid = await check_url(url)\n",
    "            df.at[i, \"Website_Valid\"] = \"valid\" if is_valid else \"invalid\"\n",
    "        else:\n",
    "            df.at[i, \"Website_Valid\"] = \"invalid\"\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# Run async validation safely inside Jupyter\n",
    "# =====================================================\n",
    "result_df = await validate_if_needed(result_df)\n",
    "\n",
    "# =====================================================\n",
    "# Final output\n",
    "# =====================================================\n",
    "display(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c268400",
   "metadata": {},
   "source": [
    "### If contact number is invalid, then webscrapped website to get contact number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e742795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import time\n",
    "from apify_client import ApifyClient\n",
    "\n",
    "# --- Initialize Apify client ---\n",
    "APIFY_TOKEN = os.getenv(\"APIFY_TOKEN\", \"apify_api_0HQ8fc5fw5T1aosdacxKQNQYVBAEwi3tXaJc\")\n",
    "client = ApifyClient(APIFY_TOKEN)\n",
    "\n",
    "# --- Async wrapper so you can run in Jupyter ---\n",
    "async def enrich_with_contact_info(df):\n",
    "    \"\"\"Scrape contact info for rows where Website_Valid == 'valid' and Phones is empty.\"\"\"\n",
    "    updated_df = df.copy()\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        website = row.get(\"Website\")\n",
    "        status = row.get(\"Website_Valid\")\n",
    "        phone = row.get(\"Phones\")\n",
    "\n",
    "        if not website or status != \"valid\" or phone:\n",
    "            continue  # Skip invalid or already complete rows\n",
    "\n",
    "        print(f\"🔍 Scraping contact page for: {website}\")\n",
    "\n",
    "        # --- CONVERTED TO PUPPETEER-SCRAPER (same as Cell 20) ---\n",
    "        # Now using native Puppeteer syntax instead of jQuery\n",
    "        run_input = {\n",
    "            \"startUrls\": [{\"url\": website}],\n",
    "            \"pageFunction\": r\"\"\"\n",
    "                async function pageFunction(context) {\n",
    "                    const { page, log, request } = context;\n",
    "                    const isContact = request.userData?.isContact || false;\n",
    "\n",
    "                    // If not on contact page yet, try to find and navigate to it\n",
    "                    if (!isContact) {\n",
    "                        try {\n",
    "                            // Wait for page to load\n",
    "                            await page.waitForSelector('a', { timeout: 10000 }).catch(() => null);\n",
    "                            \n",
    "                            // Find contact page link using Puppeteer\n",
    "                            const contactUrl = await page.evaluate(() => {\n",
    "                                const links = Array.from(document.querySelectorAll('a[href]'));\n",
    "                                for (const link of links) {\n",
    "                                    const href = link.getAttribute('href');\n",
    "                                    if (href && href.toLowerCase().includes('contact')) {\n",
    "                                        return href.startsWith('http') ? href : window.location.origin + href;\n",
    "                                    }\n",
    "                                }\n",
    "                                return null;\n",
    "                            });\n",
    "\n",
    "                            if (contactUrl) {\n",
    "                                await context.enqueueRequest({ \n",
    "                                    url: contactUrl, \n",
    "                                    userData: { isContact: true } \n",
    "                                });\n",
    "                                log.info(`Enqueued contact page: ${contactUrl}`);\n",
    "                            }\n",
    "                            return null;\n",
    "                        } catch (err) {\n",
    "                            log.error(`Error finding contact page: ${err.message}`);\n",
    "                            return null;\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "                    // We're on the contact page - extract emails and phones\n",
    "                    try {\n",
    "                        // Wait for content to load\n",
    "                        await new Promise(r => setTimeout(r, 3000));\n",
    "\n",
    "                        // Extract emails and phones using Puppeteer\n",
    "                        const contactData = await page.evaluate(() => {\n",
    "                            // Helper: check if element is visible\n",
    "                            function isVisible(el) {\n",
    "                                return el && el.offsetParent !== null;\n",
    "                            }\n",
    "\n",
    "                            // Extract emails from mailto links\n",
    "                            const emailLinks = Array.from(document.querySelectorAll('a[href^=\"mailto\"]'));\n",
    "                            const emails = emailLinks\n",
    "                                .filter(el => isVisible(el))\n",
    "                                .map(el => el.getAttribute('href').replace('mailto:', '').trim())\n",
    "                                .filter(email => email.length > 0);\n",
    "\n",
    "                            // Extract phones from tel links\n",
    "                            const phoneLinks = Array.from(document.querySelectorAll('a[href^=\"tel\"]'));\n",
    "                            const phones = phoneLinks\n",
    "                                .filter(el => isVisible(el))\n",
    "                                .map(el => el.getAttribute('href').replace(/[^0-9]/g, ''))\n",
    "                                .filter(phone => phone.length > 0);\n",
    "\n",
    "                            return {\n",
    "                                emails: [...new Set(emails)],\n",
    "                                phones: [...new Set(phones)]\n",
    "                            };\n",
    "                        });\n",
    "\n",
    "                        return {\n",
    "                            contactUrl: request.url,\n",
    "                            emails: contactData.emails.length ? contactData.emails : [],\n",
    "                            phones: contactData.phones.length ? contactData.phones : []\n",
    "                        };\n",
    "                    } catch (err) {\n",
    "                        log.error(`Error extracting contact data: ${err.message}`);\n",
    "                        return {\n",
    "                            contactUrl: request.url,\n",
    "                            emails: [],\n",
    "                            phones: [],\n",
    "                            error: err.message\n",
    "                        };\n",
    "                    }\n",
    "                }\n",
    "            \"\"\",\n",
    "            \"useChrome\": True,\n",
    "            \"headless\": True,\n",
    "            \"stealth\": True,\n",
    "            \"ignoreSslErrors\": False,\n",
    "            \"ignoreCorsAndCsp\": False,\n",
    "            \"maxRequestRetries\": 3,  # Increased retry attempts\n",
    "            \"maxRequestsPerCrawl\": 0,  # No limit (will crawl main + contact pages)\n",
    "            \"maxConcurrency\": 1,  # No parallel requests\n",
    "            \"pageLoadTimeoutSecs\": 90,  # Optimized timeout\n",
    "            \"pageFunctionTimeoutSecs\": 180,  # 3 minutes for pageFunction\n",
    "            \"waitUntil\": [\"networkidle2\"],  # Wait for network to be idle\n",
    "            # OPTIMIZED: Residential proxies with recommended rotation\n",
    "            \"proxyConfiguration\": {\n",
    "                \"useApifyProxy\": True,\n",
    "                \"apifyProxyGroups\": [\"RESIDENTIAL\"],  # Residential IPs less likely to be blocked\n",
    "            },\n",
    "            \"proxyRotation\": \"RECOMMENDED\",  # Optimal proxy rotation strategy\n",
    "        }\n",
    "\n",
    "        # --- Run the Apify scraper (NOW USING PUPPETEER-SCRAPER) ---\n",
    "        try:\n",
    "            print(f\"  📡 Starting Apify puppeteer-scraper...\")\n",
    "            run = client.actor(\"apify/puppeteer-scraper\").call(run_input=run_input)\n",
    "            \n",
    "            # Wait for dataset to be ready\n",
    "            time.sleep(3)\n",
    "            \n",
    "            dataset = client.dataset(run[\"defaultDatasetId\"])\n",
    "            results = list(dataset.iterate_items())\n",
    "            contact_results = [r for r in results if r and (r.get(\"emails\") or r.get(\"phones\"))]\n",
    "\n",
    "            if contact_results:\n",
    "                scraped = contact_results[0]\n",
    "                updated_df.at[i, \"Emails\"] = scraped.get(\"emails\", None)\n",
    "                updated_df.at[i, \"Phones\"] = scraped.get(\"phones\", None)\n",
    "                updated_df.at[i, \"Contact_Page\"] = scraped.get(\"contactUrl\", None)\n",
    "                print(f\"  ✅ Found: {scraped.get('phones', [])} / {scraped.get('emails', [])}\")\n",
    "            else:\n",
    "                print(\"  ⚠️ No contact data found.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error scraping {website}: {e}\")\n",
    "        \n",
    "        # Add delay to avoid rate limiting\n",
    "        time.sleep(5)\n",
    "\n",
    "    return updated_df\n",
    "\n",
    "\n",
    "# --- Run the scraper for valid websites ---\n",
    "result_df = await enrich_with_contact_info(result_df)\n",
    "\n",
    "# --- Display updated results ---\n",
    "display(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad033e9f",
   "metadata": {},
   "source": [
    "### Facebook Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9c9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ApifyClient with your API token\n",
    "client = ApifyClient(\"apify_api_yNR85etaHpLtBzPoVozVVXUsCZe54u2Ffog1\")\n",
    "\n",
    "# Function to validate Singapore phone numbers (MUST have country code)\n",
    "def validate_singapore_number(phone):\n",
    "    if not phone:\n",
    "        return None\n",
    "    \n",
    "    # Remove all spaces, dashes, parentheses\n",
    "    cleaned = re.sub(r'[\\s\\-\\(\\)]', '', str(phone))\n",
    "    \n",
    "    # MUST have country code: +65XXXXXXXX or 65XXXXXXXX\n",
    "    # First digit after country code must be 6, 8, or 9\n",
    "    # Total of 8 digits after country code\n",
    "    if re.match(r'^\\+?65[689]\\d{7}$', cleaned):\n",
    "        return phone  # Return original format\n",
    "    \n",
    "    # Not a valid Singapore number with country code\n",
    "    return None\n",
    "\n",
    "# Prepare the Actor input\n",
    "run_input = {\n",
    "    \"pages\": [\n",
    "        \"https://www.facebook.com/KPECTHub/\",\n",
    "    ],\n",
    "    \"language\": \"en-US\",\n",
    "}\n",
    "\n",
    "# Run the Actor and wait for it to finish\n",
    "run = client.actor(\"oJ48ceKNY7ueGPGL0\").call(run_input=run_input)\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "for item in client.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
    "    # Extract phone from multiple possible fields\n",
    "    raw_phone = item.get('phone', None) or item.get('wa_number', None)\n",
    "    \n",
    "    # Validate it's a Singapore number WITH country code\n",
    "    phone = validate_singapore_number(raw_phone)\n",
    "    \n",
    "    # Extract email\n",
    "    email = item.get('email', None)\n",
    "    \n",
    "    # Extract website from the websites list (take first non-Google Maps link if available)\n",
    "    websites = item.get('websites', [])\n",
    "    website = None\n",
    "    if websites:\n",
    "        # Filter out Google Maps links and take the first real website\n",
    "        real_websites = [w for w in websites if 'maps.google.com' not in w]\n",
    "        website = real_websites[0] if real_websites else websites[0]\n",
    "    \n",
    "    results.append({\n",
    "        'facebook_url': item.get('facebookUrl', None),\n",
    "        'page_name': item.get('pageName', None),\n",
    "        'phone': phone,  # Only Singapore numbers WITH country code or None\n",
    "        'email': email,\n",
    "        'website': website,\n",
    "        'address': item.get('address', None)\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
