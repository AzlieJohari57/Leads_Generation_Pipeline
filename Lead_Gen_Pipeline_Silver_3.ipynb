{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0e7f7c",
   "metadata": {},
   "source": [
    "### Data Mining in Website (Silver 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a789be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import time\n",
    "import scrapy\n",
    "from scrapy_playwright.page import PageMethod\n",
    "from bs4 import BeautifulSoup\n",
    "import nest_asyncio\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "from apify_client import ApifyClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d11e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_path = \"./Staging/Gold/cleaned_second_592.parquet\"\n",
    "if os.path.exists(parquet_path):\n",
    "    RecordOwl_Leads = pd.read_parquet(parquet_path, engine=\"fastparquet\")\n",
    "    print(f\"Loaded {len(RecordOwl_Leads)} rows from {parquet_path}\")\n",
    "    print(RecordOwl_Leads.shape)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Parquet file not found at {parquet_path}\")\n",
    "\n",
    "filtered_df = RecordOwl_Leads[\n",
    "    RecordOwl_Leads[\"PIC NAME 1 Contact Number\"].notna() &\n",
    "    (RecordOwl_Leads[\"PIC NAME 1 Contact Number\"] != \"\")\n",
    "]\n",
    "\n",
    "filtered_df = filtered_df[\n",
    "    (filtered_df[\"Facebook Page\"].notna()) & \n",
    "    (filtered_df[\"Facebook Page\"] != \"\")]\n",
    "\n",
    "filtered_df = filtered_df[[\"PIC NAME 1 Contact Number\", \"Facebook Page\"]]\n",
    "\n",
    "filtered_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a179cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 164\u001b[39m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m updated_df\n\u001b[32m    163\u001b[39m \u001b[38;5;66;03m# --- Run the scraper for valid websites ---\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m result_df = \u001b[38;5;28;01mawait\u001b[39;00m enrich_with_contact_info(\u001b[43mresult_df\u001b[49m)\n\u001b[32m    166\u001b[39m \u001b[38;5;66;03m# --- Display updated results ---\u001b[39;00m\n\u001b[32m    167\u001b[39m display(result_df)\n",
      "\u001b[31mNameError\u001b[39m: name 'result_df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- Initialize Apify client ---\n",
    "APIFY_TOKEN = os.getenv(\"APIFY_TOKEN\", \"apify_api_0HQ8fc5fw5T1aosdacxKQNQYVBAEwi3tXaJc\")\n",
    "client = ApifyClient(APIFY_TOKEN)\n",
    "\n",
    "# --- Async wrapper so you can run in Jupyter ---\n",
    "async def enrich_with_contact_info(df):\n",
    "    \"\"\"Scrape contact info for rows where Website_Valid == 'valid' and Phones is empty.\"\"\"\n",
    "    updated_df = df.copy()\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        website = row.get(\"Website\")\n",
    "        status = row.get(\"Website_Valid\")\n",
    "        phone = row.get(\"Phones\")\n",
    "\n",
    "        if not website or status != \"valid\" or phone:\n",
    "            continue  # Skip invalid or already complete rows\n",
    "\n",
    "        print(f\"üîç Scraping contact page for: {website}\")\n",
    "\n",
    "        # --- CONVERTED TO PUPPETEER-SCRAPER (same as Cell 20) ---\n",
    "        # Now using native Puppeteer syntax instead of jQuery\n",
    "        run_input = {\n",
    "            \"startUrls\": [{\"url\": website}],\n",
    "            \"pageFunction\": r\"\"\"\n",
    "                async function pageFunction(context) {\n",
    "                    const { page, log, request } = context;\n",
    "                    const isContact = request.userData?.isContact || false;\n",
    "\n",
    "                    // If not on contact page yet, try to find and navigate to it\n",
    "                    if (!isContact) {\n",
    "                        try {\n",
    "                            // Wait for page to load\n",
    "                            await page.waitForSelector('a', { timeout: 10000 }).catch(() => null);\n",
    "                            \n",
    "                            // Find contact page link using Puppeteer\n",
    "                            const contactUrl = await page.evaluate(() => {\n",
    "                                const links = Array.from(document.querySelectorAll('a[href]'));\n",
    "                                for (const link of links) {\n",
    "                                    const href = link.getAttribute('href');\n",
    "                                    if (href && href.toLowerCase().includes('contact')) {\n",
    "                                        return href.startsWith('http') ? href : window.location.origin + href;\n",
    "                                    }\n",
    "                                }\n",
    "                                return null;\n",
    "                            });\n",
    "\n",
    "                            if (contactUrl) {\n",
    "                                await context.enqueueRequest({ \n",
    "                                    url: contactUrl, \n",
    "                                    userData: { isContact: true } \n",
    "                                });\n",
    "                                log.info(`Enqueued contact page: ${contactUrl}`);\n",
    "                            }\n",
    "                            return null;\n",
    "                        } catch (err) {\n",
    "                            log.error(`Error finding contact page: ${err.message}`);\n",
    "                            return null;\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "                    // We're on the contact page - extract emails and phones\n",
    "                    try {\n",
    "                        // Wait for content to load\n",
    "                        await new Promise(r => setTimeout(r, 3000));\n",
    "\n",
    "                        // Extract emails and phones using Puppeteer\n",
    "                        const contactData = await page.evaluate(() => {\n",
    "                            // Helper: check if element is visible\n",
    "                            function isVisible(el) {\n",
    "                                return el && el.offsetParent !== null;\n",
    "                            }\n",
    "\n",
    "                            // Extract emails from mailto links\n",
    "                            const emailLinks = Array.from(document.querySelectorAll('a[href^=\"mailto\"]'));\n",
    "                            const emails = emailLinks\n",
    "                                .filter(el => isVisible(el))\n",
    "                                .map(el => el.getAttribute('href').replace('mailto:', '').trim())\n",
    "                                .filter(email => email.length > 0);\n",
    "\n",
    "                            // Extract phones from tel links\n",
    "                            const phoneLinks = Array.from(document.querySelectorAll('a[href^=\"tel\"]'));\n",
    "                            const phones = phoneLinks\n",
    "                                .filter(el => isVisible(el))\n",
    "                                .map(el => el.getAttribute('href').replace(/[^0-9]/g, ''))\n",
    "                                .filter(phone => phone.length > 0);\n",
    "\n",
    "                            return {\n",
    "                                emails: [...new Set(emails)],\n",
    "                                phones: [...new Set(phones)]\n",
    "                            };\n",
    "                        });\n",
    "\n",
    "                        return {\n",
    "                            contactUrl: request.url,\n",
    "                            emails: contactData.emails.length ? contactData.emails : [],\n",
    "                            phones: contactData.phones.length ? contactData.phones : []\n",
    "                        };\n",
    "                    } catch (err) {\n",
    "                        log.error(`Error extracting contact data: ${err.message}`);\n",
    "                        return {\n",
    "                            contactUrl: request.url,\n",
    "                            emails: [],\n",
    "                            phones: [],\n",
    "                            error: err.message\n",
    "                        };\n",
    "                    }\n",
    "                }\n",
    "            \"\"\",\n",
    "            \"useChrome\": True,\n",
    "            \"headless\": True,\n",
    "            \"stealth\": True,\n",
    "            \"ignoreSslErrors\": False,\n",
    "            \"ignoreCorsAndCsp\": False,\n",
    "            \"maxRequestRetries\": 3,  # Increased retry attempts\n",
    "            \"maxRequestsPerCrawl\": 0,  # No limit (will crawl main + contact pages)\n",
    "            \"maxConcurrency\": 1,  # No parallel requests\n",
    "            \"pageLoadTimeoutSecs\": 90,  # Optimized timeout\n",
    "            \"pageFunctionTimeoutSecs\": 180,  # 3 minutes for pageFunction\n",
    "            \"waitUntil\": [\"networkidle2\"],  # Wait for network to be idle\n",
    "            # OPTIMIZED: Residential proxies with recommended rotation\n",
    "            \"proxyConfiguration\": {\n",
    "                \"useApifyProxy\": True,\n",
    "                \"apifyProxyGroups\": [\"RESIDENTIAL\"],  # Residential IPs less likely to be blocked\n",
    "            },\n",
    "            \"proxyRotation\": \"RECOMMENDED\",  # Optimal proxy rotation strategy\n",
    "        }\n",
    "\n",
    "        # --- Run the Apify scraper (NOW USING PUPPETEER-SCRAPER) ---\n",
    "        try:\n",
    "            print(f\"  üì° Starting Apify puppeteer-scraper...\")\n",
    "            run = client.actor(\"apify/puppeteer-scraper\").call(run_input=run_input)\n",
    "            \n",
    "            # Wait for dataset to be ready\n",
    "            time.sleep(3)\n",
    "            \n",
    "            dataset = client.dataset(run[\"defaultDatasetId\"])\n",
    "            results = list(dataset.iterate_items())\n",
    "            contact_results = [r for r in results if r and (r.get(\"emails\") or r.get(\"phones\"))]\n",
    "\n",
    "            if contact_results:\n",
    "                scraped = contact_results[0]\n",
    "                updated_df.at[i, \"Emails\"] = scraped.get(\"emails\", None)\n",
    "                updated_df.at[i, \"Phones\"] = scraped.get(\"phones\", None)\n",
    "                updated_df.at[i, \"Contact_Page\"] = scraped.get(\"contactUrl\", None)\n",
    "                print(f\"  ‚úÖ Found: {scraped.get('phones', [])} / {scraped.get('emails', [])}\")\n",
    "            else:\n",
    "                print(\"  ‚ö†Ô∏è No contact data found.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Error scraping {website}: {e}\")\n",
    "        \n",
    "        # Add delay to avoid rate limiting\n",
    "        time.sleep(5)\n",
    "\n",
    "    return updated_df\n",
    "\n",
    "\n",
    "# --- Run the scraper for valid websites ---\n",
    "result_df = await enrich_with_contact_info(result_df)\n",
    "\n",
    "# --- Display updated results ---\n",
    "display(result_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
