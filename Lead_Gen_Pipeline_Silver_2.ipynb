{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f1d1a2",
   "metadata": {},
   "source": [
    "# Data Mining in RecordOwl (Silver 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b601322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import time\n",
    "import scrapy\n",
    "from scrapy_playwright.page import PageMethod\n",
    "from bs4 import BeautifulSoup\n",
    "import nest_asyncio\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "from apify_client import ApifyClient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c77d5d",
   "metadata": {},
   "source": [
    "### Ingesting from previous layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf8e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_path = \"./Staging/Bronze/bronze_data_1.parquet\"\n",
    "if os.path.exists(parquet_path):\n",
    "    acra_data_filtered_by_industry = pd.read_parquet(parquet_path, engine=\"fastparquet\")\n",
    "    print(f\"Loaded {len(acra_data_filtered_by_industry)} rows from {parquet_path}\")\n",
    "    print(acra_data_filtered_by_industry.shape)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Parquet file not found at {parquet_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b183e",
   "metadata": {},
   "source": [
    "### Mining RecordOwl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = ApifyClient(\"apify_api_BKqgA7WLcQMD7dugx62KslGgbrxZ2t3NB2gj\")\n",
    "\n",
    "SOCIAL_MEDIA_DOMAINS = [\n",
    "    \"facebook.com\", \"linkedin.com\", \"instagram.com\", \"youtube.com\",\n",
    "    \"tiktok.com\", \"twitter.com\", \"x.com\", \"pinterest.com\"\n",
    "]\n",
    "\n",
    "def fetch_dataset_items_safe(dataset_client, max_retries=5, initial_wait=3):\n",
    "    \"\"\"Safely fetch dataset items with multiple retry strategies.\"\"\"\n",
    "    dataset_items = []\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Strategy 1: Try using iterate_items() (streaming)\n",
    "            try:\n",
    "                dataset_items = list(dataset_client.iterate_items())\n",
    "                if dataset_items:\n",
    "                    return dataset_items\n",
    "            except (HTTPError, ConnectionError, ProtocolError, Exception) as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = initial_wait * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"  ‚ö†Ô∏è Iteration method failed (attempt {attempt + 1}/{max_retries}), trying direct fetch in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  ‚ö†Ô∏è Iteration method failed after all retries, trying direct fetch...\")\n",
    "            \n",
    "            # Strategy 2: Try using list_items() (direct pagination)\n",
    "            try:\n",
    "                offset = 0\n",
    "                limit = 100\n",
    "                while True:\n",
    "                    page = dataset_client.list_items(offset=offset, limit=limit, clean=True)\n",
    "                    if not page.items:\n",
    "                        break\n",
    "                    dataset_items.extend(page.items)\n",
    "                    if len(page.items) < limit:\n",
    "                        break\n",
    "                    offset += limit\n",
    "                \n",
    "                if dataset_items:\n",
    "                    return dataset_items\n",
    "            except (HTTPError, ConnectionError, ProtocolError, Exception) as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = initial_wait * (2 ** attempt)\n",
    "                    print(f\"  ‚ö†Ô∏è Direct fetch failed (attempt {attempt + 1}/{max_retries}), retrying in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  ‚ùå All fetch methods failed: {e}\")\n",
    "                    return []\n",
    "                    \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = initial_wait * (2 ** attempt)\n",
    "                print(f\"  ‚ö†Ô∏è Unexpected error (attempt {attempt + 1}/{max_retries}), retrying in {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"  ‚ùå Failed after all retries: {e}\")\n",
    "                return []\n",
    "    \n",
    "    return dataset_items\n",
    "\n",
    "def run_apify_with_retry(client, run_input, uen, max_retries=3):\n",
    "    \"\"\"Run Apify with exponential backoff on 403 errors AND verify dataset has items.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"  üì° Starting Apify run for {uen} (attempt {attempt + 1}/{max_retries})...\")\n",
    "            run = client.actor(\"apify/puppeteer-scraper\").call(run_input=run_input)\n",
    "            \n",
    "            print(f\"  ‚è≥ Waiting for run to complete...\")\n",
    "            run_client = client.run(run[\"id\"])\n",
    "            run_info = run_client.wait_for_finish()\n",
    "            \n",
    "            # CRITICAL FIX: Check if run actually scraped pages, not just if it \"succeeded\"\n",
    "            if run_info and \"status\" in run_info:\n",
    "                status = run_info.get(\"status\")\n",
    "                \n",
    "                # Even if status is \"SUCCEEDED\", verify dataset actually has items\n",
    "                if status == \"SUCCEEDED\" and \"defaultDatasetId\" in run:\n",
    "                    # Quick check if dataset has any items\n",
    "                    try:\n",
    "                        dataset_check = client.dataset(run[\"defaultDatasetId\"])\n",
    "                        time.sleep(2)  # Brief wait for dataset to be ready\n",
    "                        test_items = dataset_check.list_items(limit=1, clean=True)\n",
    "                        \n",
    "                        if test_items.items and len(test_items.items) > 0:\n",
    "                            # Dataset has items - true success!\n",
    "                            print(f\"  ‚úÖ Run succeeded with data\")\n",
    "                            return run, None\n",
    "                        else:\n",
    "                            # Status says \"SUCCEEDED\" but dataset is EMPTY - this is a failure!\n",
    "                            print(f\"  ‚ö†Ô∏è Run completed but dataset is empty (likely 403 block)\")\n",
    "                            # Treat as 403 and retry\n",
    "                            if attempt < max_retries - 1:\n",
    "                                wait_time = 30 * (2 ** attempt)\n",
    "                                print(f\"  üîÑ Retrying in {wait_time}s...\")\n",
    "                                time.sleep(wait_time)\n",
    "                                continue\n",
    "                            else:\n",
    "                                return None, \"Dataset empty after all retries (403 blocking)\"\n",
    "                    except Exception as e:\n",
    "                        print(f\"  ‚ö†Ô∏è Could not verify dataset: {e}\")\n",
    "                        # If we can't check dataset, try to use the run anyway\n",
    "                        return run, None\n",
    "                \n",
    "                elif status != \"SUCCEEDED\":\n",
    "                    # Check error message for 403\n",
    "                    error_msg = str(run_info)\n",
    "                    if \"403\" in error_msg or \"blocked\" in error_msg.lower():\n",
    "                        if attempt < max_retries - 1:\n",
    "                            wait_time = 30 * (2 ** attempt)  # 30s, 60s, 120s\n",
    "                            print(f\"  üö´ Request blocked (403), waiting {wait_time}s before retry...\")\n",
    "                            time.sleep(wait_time)\n",
    "                            continue\n",
    "            \n",
    "            return run, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            if \"403\" in error_str or \"blocked\" in error_str.lower():\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = 30 * (2 ** attempt)\n",
    "                    print(f\"  üö´ Request blocked (403), waiting {wait_time}s before retry...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "            return None, f\"Apify call failed: {str(e)}\"\n",
    "    \n",
    "    return None, \"Max retries exceeded due to 403 blocking\"\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for idx, (i, row) in enumerate(acra_data_filtered_by_industry.iterrows(), 1):\n",
    "    uen = str(row[\"UEN\"]).strip()\n",
    "    print(f\"\\nüîé Processing {uen} ({idx}/{len(acra_data_filtered_by_industry)})\")\n",
    "\n",
    "    # Build pageFunction with proper escaping and improved error handling\n",
    "    page_function = f\"\"\"\n",
    "    async function pageFunction(context) {{\n",
    "        const {{ page, log, request }} = context;\n",
    "        const uen = \"{uen}\";\n",
    "        log.info(\"Visiting RecordOwl for UEN: \" + uen);\n",
    "\n",
    "        try {{\n",
    "            // Step 1: Wait for search input\n",
    "            await page.waitForSelector(\"input[placeholder='Search company name, industry, or address']\", {{ timeout: 30000 }});\n",
    "            log.info(\"Search input found\");\n",
    "            \n",
    "            // Step 2: Type UEN into search box with error handling and navigation protection\n",
    "            try {{\n",
    "                // Wait for page to be stable (no navigation happening)\n",
    "                log.info(\"Waiting for page to stabilize...\");\n",
    "                await new Promise(r => setTimeout(r, 2000)); // Wait for any auto-navigation to complete\n",
    "                \n",
    "                // Wait for input to be present and stable\n",
    "                await page.waitForSelector(\"input[placeholder='Search company name, industry, or address']\", {{ \n",
    "                    timeout: 30000,\n",
    "                    visible: true \n",
    "                }});\n",
    "                \n",
    "                // Re-find input right before typing (in case page navigated)\n",
    "                let input = await page.$(\"input[placeholder='Search company name, industry, or address']\");\n",
    "                if (!input) {{\n",
    "                    log.error(\"Input element not found after wait\");\n",
    "                    return {{ status: 'error', uen, error: 'Input element not found' }};\n",
    "                }}\n",
    "                \n",
    "                // Clear and type with retry logic\n",
    "                let typed = false;\n",
    "                for (let attempt = 0; attempt < 3; attempt++) {{\n",
    "                    try {{\n",
    "                        // Re-find input on each attempt (in case context was destroyed)\n",
    "                        input = await page.$(\"input[placeholder='Search company name, industry, or address']\");\n",
    "                        if (!input) {{\n",
    "                            throw new Error(\"Input not found on attempt \" + (attempt + 1));\n",
    "                        }}\n",
    "                        \n",
    "                        // Click to focus\n",
    "                        await input.click({{ clickCount: 3 }});\n",
    "                        await new Promise(r => setTimeout(r, 300)); // Small delay after click\n",
    "                        \n",
    "                        // Clear input first\n",
    "                        await page.evaluate((selector) => {{\n",
    "                            const el = document.querySelector(selector);\n",
    "                            if (el) el.value = '';\n",
    "                        }}, \"input[placeholder='Search company name, industry, or address']\");\n",
    "                        \n",
    "                        // Type UEN\n",
    "                        await input.type(uen, {{ delay: 100 }});\n",
    "                        typed = true;\n",
    "                        log.info(\"UEN typed successfully: \" + uen);\n",
    "                        break;\n",
    "                    }} catch (typeErr) {{\n",
    "                        if (typeErr.message.includes(\"Execution context was destroyed\") || \n",
    "                            typeErr.message.includes(\"navigation\")) {{\n",
    "                            log.info(\"Navigation occurred during typing (attempt \" + (attempt + 1) + \"/3), retrying...\");\n",
    "                            // Wait for page to stabilize after navigation\n",
    "                            await new Promise(r => setTimeout(r, 2000));\n",
    "                            // Re-wait for input\n",
    "                            await page.waitForSelector(\"input[placeholder='Search company name, industry, or address']\", {{ \n",
    "                                timeout: 10000,\n",
    "                                visible: true \n",
    "                            }});\n",
    "                            continue;\n",
    "                        }} else {{\n",
    "                            throw typeErr;\n",
    "                        }}\n",
    "                    }}\n",
    "                }}\n",
    "                \n",
    "                if (!typed) {{\n",
    "                    log.error(\"Failed to type UEN after all retries\");\n",
    "                    return {{ status: 'error', uen, error: 'Failed to type UEN after retries' }};\n",
    "                }}\n",
    "                \n",
    "            }} catch (typeErr) {{\n",
    "                log.error(\"Error typing UEN: \" + typeErr.message);\n",
    "                return {{ status: 'error', uen, error: 'Failed to type UEN: ' + typeErr.message }};\n",
    "            }}\n",
    "\n",
    "            // Step 3: Submit search with flexible waiting strategy\n",
    "            try {{\n",
    "                log.info(\"Clicking submit button...\");\n",
    "                \n",
    "                // Click submit button first\n",
    "                await page.click(\"button[type='submit']\");\n",
    "                log.info(\"Submit button clicked\");\n",
    "                \n",
    "                // Wait for either navigation OR results to appear (more flexible)\n",
    "                // Strategy: Wait for results to appear, with navigation as optional\n",
    "                try {{\n",
    "                    // Option 1: Wait for navigation (if it happens) - non-blocking\n",
    "                    const navigationPromise = page.waitForNavigation({{ \n",
    "                        waitUntil: 'networkidle2', \n",
    "                        timeout: 30000 \n",
    "                    }}).catch(() => {{\n",
    "                        log.info(\"Navigation did not occur (may be client-side routing)\");\n",
    "                        return null;\n",
    "                    }});\n",
    "                    \n",
    "                    // Option 2: Wait for results to appear (more reliable)\n",
    "                    const resultsPromise = page.waitForSelector(\"a[href*='/company/']\", {{ \n",
    "                        timeout: 60000 \n",
    "                    }});\n",
    "                    \n",
    "                    // Wait for either navigation or results (whichever happens first)\n",
    "                    await Promise.race([\n",
    "                        navigationPromise,\n",
    "                        resultsPromise\n",
    "                    ]);\n",
    "                    \n",
    "                    // Give page time to stabilize\n",
    "                    await new Promise(r => setTimeout(r, 2000));\n",
    "                    log.info(\"Page stabilized after submit\");\n",
    "                    \n",
    "                }} catch (waitErr) {{\n",
    "                    // If both navigation and results wait failed, try one more time for results\n",
    "                    log.info(\"Initial wait failed, trying again for results: \" + waitErr.message);\n",
    "                    try {{\n",
    "                        await page.waitForSelector(\"a[href*='/company/']\", {{ timeout: 30000 }});\n",
    "                        log.info(\"Results found on retry\");\n",
    "                    }} catch (retryErr) {{\n",
    "                        log.info(\"No company links found after submit, might be not found\");\n",
    "                        return {{ status: 'not_found', uen }};\n",
    "                    }}\n",
    "                }}\n",
    "                \n",
    "            }} catch (navErr) {{\n",
    "                log.error(\"Error during submit: \" + navErr.message);\n",
    "                // Don't fail immediately - try to check if results are already there\n",
    "                try {{\n",
    "                    const hasResults = await page.$(\"a[href*='/company/']\");\n",
    "                    if (hasResults) {{\n",
    "                        log.info(\"Results found despite submit error\");\n",
    "                    }} else {{\n",
    "                        return {{ status: 'error', uen, error: 'Submit failed: ' + navErr.message }};\n",
    "                    }}\n",
    "                }} catch (checkErr) {{\n",
    "                    return {{ status: 'error', uen, error: 'Submit failed: ' + navErr.message }};\n",
    "                }}\n",
    "            }}\n",
    "\n",
    "            // Step 4: Verify search results are present\n",
    "            log.info(\"Verifying company links are present...\");\n",
    "            try {{\n",
    "                // Double-check that results are actually there\n",
    "                await page.waitForSelector(\"a[href*='/company/']\", {{ timeout: 10000 }});\n",
    "                log.info(\"Company links confirmed\");\n",
    "            }} catch (e) {{\n",
    "                log.info(\"No company links found, might be not found\");\n",
    "                return {{ status: 'not_found', uen }};\n",
    "            }}\n",
    "\n",
    "            // Step 5: Find the correct company link (in a new execution context after navigation)\n",
    "            let companyLink;\n",
    "            try {{\n",
    "                companyLink = await page.evaluate((searchUen) => {{\n",
    "                    const links = Array.from(document.querySelectorAll(\"a[href*='/company/']\"));\n",
    "                    \n",
    "                    // Find link where UEN appears in text or URL\n",
    "                    const uenUpper = searchUen.toUpperCase();\n",
    "                    const uenLower = searchUen.toLowerCase();\n",
    "                    \n",
    "                    for (const a of links) {{\n",
    "                        const text = (a.innerText || \"\").toUpperCase();\n",
    "                        const href = (a.href || \"\").toLowerCase();\n",
    "                        \n",
    "                        // Check if UEN appears in text or URL (case-insensitive)\n",
    "                        if (text.includes(uenUpper) || href.includes(uenLower)) {{\n",
    "                            console.log(\"Found UEN match: \" + a.href);\n",
    "                            return a.href;\n",
    "                        }}\n",
    "                    }}\n",
    "                    \n",
    "                    // Fallback: Take first company link if available\n",
    "                    if (links.length > 0) {{\n",
    "                        console.log(\"No exact UEN match, using first link: \" + links[0].href);\n",
    "                        return links[0].href;\n",
    "                    }}\n",
    "                    \n",
    "                    console.log(\"No company links found\");\n",
    "                    return null;\n",
    "                }}, uen);\n",
    "                \n",
    "                if (!companyLink) {{\n",
    "                    log.info(\"No company links found on results page\");\n",
    "                    return {{ status: 'not_found', uen }};\n",
    "                }}\n",
    "                log.info(\"Found company link: \" + companyLink);\n",
    "            }} catch (evalErr) {{\n",
    "                log.error(\"Error finding company link: \" + evalErr.message);\n",
    "                return {{ status: 'error', uen, error: 'Failed to find company link: ' + evalErr.message }};\n",
    "            }}\n",
    "\n",
    "            // Step 6: Navigate to company page if not already there\n",
    "            if (page.url() !== companyLink) {{\n",
    "                try {{\n",
    "                    log.info(\"Navigating to company page...\");\n",
    "                    await page.goto(companyLink, {{ \n",
    "                        waitUntil: 'networkidle2', \n",
    "                        timeout: 60000 \n",
    "                    }});\n",
    "                    log.info(\"Company page loaded\");\n",
    "                    \n",
    "                    // Critical: Wait for page to fully stabilize\n",
    "                    await new Promise(r => setTimeout(r, 5000));\n",
    "                }} catch (gotoErr) {{\n",
    "                    log.error(\"Error navigating to company page: \" + gotoErr.message);\n",
    "                    return {{ status: 'error', uen, error: 'Failed to load company page: ' + gotoErr.message }};\n",
    "                }}\n",
    "            }}\n",
    "\n",
    "            // Step 7: Wait for content to load (with multiple fallback strategies)\n",
    "            log.info(\"Waiting for page content...\");\n",
    "            try {{\n",
    "                await Promise.race([\n",
    "                    page.waitForSelector('dt', {{ timeout: 15000 }}),\n",
    "                    page.waitForSelector('dl', {{ timeout: 15000 }}),\n",
    "                    page.waitForSelector('.max-w-7xl', {{ timeout: 15000 }}),\n",
    "                    new Promise(r => setTimeout(r, 10000)) // Fallback: just wait 10s\n",
    "                ]);\n",
    "                log.info(\"Content loaded\");\n",
    "            }} catch (contentErr) {{\n",
    "                log.info(\"Content wait timeout, but continuing: \" + contentErr.message);\n",
    "            }}\n",
    "            \n",
    "            // Additional stabilization wait\n",
    "            await new Promise(r => setTimeout(r, 3000));\n",
    "            \n",
    "            // Step 7.5: VERIFY we're on the correct company page\n",
    "            log.info(\"Verifying UEN on company page...\");\n",
    "            try {{\n",
    "                const pageUEN = await page.evaluate((searchUen) => {{\n",
    "                    const pageText = (document.body.innerText || \"\").toUpperCase();\n",
    "                    return pageText.includes(searchUen.toUpperCase());\n",
    "                }}, uen);\n",
    "                \n",
    "                if (pageUEN) {{\n",
    "                    log.info(\"‚úì UEN verified on page: \" + uen);\n",
    "                }} else {{\n",
    "                    log.info(\"‚ö† Warning: UEN not found in page text, but continuing...\");\n",
    "                }}\n",
    "            }} catch (verifyErr) {{\n",
    "                log.info(\"Could not verify UEN, but continuing: \" + verifyErr.message);\n",
    "            }}\n",
    "            \n",
    "            // Step 8: Extract content (in stable context) - ONLY VISIBLE ELEMENTS\n",
    "            let html_content, title, url;\n",
    "            try {{\n",
    "                // Get only the visible HTML content by removing hidden elements\n",
    "                await page.evaluate(() => {{\n",
    "                    // Remove all elements that are hidden from view\n",
    "                    const allElements = document.querySelectorAll('*');\n",
    "                    allElements.forEach(el => {{\n",
    "                        const style = window.getComputedStyle(el);\n",
    "                        // Mark hidden elements with a special attribute\n",
    "                        if (style.display === 'none' || \n",
    "                            style.visibility === 'hidden' || \n",
    "                            style.opacity === '0' ||\n",
    "                            el.hidden ||\n",
    "                            el.hasAttribute('hidden')) {{\n",
    "                            el.setAttribute('data-hidden-element', 'true');\n",
    "                        }}\n",
    "                    }});\n",
    "                }});\n",
    "                \n",
    "                html_content = await page.content();\n",
    "                title = await page.title();\n",
    "                url = page.url();\n",
    "                log.info(\"Successfully extracted HTML content (\" + html_content.length + \" chars)\");\n",
    "            }} catch (extractErr) {{\n",
    "                log.error(\"Error extracting content: \" + extractErr.message);\n",
    "                return {{ status: 'error', uen, error: 'Failed to extract content: ' + extractErr.message }};\n",
    "            }}\n",
    "\n",
    "            return {{ status: 'success', uen, url, title, html_content }};\n",
    "            \n",
    "        }} catch (err) {{\n",
    "            log.error(\"Unexpected error in pageFunction: \" + err.message);\n",
    "            log.error(\"Stack: \" + err.stack);\n",
    "            return {{ status: 'error', uen, error: err.message }};\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    run_input = {\n",
    "        \"startUrls\": [{\"url\": \"https://recordowl.com/\"}],\n",
    "        \"useChrome\": True,\n",
    "        \"headless\": True,\n",
    "        \"stealth\": True,\n",
    "        \"pageFunction\": page_function,\n",
    "        \"ignoreSslErrors\": False,\n",
    "        \"ignoreCorsAndCsp\": False,\n",
    "        \"maxRequestRetries\": 3,  # Increased retry attempts\n",
    "        \"maxRequestsPerCrawl\": 1,  # One page per run\n",
    "        \"maxConcurrency\": 1,  # No parallel requests\n",
    "        \"pageLoadTimeoutSecs\": 90,  # Optimized timeout\n",
    "        \"pageFunctionTimeoutSecs\": 180,  # 3 minutes for pageFunction\n",
    "        \"waitUntil\": [\"networkidle2\"],  # Wait for network to be idle\n",
    "        # OPTIMIZED: Residential proxies with recommended rotation\n",
    "        \"proxyConfiguration\": {\n",
    "            \"useApifyProxy\": True,\n",
    "            \"apifyProxyGroups\": [\"RESIDENTIAL\"],  # Residential IPs less likely to be blocked\n",
    "        },\n",
    "        \"proxyRotation\": \"RECOMMENDED\",  # Optimal proxy rotation strategy\n",
    "    }\n",
    "\n",
    "    # Use retry logic for 403 errors (5 attempts = more chances to recover)\n",
    "    run, error = run_apify_with_retry(client, run_input, uen, max_retries=5)\n",
    "\n",
    "    if error or not run:\n",
    "        print(f\"  ‚ùå Apify call failed for {uen}: {error}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": None,\n",
    "            \"Error\": error or \"No run returned\"\n",
    "        })\n",
    "        time.sleep(10)  # Longer sleep after failure\n",
    "        continue\n",
    "\n",
    "    if not run or \"defaultDatasetId\" not in run:\n",
    "        print(f\"  ‚ö†Ô∏è No valid dataset returned for {uen}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": None,\n",
    "            \"Error\": \"No dataset returned\"\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Wait for dataset to be ready with progressive checking\n",
    "    print(f\"  ‚è≥ Waiting for dataset to be ready...\")\n",
    "    time.sleep(5)  # Initial wait\n",
    "    \n",
    "    # Try to fetch dataset with progressive waits\n",
    "    dataset_client = client.dataset(run[\"defaultDatasetId\"])\n",
    "    for check_attempt in range(3):\n",
    "        try:\n",
    "            # Quick check if dataset has items\n",
    "            test_fetch = dataset_client.list_items(limit=1, clean=True)\n",
    "            if test_fetch.items:\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if check_attempt < 2:\n",
    "            additional_wait = 3 * (check_attempt + 1)\n",
    "            print(f\"  ‚è≥ Dataset not ready, waiting {additional_wait}s more...\")\n",
    "            time.sleep(additional_wait)\n",
    "    \n",
    "    scraped_html, record_owl_url = None, None\n",
    "    \n",
    "    # Fetch dataset items with improved error handling\n",
    "    dataset_items = fetch_dataset_items_safe(\n",
    "        dataset_client,\n",
    "        max_retries=5,\n",
    "        initial_wait=5  # Increased from 3 to 5\n",
    "    )\n",
    "    \n",
    "    # Process items\n",
    "    if not dataset_items:\n",
    "        print(f\"  ‚ö†Ô∏è Dataset is empty - no items returned!\")\n",
    "    else:\n",
    "        print(f\"  üìä Dataset has {len(dataset_items)} item(s)\")\n",
    "    \n",
    "    for item in dataset_items:\n",
    "        if item.get(\"status\") == \"success\":\n",
    "            scraped_html = item.get(\"html_content\", \"\")\n",
    "            record_owl_url = item.get(\"url\")\n",
    "            if scraped_html:\n",
    "                print(f\"  ‚úÖ Successfully scraped {uen} ({len(scraped_html)} chars of HTML)\")\n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è Status is 'success' but html_content is empty for {uen}\")\n",
    "        elif item.get(\"status\") == \"not_found\":\n",
    "            print(f\"  ‚ö†Ô∏è Company not found for UEN {uen}\")\n",
    "        elif item.get(\"status\") == \"error\":\n",
    "            print(f\"  ‚ùå Error for {uen}: {item.get('error')}\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è Unknown item status for {uen}: {item.get('status')}\")\n",
    "            print(f\"  üìã Item keys: {list(item.keys())}\")\n",
    "\n",
    "    if not scraped_html:\n",
    "        # Determine the specific reason for failure\n",
    "        if not dataset_items:\n",
    "            error_reason = \"Dataset empty (likely 403 block at Apify level)\"\n",
    "            print(f\"  ‚ùå {error_reason}\")\n",
    "        elif any(item.get(\"status\") == \"not_found\" for item in dataset_items):\n",
    "            error_reason = \"Company not found on RecordOwl\"\n",
    "            print(f\"  ‚ùå {error_reason}\")\n",
    "        elif any(item.get(\"status\") == \"error\" for item in dataset_items):\n",
    "            error_details = [item.get(\"error\", \"Unknown\") for item in dataset_items if item.get(\"status\") == \"error\"]\n",
    "            error_reason = f\"Scraping error: {error_details[0] if error_details else 'Unknown'}\"\n",
    "            print(f\"  ‚ùå {error_reason}\")\n",
    "        else:\n",
    "            error_reason = \"No HTML content retrieved (unknown reason)\"\n",
    "            print(f\"  ‚ö†Ô∏è {error_reason}\")\n",
    "            # Debug: show what's in dataset items\n",
    "            if dataset_items:\n",
    "                print(f\"  üîç DEBUG - First item: {dataset_items[0]}\")\n",
    "        \n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": record_owl_url or None,\n",
    "            \"Error\": error_reason\n",
    "        })\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "\n",
    "    # Parse HTML\n",
    "    try:\n",
    "        soup = BeautifulSoup(scraped_html, \"html.parser\")\n",
    "        \n",
    "        # ========== CLEAN HTML: REMOVE HIDDEN/UNWANTED ELEMENTS ==========\n",
    "        # Remove hidden elements\n",
    "        for elem in soup.find_all(attrs={\"data-hidden-element\": \"true\"}):\n",
    "            elem.decompose()\n",
    "        \n",
    "        # Target company overview (exclude officer/director personal data)\n",
    "        overview_tab = (soup.select_one(\"#overview\") or \n",
    "                       soup.select_one(\"[aria-labelledby*='overview']\") or\n",
    "                       soup.select_one(\"div[role='tabpanel']\"))\n",
    "        \n",
    "        if overview_tab:\n",
    "            parent = overview_tab\n",
    "        else:\n",
    "            parent = soup.select_one(\"div.max-w-7xl.mx-auto.lg\\\\:py-6.sm\\\\:px-6.lg\\\\:px-8\")\n",
    "            if parent:\n",
    "                # Remove officer/shareholder sections\n",
    "                for unwanted in parent.select(\"#officers, #shareholders, #appointments, \"\n",
    "                                             \"[id*='officer'], [id*='shareholder'], [id*='appointment']\"):\n",
    "                    unwanted.decompose()\n",
    "        \n",
    "        # Remove non-visible content\n",
    "        if parent:\n",
    "            for unwanted in parent.select(\"script, style, noscript, [style*='display:none']\"):\n",
    "                unwanted.decompose()\n",
    "        # ========== END CLEAN HTML ==========\n",
    "\n",
    "        emails, phones, website = [], [], None\n",
    "        facebook_links, linkedin_links, instagram_links, tiktok_links = [], [], [], []\n",
    "        \n",
    "        # Helper function to check if element is visible\n",
    "        def is_element_visible(element):\n",
    "            \"\"\"Check if a BeautifulSoup element appears to be visible (not hidden).\"\"\"\n",
    "            if element is None:\n",
    "                return False\n",
    "            # Check for hidden attribute\n",
    "            if element.has_attr('data-hidden-element'):\n",
    "                return False\n",
    "            # Check for common hidden styles\n",
    "            style = element.get('style', '')\n",
    "            if any(hidden_style in style.lower() for hidden_style in ['display:none', 'display: none', 'visibility:hidden', 'visibility: hidden']):\n",
    "                return False\n",
    "            # Check for hidden/aria-hidden attributes\n",
    "            if element.get('hidden') or element.get('aria-hidden') == 'true':\n",
    "                return False\n",
    "            return True\n",
    "\n",
    "        if parent:\n",
    "            # Extract emails\n",
    "            for a in parent.select(\"a[href^=mailto]\"):\n",
    "                email = a.get(\"href\", \"\").replace(\"mailto:\", \"\").strip()\n",
    "                if email and email not in emails and \"@\" in email:\n",
    "                    emails.append(email)\n",
    "\n",
    "            # ========== COMPREHENSIVE SINGAPORE PHONE EXTRACTION ==========\n",
    "            # \n",
    "            # ‚úÖ HANDLES ALL POSSIBLE SINGAPORE PHONE NUMBER FORMATS:\n",
    "            # \n",
    "            #    International formats with country code +65:\n",
    "            #      ‚Ä¢ +65 6694 5996       (standard international)\n",
    "            #      ‚Ä¢ +65-6694-5996       (with dashes)\n",
    "            #      ‚Ä¢ +65.6694.5996       (with dots)\n",
    "            #      ‚Ä¢ +656694 5996        (partial spacing)\n",
    "            #      ‚Ä¢ +6566945996         (no spacing)\n",
    "            #      ‚Ä¢ +65 66945996        (no spacing in local part)\n",
    "            #    \n",
    "            #    With parentheses:\n",
    "            #      ‚Ä¢ (+65) 6694 5996     (parentheses with plus)\n",
    "            #      ‚Ä¢ (65) 6694 5996      (parentheses without plus)\n",
    "            #      ‚Ä¢ +65(6694)5996       (area code style)\n",
    "            #      ‚Ä¢ +65 (6694) 5996     (with spaces)\n",
    "            #    \n",
    "            #    Local formats without country code:\n",
    "            #      ‚Ä¢ 6566945996          (country code without plus, no spaces)\n",
    "            #      ‚Ä¢ 65 6694 5996        (country code with spaces)\n",
    "            #      ‚Ä¢ 65-6694-5996        (country code with dashes)\n",
    "            #      ‚Ä¢ 6694 5996           (8 digits with space)\n",
    "            #      ‚Ä¢ 66945996            (8 digits no space)\n",
    "            #      ‚Ä¢ 6694-5996           (8 digits with dash)\n",
    "            #      ‚Ä¢ 6694.5996           (8 digits with dot)\n",
    "            #      ‚Ä¢ 669 45996           (odd spacing patterns)\n",
    "            #    \n",
    "            #    Any combination of separators (spaces, dashes, dots, parentheses, slashes)\n",
    "            # \n",
    "            # ‚úÖ VALIDATION RULES:\n",
    "            #    ‚Ä¢ Mobile numbers: Start with 8 or 9 (e.g., 8123 4567, 9123 4567)\n",
    "            #    ‚Ä¢ Fixed line: Start with 6 (e.g., 6123 4567, 6694 5996)\n",
    "            #    ‚Ä¢ Length: Exactly 8 digits (local) or 10 digits (with country code 65)\n",
    "            #    ‚Ä¢ Country code: Singapore +65 only\n",
    "            #    ‚Ä¢ Dynamically rejects 20+ non-Singapore country codes\n",
    "            #    ‚Ä¢ Filters visible elements only (no hidden HTML data)\n",
    "            #    ‚Ä¢ Excludes personal contacts (officers, directors, shareholders)\n",
    "            # \n",
    "            # ‚ùå AUTOMATICALLY REJECTED:\n",
    "            #    ‚Ä¢ Non-Singapore country codes: +60 (Malaysia), +62 (Indonesia), +63 (Philippines),\n",
    "            #      +66 (Thailand), +81 (Japan), +82 (Korea), +84 (Vietnam), +86 (China), +91 (India), etc.\n",
    "            #    ‚Ä¢ Numbers with < 8 or incorrect digit count\n",
    "            #    ‚Ä¢ Numbers not starting with 6, 8, or 9 (after country code)\n",
    "            #    ‚Ä¢ Hidden or non-visible HTML elements\n",
    "            #    ‚Ä¢ Personal/officer contact information\n",
    "            # \n",
    "            # üì§ OUTPUT FORMAT:\n",
    "            #    All valid numbers are normalized to: +6512345678 (international format)\n",
    "            \n",
    "            def validate_sg_phone(digits_str):\n",
    "                \"\"\"\n",
    "                Validate and format Singapore phone number from digit-only string.\n",
    "                \n",
    "                This function accepts a string with all separators already removed (only digits)\n",
    "                and validates it against Singapore phone number rules. It dynamically rejects\n",
    "                numbers from other countries and only accepts valid Singapore formats.\n",
    "                \n",
    "                Args:\n",
    "                    digits_str (str): String containing only digits (e.g., \"6566945996\", \"66945996\")\n",
    "                \n",
    "                Returns:\n",
    "                    str or None: Formatted phone number as \"+6512345678\" if valid, None otherwise\n",
    "                \n",
    "                Examples:\n",
    "                    validate_sg_phone(\"6566945996\")   -> \"+6566945996\"    (country code + 8 digits)\n",
    "                    validate_sg_phone(\"66945996\")     -> \"+6566945996\"    (8 digits, add country code)\n",
    "                    validate_sg_phone(\"63378789\")     -> \"+6563378789\"    (8 digits, NOT rejected as +63)\n",
    "                    validate_sg_phone(\"60391312823\")  -> None             (Malaysia +60, rejected)\n",
    "                    validate_sg_phone(\"63123456789\")  -> None             (Philippines +63, rejected)\n",
    "                    validate_sg_phone(\"81234567\")     -> \"+6581234567\"    (mobile number)\n",
    "                \"\"\"\n",
    "                if not digits_str or len(digits_str) < 8:\n",
    "                    return None\n",
    "                \n",
    "                # ========== DYNAMIC NON-SINGAPORE COUNTRY CODE BLACKLIST ==========\n",
    "                # Comprehensive list of international country codes that are NOT Singapore\n",
    "                # This prevents false positives from extracting parts of non-SG numbers\n",
    "                non_sg_codes = [\n",
    "                    # ASEAN Countries\n",
    "                    \"60\",   # Malaysia\n",
    "                    \"62\",   # Indonesia\n",
    "                    \"63\",   # Philippines\n",
    "                    \"66\",   # Thailand\n",
    "                    \"84\",   # Vietnam\n",
    "                    \"95\",   # Myanmar\n",
    "                    \"855\",  # Cambodia\n",
    "                    \"856\",  # Laos\n",
    "                    \"880\",  # Bangladesh\n",
    "                    \n",
    "                    # East Asia\n",
    "                    \"81\",   # Japan\n",
    "                    \"82\",   # South Korea\n",
    "                    \"86\",   # China\n",
    "                    \"852\",  # Hong Kong\n",
    "                    \"853\",  # Macau\n",
    "                    \"886\",  # Taiwan\n",
    "                    \n",
    "                    # South Asia\n",
    "                    \"91\",   # India\n",
    "                    \"92\",   # Pakistan\n",
    "                    \"93\",   # Afghanistan\n",
    "                    \"94\",   # Sri Lanka\n",
    "                    \n",
    "                    # Oceania\n",
    "                    \"61\",   # Australia\n",
    "                    \"64\",   # New Zealand\n",
    "                    \n",
    "                    # Others\n",
    "                    \"90\",   # Turkey\n",
    "                    \"98\",   # Iran\n",
    "                ]\n",
    "                \n",
    "                # ========== STEP 1: VALIDATE 8-DIGIT LOCAL FORMAT FIRST ==========\n",
    "                # CRITICAL FIX: Check 8-digit local numbers BEFORE country code rejection\n",
    "                # This prevents false positives like \"6337 8789\" being rejected as Philippines \"+63\"\n",
    "                \n",
    "                # FORMAT 1: Exactly 8 digits starting with 6/8/9 (local format, no country code)\n",
    "                # Handles: 6694 5996, 66945996, 6337 8789, 6694-5996, 6694.5996, 669 45996, etc.\n",
    "                # After stripping separators: 66945996, 63378789, etc.\n",
    "                # Action: Add +65 country code prefix\n",
    "                # NOTE: Must check this BEFORE country code rejection to avoid false positives\n",
    "                if len(digits_str) == 8 and digits_str[0] in \"689\":\n",
    "                    return \"+65\" + digits_str\n",
    "                \n",
    "                # ========== STEP 2: REJECT NON-SINGAPORE COUNTRY CODES ==========\n",
    "                # For numbers with 9+ digits, reject if they start with non-SG country code\n",
    "                # This prevents extraction of parts of foreign numbers like \"+60 3-9131 2823\"\n",
    "                # NOTE: We skip this check for 8-digit numbers (handled above) to avoid false positives\n",
    "                if len(digits_str) >= 9:\n",
    "                    for code in non_sg_codes:\n",
    "                        if digits_str.startswith(code):\n",
    "                            return None  # Not a Singapore number\n",
    "                \n",
    "                # ========== STEP 3: VALIDATE 10-DIGIT INTERNATIONAL FORMAT ==========\n",
    "                \n",
    "                # FORMAT 2: Exactly 10 digits starting with 65 and third digit is 6/8/9\n",
    "                # Handles: +65 6694 5996, +6566945996, 6566945996, 65-6694-5996, etc.\n",
    "                # After stripping separators: 6566945996\n",
    "                if len(digits_str) == 10 and digits_str.startswith(\"65\") and digits_str[2] in \"689\":\n",
    "                    return \"+\" + digits_str\n",
    "                    \n",
    "                # FORMAT 3: More than 10 digits - search for valid SG pattern within string\n",
    "                # This handles edge cases where phone number might be concatenated with other digits\n",
    "                # Example: \"Contact: 6566945996 or email\" -> digits: \"6566945996\" \n",
    "                elif len(digits_str) > 10:\n",
    "                    # Search for the pattern \"65\" followed by valid SG local number (6/8/9...)\n",
    "                    for i in range(len(digits_str) - 9):\n",
    "                        if digits_str[i:i+2] == \"65\" and digits_str[i+2] in \"689\":\n",
    "                            # EXTRA VALIDATION: Ensure \"65\" is not part of another country code\n",
    "                            # For example, in \"865...\", the \"65\" might be part of Cambodia +855\n",
    "                            if i > 0:\n",
    "                                # Check if preceding digits form part of a blacklisted code\n",
    "                                prev_digits = digits_str[max(0, i-2):i]\n",
    "                                is_part_of_other_code = any(\n",
    "                                    code.endswith(prev_digits + \"65\") \n",
    "                                    for code in non_sg_codes\n",
    "                                )\n",
    "                                if is_part_of_other_code:\n",
    "                                    continue  # Skip this match, it's part of another country code\n",
    "                            \n",
    "                            # Valid Singapore number found\n",
    "                            return \"+\" + digits_str[i:i+10]\n",
    "                \n",
    "                # ========== STEP 3: REJECT ALL OTHER CASES ==========\n",
    "                # Don't attempt to force-extract or guess\n",
    "                # No \"last 8 digits\" fallback to prevent false positives\n",
    "                return None\n",
    "            \n",
    "            # Method 1: Extract from tel: links (most reliable)\n",
    "            tel_links = [link for link in parent.select(\"a[href^='tel:'], a[href^='tel']\") \n",
    "                        if is_element_visible(link)]\n",
    "            \n",
    "            for a in tel_links:\n",
    "                tel_href = a.get(\"href\", \"\").replace(\"tel:\", \"\").strip()\n",
    "                # Extract digits and validate (validation function handles rejection)\n",
    "                digits_only = re.sub(r\"\\D\", \"\", tel_href)\n",
    "                formatted = validate_sg_phone(digits_only)\n",
    "                if formatted and formatted not in phones:\n",
    "                    phones.append(formatted)\n",
    "            \n",
    "            # Method 2: Extract from dt/dd structure (company info fields)\n",
    "            company_keywords = [\"company contact\", \"business contact\", \"office phone\", \n",
    "                              \"main phone\", \"business phone\", \"company phone\", \"contact number\", \n",
    "                              \"phone\", \"tel\", \"mobile\", \"call\", \"contact no\"]\n",
    "            exclude_keywords = [\"officer\", \"charge\", \"employee\", \"shareholder\", \"director\", \n",
    "                              \"registration\", \"person\", \"individual\", \"member\", \"partner\",\n",
    "                              \"manager\", \"owner\", \"proprietor\", \"authorized\", \"representative\",\n",
    "                              \"appointment\", \"designation\", \"name of\", \"appointed\"]\n",
    "            \n",
    "            visible_dt_tags = [dt for dt in parent.select(\"dt\") if is_element_visible(dt)]\n",
    "            \n",
    "            for dt in visible_dt_tags:\n",
    "                dt_text = dt.get_text(strip=True).lower()\n",
    "                \n",
    "                # Only extract company-level contacts (not personal)\n",
    "                is_company = any(kw in dt_text for kw in company_keywords)\n",
    "                is_personal = any(excl in dt_text for excl in exclude_keywords)\n",
    "                \n",
    "                if is_company and not is_personal:\n",
    "                    dd = dt.find_next_sibling(\"dd\")\n",
    "                    if dd and is_element_visible(dd):\n",
    "                        number_text = dd.get_text(\" \", strip=True)\n",
    "                        # Extract digits and validate (validation function handles rejection)\n",
    "                        all_digits = re.sub(r\"\\D\", \"\", number_text)\n",
    "                        formatted = validate_sg_phone(all_digits)\n",
    "                        if formatted and formatted not in phones:\n",
    "                            phones.append(formatted)\n",
    "            \n",
    "            # Method 3: Fallback text search (only if no phones found via structured data)\n",
    "            # This method uses comprehensive regex patterns to find phone numbers in free text\n",
    "            if not phones:\n",
    "                full_text = parent.get_text()\n",
    "                \n",
    "                # COMPREHENSIVE REGEX PATTERNS for all Singapore phone number formats\n",
    "                # Each pattern handles different separator combinations (spaces, dashes, dots, parentheses)\n",
    "                sg_patterns = [\n",
    "                    # Pattern 1: International format with + and any separators\n",
    "                    # Matches: +65 6694 5996, +65-6694-5996, +65.6694.5996, +656694 5996, +6566945996\n",
    "                    r\"\\+[\\s\\-\\.]*65[\\s\\-\\.]*[689][\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d\",\n",
    "                    \n",
    "                    # Pattern 2: Parentheses format (+65) or (65)\n",
    "                    # Matches: (+65) 6694 5996, (65) 6694 5996, (+65)66945996, (65)6694-5996\n",
    "                    r\"\\([\\s\\-\\.]*\\+?[\\s\\-\\.]*65[\\s\\-\\.]*\\)[\\s\\-\\.]*[689][\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d\",\n",
    "                    \n",
    "                    # Pattern 3: Country code in middle with parentheses\n",
    "                    # Matches: +65(6694)5996, +65 (6694) 5996, 65(6694)5996\n",
    "                    r\"\\+?[\\s\\-\\.]*65[\\s\\-\\.]*\\([\\s\\-\\.]*[689][\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\)[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d\",\n",
    "                    \n",
    "                    # Pattern 4: Country code without + (with mandatory separator to avoid false matches)\n",
    "                    # Matches: 65 6694 5996, 65-6694-5996, 65.6694.5996\n",
    "                    # Uses negative lookbehind/lookahead to ensure not part of longer number\n",
    "                    r\"(?<!\\d)65[\\s\\-\\.]+[689][\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d(?!\\d)\",\n",
    "                    \n",
    "                    # Pattern 5: 8-digit local format (with any separators)\n",
    "                    # Matches: 6694 5996, 66945996, 6694-5996, 6694.5996, 669 45996\n",
    "                    # Uses negative lookbehind/lookahead to avoid matching parts of longer numbers\n",
    "                    r\"(?<!\\d)[689][\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d(?!\\d)\",\n",
    "                    \n",
    "                    # Pattern 6: Country code without separator (edge case)\n",
    "                    # Matches: 6566945996 (but only if preceded/followed by non-digit)\n",
    "                    r\"(?<!\\d)65[689]\\d{7}(?!\\d)\",\n",
    "                ]\n",
    "                \n",
    "                for pattern in sg_patterns:\n",
    "                    matches = re.findall(pattern, full_text)\n",
    "                    for match in matches:\n",
    "                        # Strip all non-digit characters for validation\n",
    "                        digits = re.sub(r\"\\D\", \"\", match)\n",
    "                        # Validate using our comprehensive validation function\n",
    "                        formatted = validate_sg_phone(digits)\n",
    "                        if formatted and formatted not in phones:\n",
    "                            phones.append(formatted)\n",
    "            # ========== END PHONE EXTRACTION ==========\n",
    "\n",
    "            # Extract website\n",
    "            valid_websites = []\n",
    "            for a in parent.select(\"a[href^=http]\"):\n",
    "                href = a.get(\"href\", \"\").strip()\n",
    "                href_lower = href.lower()\n",
    "                if not any(domain in href_lower for domain in SOCIAL_MEDIA_DOMAINS):\n",
    "                    if not any(skip in href_lower for skip in [\"recordowl\", \"apify.com\"]):\n",
    "                        if any(tld in href for tld in [\".com\", \".sg\", \".net\", \".org\", \".co\"]):\n",
    "                            valid_websites.append(href)\n",
    "            website = valid_websites[0] if valid_websites else None\n",
    "\n",
    "        # Extract social media links from entire page\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            href = a[\"href\"].strip().lower()\n",
    "            if \"facebook.com\" in href and href not in facebook_links:\n",
    "                facebook_links.append(href)\n",
    "            elif \"linkedin.com\" in href and href not in linkedin_links:\n",
    "                linkedin_links.append(href)\n",
    "            elif \"instagram.com\" in href and href not in instagram_links:\n",
    "                instagram_links.append(href)\n",
    "            elif \"tiktok.com\" in href and href not in tiktok_links:\n",
    "                tiktok_links.append(href)\n",
    "\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": emails if emails else None,\n",
    "            \"Phones\": phones if phones else None,\n",
    "            \"Website\": website,\n",
    "            \"Facebook\": list(set(facebook_links)) if facebook_links else None,\n",
    "            \"LinkedIn\": list(set(linkedin_links)) if linkedin_links else None,\n",
    "            \"Instagram\": list(set(instagram_links)) if instagram_links else None,\n",
    "            \"TikTok\": list(set(tiktok_links)) if tiktok_links else None,\n",
    "            \"RecordOwl_Link\": record_owl_url,\n",
    "        })\n",
    "        \n",
    "        # Print extraction results with actual phone numbers\n",
    "        if phones:\n",
    "            phone_list = \", \".join(phones)\n",
    "            print(f\"  ‚úÖ Extracted: {len(emails) if emails else 0} email(s), {len(phones)} phone(s): {phone_list}\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ Extracted: {len(emails) if emails else 0} email(s), Phone: None found\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error parsing HTML for {uen}: {e}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": record_owl_url or None,\n",
    "            \"Error\": f\"HTML parsing error: {str(e)}\"\n",
    "        })\n",
    "\n",
    "    # Dynamic sleep time to avoid rate limiting and 403 blocks\n",
    "    # Longer delays reduce detection and blocking\n",
    "    base_sleep = 20  # Increased from 10\n",
    "    random_addition = (idx % 10) + 5  # 5-14 seconds random\n",
    "    sleep_time = base_sleep + random_addition  # 25-34 seconds total\n",
    "\n",
    "    print(f\"  üí§ Sleeping for {sleep_time}s before next request...\")\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "    # Extra delay after every 5th request to further avoid detection\n",
    "    if idx % 5 == 0:\n",
    "        extra_wait = 30\n",
    "        print(f\"  üõë Checkpoint pause: waiting extra {extra_wait}s...\")\n",
    "        time.sleep(extra_wait)\n",
    "\n",
    "New_Fresh_Leads = pd.DataFrame(all_results)\n",
    "print(\"\\n‚úÖ Scraping complete!\")\n",
    "print(f\"\\nüìä Results summary:\")\n",
    "print(f\"   Total processed: {len(New_Fresh_Leads)}\")\n",
    "print(f\"   With emails: {New_Fresh_Leads['Emails'].notna().sum()}\")\n",
    "print(f\"   With phones: {New_Fresh_Leads['Phones'].notna().sum()}\")\n",
    "print(f\"   With websites: {New_Fresh_Leads['Website'].notna().sum()}\")\n",
    "\n",
    "New_Fresh_Leads.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
