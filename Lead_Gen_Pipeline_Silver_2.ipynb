{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f1d1a2",
   "metadata": {},
   "source": [
    "# Data Mining in RecordOwl (Silver 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b601322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "import time\n",
    "import scrapy\n",
    "from scrapy_playwright.page import PageMethod\n",
    "from bs4 import BeautifulSoup\n",
    "import nest_asyncio\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "from apify_client import ApifyClient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c77d5d",
   "metadata": {},
   "source": [
    "### Ingesting from previous layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86bf8e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 rows from ./Staging/Bronze/bronze_data_1.parquet\n",
      "(10, 14)\n"
     ]
    }
   ],
   "source": [
    "parquet_path = \"./Staging/Bronze/bronze_data_1.parquet\"\n",
    "if os.path.exists(parquet_path):\n",
    "    acra_data_filtered_by_industry = pd.read_parquet(parquet_path, engine=\"fastparquet\")\n",
    "    print(f\"Loaded {len(acra_data_filtered_by_industry)} rows from {parquet_path}\")\n",
    "    print(acra_data_filtered_by_industry.shape)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Parquet file not found at {parquet_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6348882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ENTITY_NAME</th>\n",
       "      <th>BUSINESS_CONSTITUTION_DESCRIPTION</th>\n",
       "      <th>ENTITY_TYPE_DESCRIPTION</th>\n",
       "      <th>ENTITY_STATUS_DESCRIPTION</th>\n",
       "      <th>REGISTRATION_INCORPORATION_DATE</th>\n",
       "      <th>PRIMARY_SSIC_CODE</th>\n",
       "      <th>SECONDARY_SSIC_CODE</th>\n",
       "      <th>STREET_NAME</th>\n",
       "      <th>POSTAL_CODE</th>\n",
       "      <th>PARENT_INDUSTRY</th>\n",
       "      <th>INDUSTRY_TYPE</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53431824W</td>\n",
       "      <td>TUTORSVILLE.SG</td>\n",
       "      <td>SOLE-PROPRIETOR</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>07-04-2021</td>\n",
       "      <td>85509</td>\n",
       "      <td>na</td>\n",
       "      <td>COMPASSVALE WALK</td>\n",
       "      <td>540230</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202344030R</td>\n",
       "      <td>CHEM AFFINITY LEARNING CENTRE PTE. LTD.</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>04-11-2023</td>\n",
       "      <td>85509</td>\n",
       "      <td>na</td>\n",
       "      <td>BEACH ROAD</td>\n",
       "      <td>189695</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T15LL1885G</td>\n",
       "      <td>EDUREACH SERVICES LLP</td>\n",
       "      <td>None</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>11-11-2015</td>\n",
       "      <td>85509</td>\n",
       "      <td>74901</td>\n",
       "      <td>TAMPINES STREET 23</td>\n",
       "      <td>527201</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53200915X</td>\n",
       "      <td>THINK ARTS</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>06-10-2011</td>\n",
       "      <td>85509</td>\n",
       "      <td>na</td>\n",
       "      <td>YARROW GARDENS</td>\n",
       "      <td>455021</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201733719E</td>\n",
       "      <td>JUS INFANTS @ MACPHERSON PTE. LTD.</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>22-11-2017</td>\n",
       "      <td>88911</td>\n",
       "      <td>na</td>\n",
       "      <td>KALLANG PUDDING ROAD</td>\n",
       "      <td>349318</td>\n",
       "      <td>Others</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Social Services (Without Accommodations)</td>\n",
       "      <td>Infant Care Services; Child Minding Services F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53227394W</td>\n",
       "      <td>MATHS TABLET</td>\n",
       "      <td>SOLE-PROPRIETOR</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>04-12-2012</td>\n",
       "      <td>85509</td>\n",
       "      <td>na</td>\n",
       "      <td>ANG MO KIO AVENUE 10</td>\n",
       "      <td>560555</td>\n",
       "      <td>Others</td>\n",
       "      <td>Educational</td>\n",
       "      <td>Tuition &amp; Enrichment Centers</td>\n",
       "      <td>Training Courses N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202209857Z</td>\n",
       "      <td>YORK EDUCATION PTE. LTD.</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>22-03-2022</td>\n",
       "      <td>88911</td>\n",
       "      <td>85101</td>\n",
       "      <td>CASHEW ROAD</td>\n",
       "      <td>679637</td>\n",
       "      <td>Others</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Social Services (Without Accommodations)</td>\n",
       "      <td>Infant Care Services; Child Minding Services F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201711911W</td>\n",
       "      <td>MAPLEBEAR LEARNING GARDEN PTE. LTD.</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>01-05-2017</td>\n",
       "      <td>88911</td>\n",
       "      <td>88912</td>\n",
       "      <td>BRADDELL ROAD</td>\n",
       "      <td>579713</td>\n",
       "      <td>Others</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Social Services (Without Accommodations)</td>\n",
       "      <td>Infant Care Services; Child Minding Services F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>201540131W</td>\n",
       "      <td>4HANDS DENTAL ASSISTING TRAINING SCHOOL PTE. LTD.</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>10-11-2015</td>\n",
       "      <td>88991</td>\n",
       "      <td>na</td>\n",
       "      <td>JURONG WEST STREET 64</td>\n",
       "      <td>641684</td>\n",
       "      <td>Others</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Social Services (Without Accommodations)</td>\n",
       "      <td>Job Training And Vocational Rehabilitation Ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202337418G</td>\n",
       "      <td>OUT OF THE BOX ACADEMY (CLEMENTI) PTE. LTD.</td>\n",
       "      <td>None</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>18-09-2023</td>\n",
       "      <td>88912</td>\n",
       "      <td>85509</td>\n",
       "      <td>CLEMENTI AVENUE 3</td>\n",
       "      <td>120433</td>\n",
       "      <td>Others</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Social Services (Without Accommodations)</td>\n",
       "      <td>Student Care Services; Child Minding Services ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          UEN                                        ENTITY_NAME  \\\n",
       "0   53431824W                                     TUTORSVILLE.SG   \n",
       "1  202344030R            CHEM AFFINITY LEARNING CENTRE PTE. LTD.   \n",
       "2  T15LL1885G                              EDUREACH SERVICES LLP   \n",
       "3   53200915X                                         THINK ARTS   \n",
       "4  201733719E                 JUS INFANTS @ MACPHERSON PTE. LTD.   \n",
       "5   53227394W                                       MATHS TABLET   \n",
       "6  202209857Z                           YORK EDUCATION PTE. LTD.   \n",
       "7  201711911W                MAPLEBEAR LEARNING GARDEN PTE. LTD.   \n",
       "8  201540131W  4HANDS DENTAL ASSISTING TRAINING SCHOOL PTE. LTD.   \n",
       "9  202337418G        OUT OF THE BOX ACADEMY (CLEMENTI) PTE. LTD.   \n",
       "\n",
       "  BUSINESS_CONSTITUTION_DESCRIPTION           ENTITY_TYPE_DESCRIPTION  \\\n",
       "0                   SOLE-PROPRIETOR  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "1                              None                     LOCAL COMPANY   \n",
       "2                              None     LIMITED LIABILITY PARTNERSHIP   \n",
       "3                       PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "4                              None                     LOCAL COMPANY   \n",
       "5                   SOLE-PROPRIETOR  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "6                              None                     LOCAL COMPANY   \n",
       "7                              None                     LOCAL COMPANY   \n",
       "8                              None                     LOCAL COMPANY   \n",
       "9                              None                     LOCAL COMPANY   \n",
       "\n",
       "  ENTITY_STATUS_DESCRIPTION REGISTRATION_INCORPORATION_DATE  \\\n",
       "0                      LIVE                      07-04-2021   \n",
       "1              LIVE COMPANY                      04-11-2023   \n",
       "2                      LIVE                      11-11-2015   \n",
       "3                      LIVE                      06-10-2011   \n",
       "4              LIVE COMPANY                      22-11-2017   \n",
       "5                      LIVE                      04-12-2012   \n",
       "6              LIVE COMPANY                      22-03-2022   \n",
       "7              LIVE COMPANY                      01-05-2017   \n",
       "8              LIVE COMPANY                      10-11-2015   \n",
       "9              LIVE COMPANY                      18-09-2023   \n",
       "\n",
       "   PRIMARY_SSIC_CODE SECONDARY_SSIC_CODE            STREET_NAME POSTAL_CODE  \\\n",
       "0              85509                  na       COMPASSVALE WALK      540230   \n",
       "1              85509                  na             BEACH ROAD      189695   \n",
       "2              85509               74901     TAMPINES STREET 23      527201   \n",
       "3              85509                  na         YARROW GARDENS      455021   \n",
       "4              88911                  na   KALLANG PUDDING ROAD      349318   \n",
       "5              85509                  na   ANG MO KIO AVENUE 10      560555   \n",
       "6              88911               85101            CASHEW ROAD      679637   \n",
       "7              88911               88912          BRADDELL ROAD      579713   \n",
       "8              88991                  na  JURONG WEST STREET 64      641684   \n",
       "9              88912               85509      CLEMENTI AVENUE 3      120433   \n",
       "\n",
       "  PARENT_INDUSTRY INDUSTRY_TYPE                              SUB_INDUSTRY  \\\n",
       "0          Others   Educational              Tuition & Enrichment Centers   \n",
       "1          Others   Educational              Tuition & Enrichment Centers   \n",
       "2          Others   Educational              Tuition & Enrichment Centers   \n",
       "3          Others   Educational              Tuition & Enrichment Centers   \n",
       "4          Others      Hospital  Social Services (Without Accommodations)   \n",
       "5          Others   Educational              Tuition & Enrichment Centers   \n",
       "6          Others      Hospital  Social Services (Without Accommodations)   \n",
       "7          Others      Hospital  Social Services (Without Accommodations)   \n",
       "8          Others      Hospital  Social Services (Without Accommodations)   \n",
       "9          Others      Hospital  Social Services (Without Accommodations)   \n",
       "\n",
       "                                         DESCRIPTION  \n",
       "0                            Training Courses N.E.C.  \n",
       "1                            Training Courses N.E.C.  \n",
       "2                            Training Courses N.E.C.  \n",
       "3                            Training Courses N.E.C.  \n",
       "4  Infant Care Services; Child Minding Services F...  \n",
       "5                            Training Courses N.E.C.  \n",
       "6  Infant Care Services; Child Minding Services F...  \n",
       "7  Infant Care Services; Child Minding Services F...  \n",
       "8  Job Training And Vocational Rehabilitation Ser...  \n",
       "9  Student Care Services; Child Minding Services ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acra_data_filtered_by_industry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83b183e",
   "metadata": {},
   "source": [
    "### Mining RecordOwl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f852275e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”Ž Processing 53431824W (1/10)\n",
      "  ðŸ“¡ Starting Apify run for 53431824W (attempt 1/5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:34:37.672Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:34:37.673Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:34:37.714Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:34:37.888Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:34:38.553Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:34:39.387Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:34:40.667Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:34:40.879Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:05.852Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Visiting RecordOwl for UEN: 53431824W\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:05.858Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Search input found\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:05.860Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page to stabilize...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:09.105Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m UEN typed successfully: 53431824W\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:09.106Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Clicking submit button...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:09.124Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Submit button clicked\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:11.192Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Page stabilized after submit\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:11.194Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying company links are present...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:13.900Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company links confirmed\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:13.902Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Found company link: https://recordowl.com/company/tutorsville-sg\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:13.904Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Navigating to company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:15.918Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company page loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:20.918Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page content...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:20.925Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Content loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:23.926Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying UEN on company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:23.930Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m âœ“ UEN verified on page: 53431824W\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:23.971Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Successfully extracted HTML content (1080245 chars)\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:24.433Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:24.784Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":1,\"requestsFailed\":0,\"retryHistogram\":[1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":42600,\"requestsFinishedPerMinute\":1,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":42600,\"requestsTotal\":1,\"crawlerRuntimeMillis\":44187}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:24.785Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Finished! Total 1 requests: 1 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> 2025-11-11T08:35:24.815Z \u001b[32mINFO\u001b[39m  Puppeteer Scraper finished.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:qSqVEzPUBJ0vdt1gh]\u001b[0m -> Status: SUCCEEDED, Message: Finished! Total 1 requests: 1 succeeded, 0 failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â³ Waiting for run to complete...\n",
      "  âœ… Run succeeded with data\n",
      "  â³ Waiting for dataset to be ready...\n",
      "  ðŸ“Š Dataset has 1 item(s)\n",
      "  âœ… Successfully scraped 53431824W (1080245 chars of HTML)\n",
      "  âœ… Extracted: 0 email(s), Phone: None found\n",
      "  ðŸ’¤ Sleeping for 26s before next request...\n",
      "\n",
      "ðŸ”Ž Processing 202344030R (2/10)\n",
      "  ðŸ“¡ Starting Apify run for 202344030R (attempt 1/5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:10.225Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:10.228Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:10.282Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:10.471Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:11.177Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:11.316Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:12.589Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:12.859Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:18.910Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked - received 403 status code.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:18.911Z \u001b[90m {\"id\":\"XsOj8IqwoXyWgRx\",\"url\":\"https://recordowl.com/\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:30.402Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Visiting RecordOwl for UEN: 202344030R\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:30.462Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Search input found\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:30.463Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page to stabilize...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:33.856Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m UEN typed successfully: 202344030R\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:33.856Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Clicking submit button...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:33.867Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Submit button clicked\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:35.871Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Page stabilized after submit\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:35.872Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying company links are present...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:36.148Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company links confirmed\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:36.150Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Found company link: https://recordowl.com/company/chem-affinity-learning-centre-pte-ltd\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:36.150Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Navigating to company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:46.152Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company page loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:51.153Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page content...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:51.162Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Content loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:54.162Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying UEN on company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:54.163Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m âœ“ UEN verified on page: 202344030R\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:54.224Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Successfully extracted HTML content (1127047 chars)\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:54.784Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:55.939Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":1,\"requestsFailed\":0,\"retryHistogram\":[null,1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":35093,\"requestsFinishedPerMinute\":1,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":35093,\"requestsTotal\":1,\"crawlerRuntimeMillis\":43418}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:55.940Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Finished! Total 1 requests: 1 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> 2025-11-11T08:36:56.070Z \u001b[32mINFO\u001b[39m  Puppeteer Scraper finished.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:IDFpGTgzuXLGPaYG5]\u001b[0m -> Status: SUCCEEDED, Message: Finished! Total 1 requests: 1 succeeded, 0 failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â³ Waiting for run to complete...\n",
      "  âœ… Run succeeded with data\n",
      "  â³ Waiting for dataset to be ready...\n",
      "  ðŸ“Š Dataset has 1 item(s)\n",
      "  âœ… Successfully scraped 202344030R (1127047 chars of HTML)\n",
      "  âœ… Extracted: 0 email(s), 1 phone(s): +6591943237\n",
      "  ðŸ’¤ Sleeping for 27s before next request...\n",
      "\n",
      "ðŸ”Ž Processing T15LL1885G (3/10)\n",
      "  ðŸ“¡ Starting Apify run for T15LL1885G (attempt 1/5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:41.171Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:41.173Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:41.411Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:42.135Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:43.228Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:43.541Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:44.613Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:44.704Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:52.349Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Visiting RecordOwl for UEN: T15LL1885G\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:52.355Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Search input found\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:52.357Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page to stabilize...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:56.125Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m UEN typed successfully: T15LL1885G\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:56.129Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Clicking submit button...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:56.139Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Submit button clicked\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:57.315Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Initial wait failed, trying again for results: Waiting for selector `a[href*='/company/']` failed\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:58.002Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Results found on retry\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:58.005Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying company links are present...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:58.011Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company links confirmed\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:58.013Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Found company link: https://recordowl.com/company/edureach-services-llp\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:37:58.015Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Navigating to company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:38:06.510Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company page loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:38:11.517Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page content...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:38:11.529Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Content loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:38:14.529Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying UEN on company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:38:14.537Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m âœ“ UEN verified on page: T15LL1885G\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:38:14.574Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Successfully extracted HTML content (810190 chars)\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:38:19.552Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:38:20.557Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":1,\"requestsFailed\":0,\"retryHistogram\":[1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":33599,\"requestsFinishedPerMinute\":2,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":33599,\"requestsTotal\":1,\"crawlerRuntimeMillis\":36020}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:38:20.559Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Finished! Total 1 requests: 1 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> Status: RUNNING, Message: Finished! Total 1 requests: 1 succeeded, 0 failed.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:as7pKlVikKf2GAtgR]\u001b[0m -> 2025-11-11T08:38:20.574Z \u001b[32mINFO\u001b[39m  Puppeteer Scraper finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â³ Waiting for run to complete...\n",
      "  âœ… Run succeeded with data\n",
      "  â³ Waiting for dataset to be ready...\n",
      "  ðŸ“Š Dataset has 1 item(s)\n",
      "  âœ… Successfully scraped T15LL1885G (810190 chars of HTML)\n",
      "  âœ… Extracted: 0 email(s), 1 phone(s): +6568176157\n",
      "  ðŸ’¤ Sleeping for 28s before next request...\n",
      "\n",
      "ðŸ”Ž Processing 53200915X (4/10)\n",
      "  ðŸ“¡ Starting Apify run for 53200915X (attempt 1/5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:06.430Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:06.432Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:06.475Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:06.683Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:08.218Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:08.406Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:12.904Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:13.120Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:21.677Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Visiting RecordOwl for UEN: 53200915X\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:21.689Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Search input found\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:21.691Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page to stabilize...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:25.084Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m UEN typed successfully: 53200915X\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:25.086Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Clicking submit button...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:25.192Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Submit button clicked\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:29.111Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Page stabilized after submit\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:29.112Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying company links are present...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:29.862Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company links confirmed\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:29.873Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Found company link: https://recordowl.com/company/think-arts\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:29.874Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Navigating to company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:30.953Z \u001b[31mERROR\u001b[39m\u001b[33m PuppeteerCrawler:\u001b[39m Error navigating to company page: net::ERR_SOCKET_NOT_CONNECTED at https://recordowl.com/company/think-arts\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:31.646Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Navigation did not occur (may be client-side routing)\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:31.677Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:32.571Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":1,\"requestsFailed\":0,\"retryHistogram\":[1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":17768,\"requestsFinishedPerMinute\":3,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":17768,\"requestsTotal\":1,\"crawlerRuntimeMillis\":19611}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:32.575Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Finished! Total 1 requests: 1 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> 2025-11-11T08:39:32.577Z \u001b[32mINFO\u001b[39m  Puppeteer Scraper finished.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:i58A7BZW1fwJo9eyq]\u001b[0m -> Status: SUCCEEDED, Message: Finished! Total 1 requests: 1 succeeded, 0 failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â³ Waiting for run to complete...\n",
      "  âœ… Run succeeded with data\n",
      "  â³ Waiting for dataset to be ready...\n",
      "  ðŸ“Š Dataset has 1 item(s)\n",
      "  âŒ Error for 53200915X: Failed to load company page: net::ERR_SOCKET_NOT_CONNECTED at https://recordowl.com/company/think-arts\n",
      "  âŒ Scraping error: Failed to load company page: net::ERR_SOCKET_NOT_CONNECTED at https://recordowl.com/company/think-arts\n",
      "\n",
      "ðŸ”Ž Processing 201733719E (5/10)\n",
      "  ðŸ“¡ Starting Apify run for 201733719E (attempt 1/5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:39:52.839Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:39:52.841Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:39:52.886Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:39:53.071Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:39:54.469Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:39:54.604Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:39:55.486Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:39:55.566Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:02.404Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked - received 403 status code.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:02.406Z \u001b[90m {\"id\":\"XsOj8IqwoXyWgRx\",\"url\":\"https://recordowl.com/\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:10.886Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked - received 403 status code.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:10.888Z \u001b[90m {\"id\":\"XsOj8IqwoXyWgRx\",\"url\":\"https://recordowl.com/\",\"retryCount\":2}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:22.285Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Visiting RecordOwl for UEN: 201733719E\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:22.291Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Search input found\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:22.292Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page to stabilize...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:25.871Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m UEN typed successfully: 201733719E\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:25.873Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Clicking submit button...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:25.895Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Submit button clicked\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:27.900Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Page stabilized after submit\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:27.967Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying company links are present...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:28.268Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company links confirmed\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:28.271Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Found company link: https://recordowl.com/company/jus-infants-macpherson-pte-ltd\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:28.272Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Navigating to company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:37.384Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company page loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:42.385Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page content...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:42.393Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Content loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:45.393Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying UEN on company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:45.395Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m âœ“ UEN verified on page: 201733719E\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:45.449Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Successfully extracted HTML content (1078276 chars)\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:45.692Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:46.203Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":1,\"requestsFailed\":0,\"retryHistogram\":[null,null,1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":34455,\"requestsFinishedPerMinute\":1,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":34455,\"requestsTotal\":1,\"crawlerRuntimeMillis\":50794}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:46.205Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Finished! Total 1 requests: 1 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> Status: RUNNING, Message: Finished! Total 1 requests: 1 succeeded, 0 failed.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:8ny5EWQU5uGGbJLXn]\u001b[0m -> 2025-11-11T08:40:46.232Z \u001b[32mINFO\u001b[39m  Puppeteer Scraper finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â³ Waiting for run to complete...\n",
      "  âœ… Run succeeded with data\n",
      "  â³ Waiting for dataset to be ready...\n",
      "  ðŸ“Š Dataset has 1 item(s)\n",
      "  âœ… Successfully scraped 201733719E (1078276 chars of HTML)\n",
      "  âœ… Extracted: 0 email(s), 1 phone(s): +6586860777\n",
      "  ðŸ’¤ Sleeping for 30s before next request...\n",
      "  ðŸ›‘ Checkpoint pause: waiting extra 30s...\n",
      "\n",
      "ðŸ”Ž Processing 53227394W (6/10)\n",
      "  ðŸ“¡ Starting Apify run for 53227394W (attempt 1/5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:03.366Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:03.367Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:03.612Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:03.784Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:04.477Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:04.587Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:05.175Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:05.299Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:19.071Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Visiting RecordOwl for UEN: 53227394W\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:19.078Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Search input found\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:19.079Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page to stabilize...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:22.432Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m UEN typed successfully: 53227394W\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:22.433Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Clicking submit button...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:22.459Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Submit button clicked\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:24.505Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Page stabilized after submit\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:24.506Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying company links are present...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:25.706Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company links confirmed\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:25.707Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Found company link: https://recordowl.com/company/maths-tablet\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:25.708Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Navigating to company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:35.881Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company page loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:40.904Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page content...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:40.928Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Content loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:43.928Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying UEN on company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:43.932Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m âœ“ UEN verified on page: 53227394W\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:43.986Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Successfully extracted HTML content (1433338 chars)\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:44.244Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:44.626Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":1,\"requestsFailed\":0,\"retryHistogram\":[1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":38577,\"requestsFinishedPerMinute\":2,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":38577,\"requestsTotal\":1,\"crawlerRuntimeMillis\":39518}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:44.627Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Finished! Total 1 requests: 1 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> Status: RUNNING, Message: Finished! Total 1 requests: 1 succeeded, 0 failed.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:fXf1ypbbYYR0CL54K]\u001b[0m -> 2025-11-11T08:42:44.643Z \u001b[32mINFO\u001b[39m  Puppeteer Scraper finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â³ Waiting for run to complete...\n",
      "  âœ… Run succeeded with data\n",
      "  â³ Waiting for dataset to be ready...\n",
      "  ðŸ“Š Dataset has 1 item(s)\n",
      "  âœ… Successfully scraped 53227394W (1433338 chars of HTML)\n",
      "  âœ… Extracted: 0 email(s), 1 phone(s): +6598524810\n",
      "  ðŸ’¤ Sleeping for 31s before next request...\n",
      "\n",
      "ðŸ”Ž Processing 202209857Z (7/10)\n",
      "  ðŸ“¡ Starting Apify run for 202209857Z (attempt 1/5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:43:32.644Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:43:32.646Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:43:32.688Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:43:32.999Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:43:33.955Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:43:34.067Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:43:34.655Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:43:34.774Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:43:58.128Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked - received 403 status code.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:43:58.130Z \u001b[90m {\"id\":\"XsOj8IqwoXyWgRx\",\"url\":\"https://recordowl.com/\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:13.965Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Visiting RecordOwl for UEN: 202209857Z\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:13.976Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Search input found\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:13.978Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page to stabilize...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:17.612Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m UEN typed successfully: 202209857Z\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:17.614Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Clicking submit button...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:17.655Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Submit button clicked\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:21.776Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Page stabilized after submit\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:21.778Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying company links are present...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:21.844Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company links confirmed\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:21.847Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Found company link: https://recordowl.com/company/york-education-pte-ltd\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:21.849Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Navigating to company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:24.537Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company page loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:29.538Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page content...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:29.551Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Content loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:32.551Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying UEN on company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:32.553Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m âœ“ UEN verified on page: 202209857Z\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:32.562Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Successfully extracted HTML content (134579 chars)\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:32.984Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:33.307Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":1,\"requestsFailed\":0,\"retryHistogram\":[null,1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":33373,\"requestsFinishedPerMinute\":1,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":33373,\"requestsTotal\":1,\"crawlerRuntimeMillis\":58727}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:33.308Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Finished! Total 1 requests: 1 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> 2025-11-11T08:44:33.329Z \u001b[32mINFO\u001b[39m  Puppeteer Scraper finished.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:hgsfHvCGuim9sEE8f]\u001b[0m -> Status: SUCCEEDED, Message: Finished! Total 1 requests: 1 succeeded, 0 failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â³ Waiting for run to complete...\n",
      "  âœ… Run succeeded with data\n",
      "  â³ Waiting for dataset to be ready...\n",
      "  ðŸ“Š Dataset has 1 item(s)\n",
      "  âœ… Successfully scraped 202209857Z (134579 chars of HTML)\n",
      "  âœ… Extracted: 0 email(s), 1 phone(s): +6598193093\n",
      "  ðŸ’¤ Sleeping for 32s before next request...\n",
      "\n",
      "ðŸ”Ž Processing 201711911W (8/10)\n",
      "  ðŸ“¡ Starting Apify run for 201711911W (attempt 1/5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:45:21.493Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:45:21.496Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:45:21.545Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:45:21.688Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:45:24.818Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:45:24.922Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:45:26.206Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:45:26.331Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:45:43.110Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked - received 403 status code.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:45:43.113Z \u001b[90m {\"id\":\"XsOj8IqwoXyWgRx\",\"url\":\"https://recordowl.com/\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:45:54.121Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked - received 403 status code.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:45:54.125Z \u001b[90m {\"id\":\"XsOj8IqwoXyWgRx\",\"url\":\"https://recordowl.com/\",\"retryCount\":2}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:09.866Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Visiting RecordOwl for UEN: 201711911W\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:09.871Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Search input found\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:09.874Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page to stabilize...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:13.270Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m UEN typed successfully: 201711911W\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:13.272Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Clicking submit button...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:13.282Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Submit button clicked\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:15.285Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Page stabilized after submit\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:15.291Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying company links are present...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:15.293Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company links confirmed\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:15.295Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Found company link: https://recordowl.com/company/maplebear-learning-garden-pte-ltd\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:15.297Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Navigating to company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:23.816Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company page loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:26.331Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":null,\"requestsFinishedPerMinute\":0,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":0,\"requestsTotal\":0,\"crawlerRuntimeMillis\":60192,\"retryHistogram\":[]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:26.366Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":1,\"desiredConcurrency\":1,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0.02},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:28.815Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page content...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:28.822Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Content loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:31.822Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying UEN on company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:31.825Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m âœ“ UEN verified on page: 201711911W\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:31.881Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Successfully extracted HTML content (1485862 chars)\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:32.192Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:32.569Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":1,\"requestsFailed\":0,\"retryHistogram\":[null,null,1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":37705,\"requestsFinishedPerMinute\":1,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":37705,\"requestsTotal\":1,\"crawlerRuntimeMillis\":66430}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:32.571Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Finished! Total 1 requests: 1 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> 2025-11-11T08:46:32.581Z \u001b[32mINFO\u001b[39m  Puppeteer Scraper finished.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:dVFdTbnR5jU9VYfKh]\u001b[0m -> Status: SUCCEEDED, Message: Finished! Total 1 requests: 1 succeeded, 0 failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â³ Waiting for run to complete...\n",
      "  âœ… Run succeeded with data\n",
      "  â³ Waiting for dataset to be ready...\n",
      "  ðŸ“Š Dataset has 1 item(s)\n",
      "  âœ… Successfully scraped 201711911W (1485862 chars of HTML)\n",
      "  âœ… Extracted: 1 email(s), 1 phone(s): +6562521488\n",
      "  ðŸ’¤ Sleeping for 33s before next request...\n",
      "\n",
      "ðŸ”Ž Processing 201540131W (9/10)\n",
      "  ðŸ“¡ Starting Apify run for 201540131W (attempt 1/5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:21.720Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:21.722Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:21.760Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:21.933Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:22.665Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:22.793Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:23.524Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:23.910Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:39.043Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Visiting RecordOwl for UEN: 201540131W\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:39.049Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Search input found\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:39.051Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page to stabilize...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:42.509Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m UEN typed successfully: 201540131W\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:42.514Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Clicking submit button...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:42.538Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Submit button clicked\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:48.312Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Page stabilized after submit\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:48.319Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying company links are present...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:48.393Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company links confirmed\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:48.395Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Found company link: https://recordowl.com/company/4hands-dental-assisting-training-school-pte-ltd\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:48.397Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Navigating to company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:52.089Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company page loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:57.089Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page content...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:47:57.102Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Content loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:48:00.102Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying UEN on company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:48:00.104Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m âœ“ UEN verified on page: 201540131W\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:48:00.215Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Successfully extracted HTML content (1136051 chars)\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:48:00.529Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:48:01.338Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":1,\"requestsFailed\":0,\"retryHistogram\":[1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":35637,\"requestsFinishedPerMinute\":2,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":35637,\"requestsTotal\":1,\"crawlerRuntimeMillis\":37893}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:48:01.339Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Finished! Total 1 requests: 1 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> 2025-11-11T08:48:01.377Z \u001b[32mINFO\u001b[39m  Puppeteer Scraper finished.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:90rpUfCI33PudDYFF]\u001b[0m -> Status: SUCCEEDED, Message: Finished! Total 1 requests: 1 succeeded, 0 failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â³ Waiting for run to complete...\n",
      "  âœ… Run succeeded with data\n",
      "  â³ Waiting for dataset to be ready...\n",
      "  ðŸ“Š Dataset has 1 item(s)\n",
      "  âœ… Successfully scraped 201540131W (1136051 chars of HTML)\n",
      "  âœ… Extracted: 1 email(s), 1 phone(s): +6594203111\n",
      "  ðŸ’¤ Sleeping for 34s before next request...\n",
      "\n",
      "ðŸ”Ž Processing 202337418G (10/10)\n",
      "  ðŸ“¡ Starting Apify run for 202337418G (attempt 1/5)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:48:51.287Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:48:51.297Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:48:51.612Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:48:51.916Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:48:53.251Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:48:53.357Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:48:53.989Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:48:54.062Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:49:01.976Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked - received 403 status code.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 1.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:49:01.977Z \u001b[90m {\"id\":\"XsOj8IqwoXyWgRx\",\"url\":\"https://recordowl.com/\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:49:17.623Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Visiting RecordOwl for UEN: 202337418G\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:49:17.635Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Search input found\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:49:17.635Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page to stabilize...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:49:22.554Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m UEN typed successfully: 202337418G\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:49:22.555Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Clicking submit button...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:49:54.062Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":null,\"requestsFinishedPerMinute\":0,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":0,\"requestsTotal\":0,\"crawlerRuntimeMillis\":60147,\"retryHistogram\":[]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:49:54.085Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":1,\"desiredConcurrency\":1,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:50:54.062Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":null,\"requestsFinishedPerMinute\":0,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":0,\"requestsTotal\":0,\"crawlerRuntimeMillis\":120147,\"retryHistogram\":[]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:50:54.087Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":1,\"desiredConcurrency\":1,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:51:54.063Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:Statistics:\u001b[39m PuppeteerCrawler request statistics:\u001b[90m {\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":null,\"requestsFinishedPerMinute\":0,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":0,\"requestsTotal\":0,\"crawlerRuntimeMillis\":180148,\"retryHistogram\":[]}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:51:54.089Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:AutoscaledPool:\u001b[39m state\u001b[90m {\"currentConcurrency\":1,\"desiredConcurrency\":1,\"systemStatus\":{\"isSystemIdle\":true,\"memInfo\":{\"isOverloaded\":false,\"limitRatio\":0.2,\"actualRatio\":0},\"eventLoopInfo\":{\"isOverloaded\":false,\"limitRatio\":0.6,\"actualRatio\":0},\"cpuInfo\":{\"isOverloaded\":false,\"limitRatio\":0.4,\"actualRatio\":0},\"clientInfo\":{\"isOverloaded\":false,\"limitRatio\":0.3,\"actualRatio\":0}}}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:16.531Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. requestHandler timed out after 180 seconds.\u001b[90m {\"id\":\"XsOj8IqwoXyWgRx\",\"url\":\"https://recordowl.com/\",\"retryCount\":2}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:16.631Z \u001b[31mERROR\u001b[39m\u001b[33m PuppeteerCrawler:\u001b[39m Error during submit: Protocol error (Runtime.callFunctionOn): Target closed\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:22.098Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Visiting RecordOwl for UEN: 202337418G\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:22.141Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Search input found\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:22.141Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page to stabilize...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:25.628Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m UEN typed successfully: 202337418G\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:25.633Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Clicking submit button...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:26.420Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Submit button clicked\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:33.735Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Page stabilized after submit\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:33.735Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying company links are present...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:33.838Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company links confirmed\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:33.841Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Found company link: https://recordowl.com/company/out-of-the-box-academy-clementi-pte-ltd\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:33.842Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Navigating to company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:42.393Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Company page loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:47.393Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Waiting for page content...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:47.407Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Content loaded\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:50.407Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Verifying UEN on company page...\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:50.410Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m âœ“ UEN verified on page: 202337418G\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:50.528Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Successfully extracted HTML content (797812 chars)\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:50.868Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:54.002Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":1,\"requestsFailed\":0,\"retryHistogram\":[null,null,1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":33800,\"requestsFinishedPerMinute\":0,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":33800,\"requestsTotal\":1,\"crawlerRuntimeMillis\":240087}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:54.003Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Finished! Total 1 requests: 1 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> Status: RUNNING, Message: Finished! Total 1 requests: 1 succeeded, 0 failed.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:c2lEquVVPX9e1Ld9X]\u001b[0m -> 2025-11-11T08:52:54.021Z \u001b[32mINFO\u001b[39m  Puppeteer Scraper finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  â³ Waiting for run to complete...\n",
      "  âœ… Run succeeded with data\n",
      "  â³ Waiting for dataset to be ready...\n",
      "  ðŸ“Š Dataset has 2 item(s)\n",
      "  âŒ Error for 202337418G: Submit failed: Protocol error (Runtime.callFunctionOn): Target closed\n",
      "  âœ… Successfully scraped 202337418G (797812 chars of HTML)\n",
      "  âœ… Extracted: 1 email(s), 1 phone(s): +6580664284\n",
      "  ðŸ’¤ Sleeping for 25s before next request...\n",
      "  ðŸ›‘ Checkpoint pause: waiting extra 30s...\n",
      "\n",
      "âœ… Scraping complete!\n",
      "\n",
      "ðŸ“Š Results summary:\n",
      "   Total processed: 10\n",
      "   With emails: 3\n",
      "   With phones: 8\n",
      "   With websites: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>address</th>\n",
       "      <th>Emails</th>\n",
       "      <th>Phones</th>\n",
       "      <th>Website</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Instagram</th>\n",
       "      <th>TikTok</th>\n",
       "      <th>RecordOwl_Link</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53431824W</td>\n",
       "      <td>230 COMPASSVALE WALK #10-430 SINGAPORE 540230</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.tutorsville.sg/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/tutorsville-sg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202344030R</td>\n",
       "      <td>87 BEACH ROAD #04-03 CHYE SING BUILDING 189695</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6591943237]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/chem-affinity-le...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T15LL1885G</td>\n",
       "      <td>201E TAMPINES STREET 23 #01-122 SINGAPORE 527201</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6568176157]</td>\n",
       "      <td>https://edureachsg.com</td>\n",
       "      <td>[https://www.facebook.com/edureachservices]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/edureach-service...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53200915X</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Scraping error: Failed to load company page: n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201733719E</td>\n",
       "      <td>47 KALLANG PUDDING ROAD #01-01 THE CRESCENT @ ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6586860777]</td>\n",
       "      <td>https://jusinfants.com</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/jusinfantsplayhouse/]</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/jus-infants-macp...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53227394W</td>\n",
       "      <td>555 ANG MO KIO AVENUE 10 #01-1958 CHENG SAN PL...</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6598524810]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/maths-tablet</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202209857Z</td>\n",
       "      <td>54 CASHEW ROAD #02-02 CASHEW PARK CONDOMINIUM ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6598193093]</td>\n",
       "      <td>http://www.yorkearlyyears.com/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/york-education-p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201711911W</td>\n",
       "      <td>351 BRADDELL ROAD #03-01 351 ON BRADDELL SINGA...</td>\n",
       "      <td>[principal-rochester@maplebear.sg]</td>\n",
       "      <td>[+6562521488]</td>\n",
       "      <td>https://maplebear.sg/contact-us</td>\n",
       "      <td>[https://www.facebook.com/maplebearsg]</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/maplebear_rochester...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/maplebear-learni...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>201540131W</td>\n",
       "      <td>684A JURONG WEST STREET 64 #17-103 SINGAPORE 6...</td>\n",
       "      <td>[sg_4hands@outlook.com]</td>\n",
       "      <td>[+6594203111]</td>\n",
       "      <td>https://4handsda.com</td>\n",
       "      <td>[https://www.facebook.com/4handsda/]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/4hands-dental-as...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202337418G</td>\n",
       "      <td>433 CLEMENTI AVENUE 3 #01-258 120433</td>\n",
       "      <td>[enquiries@outoftheboxacademy.com]</td>\n",
       "      <td>[+6580664284]</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.facebook.com/outofboxacademy/, ht...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/otbstudentcare/]</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/out-of-the-box-a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          UEN                                            address  \\\n",
       "0   53431824W      230 COMPASSVALE WALK #10-430 SINGAPORE 540230   \n",
       "1  202344030R     87 BEACH ROAD #04-03 CHYE SING BUILDING 189695   \n",
       "2  T15LL1885G   201E TAMPINES STREET 23 #01-122 SINGAPORE 527201   \n",
       "3   53200915X                                               None   \n",
       "4  201733719E  47 KALLANG PUDDING ROAD #01-01 THE CRESCENT @ ...   \n",
       "5   53227394W  555 ANG MO KIO AVENUE 10 #01-1958 CHENG SAN PL...   \n",
       "6  202209857Z  54 CASHEW ROAD #02-02 CASHEW PARK CONDOMINIUM ...   \n",
       "7  201711911W  351 BRADDELL ROAD #03-01 351 ON BRADDELL SINGA...   \n",
       "8  201540131W  684A JURONG WEST STREET 64 #17-103 SINGAPORE 6...   \n",
       "9  202337418G               433 CLEMENTI AVENUE 3 #01-258 120433   \n",
       "\n",
       "                               Emails         Phones  \\\n",
       "0                                None           None   \n",
       "1                                None  [+6591943237]   \n",
       "2                                None  [+6568176157]   \n",
       "3                                None           None   \n",
       "4                                None  [+6586860777]   \n",
       "5                                None  [+6598524810]   \n",
       "6                                None  [+6598193093]   \n",
       "7  [principal-rochester@maplebear.sg]  [+6562521488]   \n",
       "8             [sg_4hands@outlook.com]  [+6594203111]   \n",
       "9  [enquiries@outoftheboxacademy.com]  [+6580664284]   \n",
       "\n",
       "                           Website  \\\n",
       "0      https://www.tutorsville.sg/   \n",
       "1                             None   \n",
       "2           https://edureachsg.com   \n",
       "3                             None   \n",
       "4           https://jusinfants.com   \n",
       "5                             None   \n",
       "6   http://www.yorkearlyyears.com/   \n",
       "7  https://maplebear.sg/contact-us   \n",
       "8             https://4handsda.com   \n",
       "9                             None   \n",
       "\n",
       "                                            Facebook LinkedIn  \\\n",
       "0                                               None     None   \n",
       "1                                               None     None   \n",
       "2        [https://www.facebook.com/edureachservices]     None   \n",
       "3                                               None     None   \n",
       "4                                               None     None   \n",
       "5                                               None     None   \n",
       "6                                               None     None   \n",
       "7             [https://www.facebook.com/maplebearsg]     None   \n",
       "8               [https://www.facebook.com/4handsda/]     None   \n",
       "9  [https://www.facebook.com/outofboxacademy/, ht...     None   \n",
       "\n",
       "                                           Instagram TikTok  \\\n",
       "0                                               None   None   \n",
       "1                                               None   None   \n",
       "2                                               None   None   \n",
       "3                                               None   None   \n",
       "4   [https://www.instagram.com/jusinfantsplayhouse/]   None   \n",
       "5                                               None   None   \n",
       "6                                               None   None   \n",
       "7  [https://www.instagram.com/maplebear_rochester...   None   \n",
       "8                                               None   None   \n",
       "9        [https://www.instagram.com/otbstudentcare/]   None   \n",
       "\n",
       "                                      RecordOwl_Link  \\\n",
       "0       https://recordowl.com/company/tutorsville-sg   \n",
       "1  https://recordowl.com/company/chem-affinity-le...   \n",
       "2  https://recordowl.com/company/edureach-service...   \n",
       "3                                               None   \n",
       "4  https://recordowl.com/company/jus-infants-macp...   \n",
       "5         https://recordowl.com/company/maths-tablet   \n",
       "6  https://recordowl.com/company/york-education-p...   \n",
       "7  https://recordowl.com/company/maplebear-learni...   \n",
       "8  https://recordowl.com/company/4hands-dental-as...   \n",
       "9  https://recordowl.com/company/out-of-the-box-a...   \n",
       "\n",
       "                                               Error  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  Scraping error: Failed to load company page: n...  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client = ApifyClient(\"apify_api_BKqgA7WLcQMD7dugx62KslGgbrxZ2t3NB2gj\")\n",
    "\n",
    "SOCIAL_MEDIA_DOMAINS = [\n",
    "    \"facebook.com\", \"linkedin.com\", \"instagram.com\", \"youtube.com\",\n",
    "    \"tiktok.com\", \"twitter.com\", \"x.com\", \"pinterest.com\"\n",
    "]\n",
    "\n",
    "def fetch_dataset_items_safe(dataset_client, max_retries=5, initial_wait=3):\n",
    "    \"\"\"Safely fetch dataset items with multiple retry strategies.\"\"\"\n",
    "    dataset_items = []\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Strategy 1: Try using iterate_items() (streaming)\n",
    "            try:\n",
    "                dataset_items = list(dataset_client.iterate_items())\n",
    "                if dataset_items:\n",
    "                    return dataset_items\n",
    "            except (HTTPError, ConnectionError, ProtocolError, Exception) as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = initial_wait * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"  âš ï¸ Iteration method failed (attempt {attempt + 1}/{max_retries}), trying direct fetch in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  âš ï¸ Iteration method failed after all retries, trying direct fetch...\")\n",
    "            \n",
    "            # Strategy 2: Try using list_items() (direct pagination)\n",
    "            try:\n",
    "                offset = 0\n",
    "                limit = 100\n",
    "                while True:\n",
    "                    page = dataset_client.list_items(offset=offset, limit=limit, clean=True)\n",
    "                    if not page.items:\n",
    "                        break\n",
    "                    dataset_items.extend(page.items)\n",
    "                    if len(page.items) < limit:\n",
    "                        break\n",
    "                    offset += limit\n",
    "                \n",
    "                if dataset_items:\n",
    "                    return dataset_items\n",
    "            except (HTTPError, ConnectionError, ProtocolError, Exception) as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = initial_wait * (2 ** attempt)\n",
    "                    print(f\"  âš ï¸ Direct fetch failed (attempt {attempt + 1}/{max_retries}), retrying in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  âŒ All fetch methods failed: {e}\")\n",
    "                    return []\n",
    "                    \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = initial_wait * (2 ** attempt)\n",
    "                print(f\"  âš ï¸ Unexpected error (attempt {attempt + 1}/{max_retries}), retrying in {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"  âŒ Failed after all retries: {e}\")\n",
    "                return []\n",
    "    \n",
    "    return dataset_items\n",
    "\n",
    "def run_apify_with_retry(client, run_input, uen, max_retries=3):\n",
    "    \"\"\"Run Apify with exponential backoff on 403 errors AND verify dataset has items.\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"  ðŸ“¡ Starting Apify run for {uen} (attempt {attempt + 1}/{max_retries})...\")\n",
    "            run = client.actor(\"apify/puppeteer-scraper\").call(run_input=run_input)\n",
    "            \n",
    "            print(f\"  â³ Waiting for run to complete...\")\n",
    "            run_client = client.run(run[\"id\"])\n",
    "            run_info = run_client.wait_for_finish()\n",
    "            \n",
    "            # CRITICAL FIX: Check if run actually scraped pages, not just if it \"succeeded\"\n",
    "            if run_info and \"status\" in run_info:\n",
    "                status = run_info.get(\"status\")\n",
    "                \n",
    "                # Even if status is \"SUCCEEDED\", verify dataset actually has items\n",
    "                if status == \"SUCCEEDED\" and \"defaultDatasetId\" in run:\n",
    "                    # Quick check if dataset has any items\n",
    "                    try:\n",
    "                        dataset_check = client.dataset(run[\"defaultDatasetId\"])\n",
    "                        time.sleep(2)  # Brief wait for dataset to be ready\n",
    "                        test_items = dataset_check.list_items(limit=1, clean=True)\n",
    "                        \n",
    "                        if test_items.items and len(test_items.items) > 0:\n",
    "                            # Dataset has items - true success!\n",
    "                            print(f\"  âœ… Run succeeded with data\")\n",
    "                            return run, None\n",
    "                        else:\n",
    "                            # Status says \"SUCCEEDED\" but dataset is EMPTY - this is a failure!\n",
    "                            print(f\"  âš ï¸ Run completed but dataset is empty (likely 403 block)\")\n",
    "                            # Treat as 403 and retry\n",
    "                            if attempt < max_retries - 1:\n",
    "                                wait_time = 30 * (2 ** attempt)\n",
    "                                print(f\"  ðŸ”„ Retrying in {wait_time}s...\")\n",
    "                                time.sleep(wait_time)\n",
    "                                continue\n",
    "                            else:\n",
    "                                return None, \"Dataset empty after all retries (403 blocking)\"\n",
    "                    except Exception as e:\n",
    "                        print(f\"  âš ï¸ Could not verify dataset: {e}\")\n",
    "                        # If we can't check dataset, try to use the run anyway\n",
    "                        return run, None\n",
    "                \n",
    "                elif status != \"SUCCEEDED\":\n",
    "                    # Check error message for 403\n",
    "                    error_msg = str(run_info)\n",
    "                    if \"403\" in error_msg or \"blocked\" in error_msg.lower():\n",
    "                        if attempt < max_retries - 1:\n",
    "                            wait_time = 30 * (2 ** attempt)  # 30s, 60s, 120s\n",
    "                            print(f\"  ðŸš« Request blocked (403), waiting {wait_time}s before retry...\")\n",
    "                            time.sleep(wait_time)\n",
    "                            continue\n",
    "            \n",
    "            return run, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            if \"403\" in error_str or \"blocked\" in error_str.lower():\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = 30 * (2 ** attempt)\n",
    "                    print(f\"  ðŸš« Request blocked (403), waiting {wait_time}s before retry...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "            return None, f\"Apify call failed: {str(e)}\"\n",
    "    \n",
    "    return None, \"Max retries exceeded due to 403 blocking\"\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for idx, (i, row) in enumerate(acra_data_filtered_by_industry.iterrows(), 1):\n",
    "    uen = str(row[\"UEN\"]).strip()\n",
    "    print(f\"\\nðŸ”Ž Processing {uen} ({idx}/{len(acra_data_filtered_by_industry)})\")\n",
    "\n",
    "    # Build pageFunction with proper escaping and improved error handling\n",
    "    page_function = f\"\"\"\n",
    "    async function pageFunction(context) {{\n",
    "        const {{ page, log, request }} = context;\n",
    "        const uen = \"{uen}\";\n",
    "        log.info(\"Visiting RecordOwl for UEN: \" + uen);\n",
    "\n",
    "        try {{\n",
    "            // Step 1: Wait for search input\n",
    "            await page.waitForSelector(\"input[placeholder='Search company name, industry, or address']\", {{ timeout: 30000 }});\n",
    "            log.info(\"Search input found\");\n",
    "            \n",
    "            // Step 2: Type UEN into search box with error handling and navigation protection\n",
    "            try {{\n",
    "                // Wait for page to be stable (no navigation happening)\n",
    "                log.info(\"Waiting for page to stabilize...\");\n",
    "                await new Promise(r => setTimeout(r, 2000)); // Wait for any auto-navigation to complete\n",
    "                \n",
    "                // Wait for input to be present and stable\n",
    "                await page.waitForSelector(\"input[placeholder='Search company name, industry, or address']\", {{ \n",
    "                    timeout: 30000,\n",
    "                    visible: true \n",
    "                }});\n",
    "                \n",
    "                // Re-find input right before typing (in case page navigated)\n",
    "                let input = await page.$(\"input[placeholder='Search company name, industry, or address']\");\n",
    "                if (!input) {{\n",
    "                    log.error(\"Input element not found after wait\");\n",
    "                    return {{ status: 'error', uen, error: 'Input element not found' }};\n",
    "                }}\n",
    "                \n",
    "                // Clear and type with retry logic\n",
    "                let typed = false;\n",
    "                for (let attempt = 0; attempt < 3; attempt++) {{\n",
    "                    try {{\n",
    "                        // Re-find input on each attempt (in case context was destroyed)\n",
    "                        input = await page.$(\"input[placeholder='Search company name, industry, or address']\");\n",
    "                        if (!input) {{\n",
    "                            throw new Error(\"Input not found on attempt \" + (attempt + 1));\n",
    "                        }}\n",
    "                        \n",
    "                        // Click to focus\n",
    "                        await input.click({{ clickCount: 3 }});\n",
    "                        await new Promise(r => setTimeout(r, 300)); // Small delay after click\n",
    "                        \n",
    "                        // Clear input first\n",
    "                        await page.evaluate((selector) => {{\n",
    "                            const el = document.querySelector(selector);\n",
    "                            if (el) el.value = '';\n",
    "                        }}, \"input[placeholder='Search company name, industry, or address']\");\n",
    "                        \n",
    "                        // Type UEN\n",
    "                        await input.type(uen, {{ delay: 100 }});\n",
    "                        typed = true;\n",
    "                        log.info(\"UEN typed successfully: \" + uen);\n",
    "                        break;\n",
    "                    }} catch (typeErr) {{\n",
    "                        if (typeErr.message.includes(\"Execution context was destroyed\") || \n",
    "                            typeErr.message.includes(\"navigation\")) {{\n",
    "                            log.info(\"Navigation occurred during typing (attempt \" + (attempt + 1) + \"/3), retrying...\");\n",
    "                            // Wait for page to stabilize after navigation\n",
    "                            await new Promise(r => setTimeout(r, 2000));\n",
    "                            // Re-wait for input\n",
    "                            await page.waitForSelector(\"input[placeholder='Search company name, industry, or address']\", {{ \n",
    "                                timeout: 10000,\n",
    "                                visible: true \n",
    "                            }});\n",
    "                            continue;\n",
    "                        }} else {{\n",
    "                            throw typeErr;\n",
    "                        }}\n",
    "                    }}\n",
    "                }}\n",
    "                \n",
    "                if (!typed) {{\n",
    "                    log.error(\"Failed to type UEN after all retries\");\n",
    "                    return {{ status: 'error', uen, error: 'Failed to type UEN after retries' }};\n",
    "                }}\n",
    "                \n",
    "            }} catch (typeErr) {{\n",
    "                log.error(\"Error typing UEN: \" + typeErr.message);\n",
    "                return {{ status: 'error', uen, error: 'Failed to type UEN: ' + typeErr.message }};\n",
    "            }}\n",
    "\n",
    "            // Step 3: Submit search with flexible waiting strategy\n",
    "            try {{\n",
    "                log.info(\"Clicking submit button...\");\n",
    "                \n",
    "                // Click submit button first\n",
    "                await page.click(\"button[type='submit']\");\n",
    "                log.info(\"Submit button clicked\");\n",
    "                \n",
    "                // Wait for either navigation OR results to appear (more flexible)\n",
    "                // Strategy: Wait for results to appear, with navigation as optional\n",
    "                try {{\n",
    "                    // Option 1: Wait for navigation (if it happens) - non-blocking\n",
    "                    const navigationPromise = page.waitForNavigation({{ \n",
    "                        waitUntil: 'networkidle2', \n",
    "                        timeout: 30000 \n",
    "                    }}).catch(() => {{\n",
    "                        log.info(\"Navigation did not occur (may be client-side routing)\");\n",
    "                        return null;\n",
    "                    }});\n",
    "                    \n",
    "                    // Option 2: Wait for results to appear (more reliable)\n",
    "                    const resultsPromise = page.waitForSelector(\"a[href*='/company/']\", {{ \n",
    "                        timeout: 60000 \n",
    "                    }});\n",
    "                    \n",
    "                    // Wait for either navigation or results (whichever happens first)\n",
    "                    await Promise.race([\n",
    "                        navigationPromise,\n",
    "                        resultsPromise\n",
    "                    ]);\n",
    "                    \n",
    "                    // Give page time to stabilize\n",
    "                    await new Promise(r => setTimeout(r, 2000));\n",
    "                    log.info(\"Page stabilized after submit\");\n",
    "                    \n",
    "                }} catch (waitErr) {{\n",
    "                    // If both navigation and results wait failed, try one more time for results\n",
    "                    log.info(\"Initial wait failed, trying again for results: \" + waitErr.message);\n",
    "                    try {{\n",
    "                        await page.waitForSelector(\"a[href*='/company/']\", {{ timeout: 30000 }});\n",
    "                        log.info(\"Results found on retry\");\n",
    "                    }} catch (retryErr) {{\n",
    "                        log.info(\"No company links found after submit, might be not found\");\n",
    "                        return {{ status: 'not_found', uen }};\n",
    "                    }}\n",
    "                }}\n",
    "                \n",
    "            }} catch (navErr) {{\n",
    "                log.error(\"Error during submit: \" + navErr.message);\n",
    "                // Don't fail immediately - try to check if results are already there\n",
    "                try {{\n",
    "                    const hasResults = await page.$(\"a[href*='/company/']\");\n",
    "                    if (hasResults) {{\n",
    "                        log.info(\"Results found despite submit error\");\n",
    "                    }} else {{\n",
    "                        return {{ status: 'error', uen, error: 'Submit failed: ' + navErr.message }};\n",
    "                    }}\n",
    "                }} catch (checkErr) {{\n",
    "                    return {{ status: 'error', uen, error: 'Submit failed: ' + navErr.message }};\n",
    "                }}\n",
    "            }}\n",
    "\n",
    "            // Step 4: Verify search results are present\n",
    "            log.info(\"Verifying company links are present...\");\n",
    "            try {{\n",
    "                // Double-check that results are actually there\n",
    "                await page.waitForSelector(\"a[href*='/company/']\", {{ timeout: 10000 }});\n",
    "                log.info(\"Company links confirmed\");\n",
    "            }} catch (e) {{\n",
    "                log.info(\"No company links found, might be not found\");\n",
    "                return {{ status: 'not_found', uen }};\n",
    "            }}\n",
    "\n",
    "            // Step 5: Find the correct company link (in a new execution context after navigation)\n",
    "            let companyLink;\n",
    "            try {{\n",
    "                companyLink = await page.evaluate((searchUen) => {{\n",
    "                    const links = Array.from(document.querySelectorAll(\"a[href*='/company/']\"));\n",
    "                    \n",
    "                    // Find link where UEN appears in text or URL\n",
    "                    const uenUpper = searchUen.toUpperCase();\n",
    "                    const uenLower = searchUen.toLowerCase();\n",
    "                    \n",
    "                    for (const a of links) {{\n",
    "                        const text = (a.innerText || \"\").toUpperCase();\n",
    "                        const href = (a.href || \"\").toLowerCase();\n",
    "                        \n",
    "                        // Check if UEN appears in text or URL (case-insensitive)\n",
    "                        if (text.includes(uenUpper) || href.includes(uenLower)) {{\n",
    "                            console.log(\"Found UEN match: \" + a.href);\n",
    "                            return a.href;\n",
    "                        }}\n",
    "                    }}\n",
    "                    \n",
    "                    // Fallback: Take first company link if available\n",
    "                    if (links.length > 0) {{\n",
    "                        console.log(\"No exact UEN match, using first link: \" + links[0].href);\n",
    "                        return links[0].href;\n",
    "                    }}\n",
    "                    \n",
    "                    console.log(\"No company links found\");\n",
    "                    return null;\n",
    "                }}, uen);\n",
    "                \n",
    "                if (!companyLink) {{\n",
    "                    log.info(\"No company links found on results page\");\n",
    "                    return {{ status: 'not_found', uen }};\n",
    "                }}\n",
    "                log.info(\"Found company link: \" + companyLink);\n",
    "            }} catch (evalErr) {{\n",
    "                log.error(\"Error finding company link: \" + evalErr.message);\n",
    "                return {{ status: 'error', uen, error: 'Failed to find company link: ' + evalErr.message }};\n",
    "            }}\n",
    "\n",
    "            // Step 6: Navigate to company page if not already there\n",
    "            if (page.url() !== companyLink) {{\n",
    "                try {{\n",
    "                    log.info(\"Navigating to company page...\");\n",
    "                    await page.goto(companyLink, {{ \n",
    "                        waitUntil: 'networkidle2', \n",
    "                        timeout: 60000 \n",
    "                    }});\n",
    "                    log.info(\"Company page loaded\");\n",
    "                    \n",
    "                    // Critical: Wait for page to fully stabilize\n",
    "                    await new Promise(r => setTimeout(r, 5000));\n",
    "                }} catch (gotoErr) {{\n",
    "                    log.error(\"Error navigating to company page: \" + gotoErr.message);\n",
    "                    return {{ status: 'error', uen, error: 'Failed to load company page: ' + gotoErr.message }};\n",
    "                }}\n",
    "            }}\n",
    "\n",
    "            // Step 7: Wait for content to load (with multiple fallback strategies)\n",
    "            log.info(\"Waiting for page content...\");\n",
    "            try {{\n",
    "                await Promise.race([\n",
    "                    page.waitForSelector('dt', {{ timeout: 15000 }}),\n",
    "                    page.waitForSelector('dl', {{ timeout: 15000 }}),\n",
    "                    page.waitForSelector('.max-w-7xl', {{ timeout: 15000 }}),\n",
    "                    new Promise(r => setTimeout(r, 10000)) // Fallback: just wait 10s\n",
    "                ]);\n",
    "                log.info(\"Content loaded\");\n",
    "            }} catch (contentErr) {{\n",
    "                log.info(\"Content wait timeout, but continuing: \" + contentErr.message);\n",
    "            }}\n",
    "            \n",
    "            // Additional stabilization wait\n",
    "            await new Promise(r => setTimeout(r, 3000));\n",
    "            \n",
    "            // Step 7.5: VERIFY we're on the correct company page\n",
    "            log.info(\"Verifying UEN on company page...\");\n",
    "            try {{\n",
    "                const pageUEN = await page.evaluate((searchUen) => {{\n",
    "                    const pageText = (document.body.innerText || \"\").toUpperCase();\n",
    "                    return pageText.includes(searchUen.toUpperCase());\n",
    "                }}, uen);\n",
    "                \n",
    "                if (pageUEN) {{\n",
    "                    log.info(\"âœ“ UEN verified on page: \" + uen);\n",
    "                }} else {{\n",
    "                    log.info(\"âš  Warning: UEN not found in page text, but continuing...\");\n",
    "                }}\n",
    "            }} catch (verifyErr) {{\n",
    "                log.info(\"Could not verify UEN, but continuing: \" + verifyErr.message);\n",
    "            }}\n",
    "            \n",
    "            // Step 8: Extract content (in stable context) - ONLY VISIBLE ELEMENTS\n",
    "            let html_content, title, url;\n",
    "            try {{\n",
    "                // Get only the visible HTML content by removing hidden elements\n",
    "                await page.evaluate(() => {{\n",
    "                    // Remove all elements that are hidden from view\n",
    "                    const allElements = document.querySelectorAll('*');\n",
    "                    allElements.forEach(el => {{\n",
    "                        const style = window.getComputedStyle(el);\n",
    "                        // Mark hidden elements with a special attribute\n",
    "                        if (style.display === 'none' || \n",
    "                            style.visibility === 'hidden' || \n",
    "                            style.opacity === '0' ||\n",
    "                            el.hidden ||\n",
    "                            el.hasAttribute('hidden')) {{\n",
    "                            el.setAttribute('data-hidden-element', 'true');\n",
    "                        }}\n",
    "                    }});\n",
    "                }});\n",
    "                \n",
    "                html_content = await page.content();\n",
    "                title = await page.title();\n",
    "                url = page.url();\n",
    "                log.info(\"Successfully extracted HTML content (\" + html_content.length + \" chars)\");\n",
    "            }} catch (extractErr) {{\n",
    "                log.error(\"Error extracting content: \" + extractErr.message);\n",
    "                return {{ status: 'error', uen, error: 'Failed to extract content: ' + extractErr.message }};\n",
    "            }}\n",
    "\n",
    "            return {{ status: 'success', uen, url, title, html_content }};\n",
    "            \n",
    "        }} catch (err) {{\n",
    "            log.error(\"Unexpected error in pageFunction: \" + err.message);\n",
    "            log.error(\"Stack: \" + err.stack);\n",
    "            return {{ status: 'error', uen, error: err.message }};\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    run_input = {\n",
    "        \"startUrls\": [{\"url\": \"https://recordowl.com/\"}],\n",
    "        \"useChrome\": True,\n",
    "        \"headless\": True,\n",
    "        \"stealth\": True,\n",
    "        \"pageFunction\": page_function,\n",
    "        \"ignoreSslErrors\": False,\n",
    "        \"ignoreCorsAndCsp\": False,\n",
    "        \"maxRequestRetries\": 3,  # Increased retry attempts\n",
    "        \"maxRequestsPerCrawl\": 1,  # One page per run\n",
    "        \"maxConcurrency\": 1,  # No parallel requests\n",
    "        \"pageLoadTimeoutSecs\": 90,  # Optimized timeout\n",
    "        \"pageFunctionTimeoutSecs\": 180,  # 3 minutes for pageFunction\n",
    "        \"waitUntil\": [\"networkidle2\"],  # Wait for network to be idle\n",
    "        # OPTIMIZED: Residential proxies with recommended rotation\n",
    "        \"proxyConfiguration\": {\n",
    "            \"useApifyProxy\": True,\n",
    "            \"apifyProxyGroups\": [\"RESIDENTIAL\"],  # Residential IPs less likely to be blocked\n",
    "        },\n",
    "        \"proxyRotation\": \"RECOMMENDED\",  # Optimal proxy rotation strategy\n",
    "    }\n",
    "\n",
    "    # Use retry logic for 403 errors (5 attempts = more chances to recover)\n",
    "    run, error = run_apify_with_retry(client, run_input, uen, max_retries=5)\n",
    "\n",
    "    if error or not run:\n",
    "        print(f\"  âŒ Apify call failed for {uen}: {error}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"address\": None,\n",
    "            \"RecordOwl_Link\": None,\n",
    "            \"Error\": error or \"No run returned\"\n",
    "        })\n",
    "        time.sleep(10)  # Longer sleep after failure\n",
    "        continue\n",
    "\n",
    "    if not run or \"defaultDatasetId\" not in run:\n",
    "        print(f\"  âš ï¸ No valid dataset returned for {uen}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"address\": None,\n",
    "            \"RecordOwl_Link\": None,\n",
    "            \"Error\": \"No dataset returned\"\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Wait for dataset to be ready with progressive checking\n",
    "    print(f\"  â³ Waiting for dataset to be ready...\")\n",
    "    time.sleep(5)  # Initial wait\n",
    "    \n",
    "    # Try to fetch dataset with progressive waits\n",
    "    dataset_client = client.dataset(run[\"defaultDatasetId\"])\n",
    "    for check_attempt in range(3):\n",
    "        try:\n",
    "            # Quick check if dataset has items\n",
    "            test_fetch = dataset_client.list_items(limit=1, clean=True)\n",
    "            if test_fetch.items:\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if check_attempt < 2:\n",
    "            additional_wait = 3 * (check_attempt + 1)\n",
    "            print(f\"  â³ Dataset not ready, waiting {additional_wait}s more...\")\n",
    "            time.sleep(additional_wait)\n",
    "    \n",
    "    scraped_html, record_owl_url = None, None\n",
    "    \n",
    "    # Fetch dataset items with improved error handling\n",
    "    dataset_items = fetch_dataset_items_safe(\n",
    "        dataset_client,\n",
    "        max_retries=5,\n",
    "        initial_wait=5  # Increased from 3 to 5\n",
    "    )\n",
    "    \n",
    "    # Process items\n",
    "    if not dataset_items:\n",
    "        print(f\"  âš ï¸ Dataset is empty - no items returned!\")\n",
    "    else:\n",
    "        print(f\"  ðŸ“Š Dataset has {len(dataset_items)} item(s)\")\n",
    "    \n",
    "    for item in dataset_items:\n",
    "        if item.get(\"status\") == \"success\":\n",
    "            scraped_html = item.get(\"html_content\", \"\")\n",
    "            record_owl_url = item.get(\"url\")\n",
    "            if scraped_html:\n",
    "                print(f\"  âœ… Successfully scraped {uen} ({len(scraped_html)} chars of HTML)\")\n",
    "            else:\n",
    "                print(f\"  âš ï¸ Status is 'success' but html_content is empty for {uen}\")\n",
    "        elif item.get(\"status\") == \"not_found\":\n",
    "            print(f\"  âš ï¸ Company not found for UEN {uen}\")\n",
    "        elif item.get(\"status\") == \"error\":\n",
    "            print(f\"  âŒ Error for {uen}: {item.get('error')}\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ Unknown item status for {uen}: {item.get('status')}\")\n",
    "            print(f\"  ðŸ“‹ Item keys: {list(item.keys())}\")\n",
    "\n",
    "    if not scraped_html:\n",
    "        # Determine the specific reason for failure\n",
    "        if not dataset_items:\n",
    "            error_reason = \"Dataset empty (likely 403 block at Apify level)\"\n",
    "            print(f\"  âŒ {error_reason}\")\n",
    "        elif any(item.get(\"status\") == \"not_found\" for item in dataset_items):\n",
    "            error_reason = \"Company not found on RecordOwl\"\n",
    "            print(f\"  âŒ {error_reason}\")\n",
    "        elif any(item.get(\"status\") == \"error\" for item in dataset_items):\n",
    "            error_details = [item.get(\"error\", \"Unknown\") for item in dataset_items if item.get(\"status\") == \"error\"]\n",
    "            error_reason = f\"Scraping error: {error_details[0] if error_details else 'Unknown'}\"\n",
    "            print(f\"  âŒ {error_reason}\")\n",
    "        else:\n",
    "            error_reason = \"No HTML content retrieved (unknown reason)\"\n",
    "            print(f\"  âš ï¸ {error_reason}\")\n",
    "            # Debug: show what's in dataset items\n",
    "            if dataset_items:\n",
    "                print(f\"  ðŸ” DEBUG - First item: {dataset_items[0]}\")\n",
    "        \n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"address\": None,\n",
    "            \"RecordOwl_Link\": record_owl_url or None,\n",
    "            \"Error\": error_reason\n",
    "        })\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "\n",
    "    # Parse HTML\n",
    "    try:\n",
    "        soup = BeautifulSoup(scraped_html, \"html.parser\")\n",
    "        \n",
    "        # ========== CLEAN HTML: REMOVE HIDDEN/UNWANTED ELEMENTS ==========\n",
    "        # Remove hidden elements\n",
    "        for elem in soup.find_all(attrs={\"data-hidden-element\": \"true\"}):\n",
    "            elem.decompose()\n",
    "        \n",
    "        # Target company overview (exclude officer/director personal data)\n",
    "        overview_tab = (soup.select_one(\"#overview\") or \n",
    "                       soup.select_one(\"[aria-labelledby*='overview']\") or\n",
    "                       soup.select_one(\"div[role='tabpanel']\"))\n",
    "        \n",
    "        if overview_tab:\n",
    "            parent = overview_tab\n",
    "        else:\n",
    "            parent = soup.select_one(\"div.max-w-7xl.mx-auto.lg\\\\:py-6.sm\\\\:px-6.lg\\\\:px-8\")\n",
    "            if parent:\n",
    "                # Remove officer/shareholder sections\n",
    "                for unwanted in parent.select(\"#officers, #shareholders, #appointments, \"\n",
    "                                             \"[id*='officer'], [id*='shareholder'], [id*='appointment']\"):\n",
    "                    unwanted.decompose()\n",
    "        \n",
    "        # Remove non-visible content\n",
    "        if parent:\n",
    "            for unwanted in parent.select(\"script, style, noscript, [style*='display:none']\"):\n",
    "                unwanted.decompose()\n",
    "        # ========== END CLEAN HTML ==========\n",
    "\n",
    "        emails, phones, website = [], [], None\n",
    "        facebook_links, linkedin_links, instagram_links, tiktok_links = [], [], [], []\n",
    "        \n",
    "        # Helper function to check if element is visible\n",
    "        def is_element_visible(element):\n",
    "            \"\"\"Check if a BeautifulSoup element appears to be visible (not hidden).\"\"\"\n",
    "            if element is None:\n",
    "                return False\n",
    "            # Check for hidden attribute\n",
    "            if element.has_attr('data-hidden-element'):\n",
    "                return False\n",
    "            # Check for common hidden styles\n",
    "            style = element.get('style', '')\n",
    "            if any(hidden_style in style.lower() for hidden_style in ['display:none', 'display: none', 'visibility:hidden', 'visibility: hidden']):\n",
    "                return False\n",
    "            # Check for hidden/aria-hidden attributes\n",
    "            if element.get('hidden') or element.get('aria-hidden') == 'true':\n",
    "                return False\n",
    "            return True\n",
    "\n",
    "        if parent:\n",
    "            # Extract emails\n",
    "            for a in parent.select(\"a[href^=mailto]\"):\n",
    "                email = a.get(\"href\", \"\").replace(\"mailto:\", \"\").strip()\n",
    "                if email and email not in emails and \"@\" in email:\n",
    "                    emails.append(email)\n",
    "\n",
    "            # ========== COMPREHENSIVE SINGAPORE PHONE EXTRACTION ==========\n",
    "            # \n",
    "            # âœ… HANDLES ALL POSSIBLE SINGAPORE PHONE NUMBER FORMATS:\n",
    "            # \n",
    "            #    International formats with country code +65:\n",
    "            #      â€¢ +65 6694 5996       (standard international)\n",
    "            #      â€¢ +65-6694-5996       (with dashes)\n",
    "            #      â€¢ +65.6694.5996       (with dots)\n",
    "            #      â€¢ +656694 5996        (partial spacing)\n",
    "            #      â€¢ +6566945996         (no spacing)\n",
    "            #      â€¢ +65 66945996        (no spacing in local part)\n",
    "            #    \n",
    "            #    With parentheses:\n",
    "            #      â€¢ (+65) 6694 5996     (parentheses with plus)\n",
    "            #      â€¢ (65) 6694 5996      (parentheses without plus)\n",
    "            #      â€¢ +65(6694)5996       (area code style)\n",
    "            #      â€¢ +65 (6694) 5996     (with spaces)\n",
    "            #    \n",
    "            #    Local formats without country code:\n",
    "            #      â€¢ 6566945996          (country code without plus, no spaces)\n",
    "            #      â€¢ 65 6694 5996        (country code with spaces)\n",
    "            #      â€¢ 65-6694-5996        (country code with dashes)\n",
    "            #      â€¢ 6694 5996           (8 digits with space)\n",
    "            #      â€¢ 66945996            (8 digits no space)\n",
    "            #      â€¢ 6694-5996           (8 digits with dash)\n",
    "            #      â€¢ 6694.5996           (8 digits with dot)\n",
    "            #      â€¢ 669 45996           (odd spacing patterns)\n",
    "            #    \n",
    "            #    Any combination of separators (spaces, dashes, dots, parentheses, slashes)\n",
    "            # \n",
    "            # âœ… VALIDATION RULES:\n",
    "            #    â€¢ Mobile numbers: Start with 8 or 9 (e.g., 8123 4567, 9123 4567)\n",
    "            #    â€¢ Fixed line: Start with 6 (e.g., 6123 4567, 6694 5996)\n",
    "            #    â€¢ Length: Exactly 8 digits (local) or 10 digits (with country code 65)\n",
    "            #    â€¢ Country code: Singapore +65 only\n",
    "            #    â€¢ Dynamically rejects 20+ non-Singapore country codes\n",
    "            #    â€¢ Filters visible elements only (no hidden HTML data)\n",
    "            #    â€¢ Excludes personal contacts (officers, directors, shareholders)\n",
    "            # \n",
    "            # âŒ AUTOMATICALLY REJECTED:\n",
    "            #    â€¢ Non-Singapore country codes: +60 (Malaysia), +62 (Indonesia), +63 (Philippines),\n",
    "            #      +66 (Thailand), +81 (Japan), +82 (Korea), +84 (Vietnam), +86 (China), +91 (India), etc.\n",
    "            #    â€¢ Numbers with < 8 or incorrect digit count\n",
    "            #    â€¢ Numbers not starting with 6, 8, or 9 (after country code)\n",
    "            #    â€¢ Hidden or non-visible HTML elements\n",
    "            #    â€¢ Personal/officer contact information\n",
    "            # \n",
    "            # ðŸ“¤ OUTPUT FORMAT:\n",
    "            #    All valid numbers are normalized to: +6512345678 (international format)\n",
    "            \n",
    "            def validate_sg_phone(digits_str):\n",
    "                \"\"\"\n",
    "                Validate and format Singapore phone number from digit-only string.\n",
    "                \n",
    "                This function accepts a string with all separators already removed (only digits)\n",
    "                and validates it against Singapore phone number rules. It dynamically rejects\n",
    "                numbers from other countries and only accepts valid Singapore formats.\n",
    "                \n",
    "                Args:\n",
    "                    digits_str (str): String containing only digits (e.g., \"6566945996\", \"66945996\")\n",
    "                \n",
    "                Returns:\n",
    "                    str or None: Formatted phone number as \"+6512345678\" if valid, None otherwise\n",
    "                \n",
    "                Examples:\n",
    "                    validate_sg_phone(\"6566945996\")   -> \"+6566945996\"    (country code + 8 digits)\n",
    "                    validate_sg_phone(\"66945996\")     -> \"+6566945996\"    (8 digits, add country code)\n",
    "                    validate_sg_phone(\"63378789\")     -> \"+6563378789\"    (8 digits, NOT rejected as +63)\n",
    "                    validate_sg_phone(\"60391312823\")  -> None             (Malaysia +60, rejected)\n",
    "                    validate_sg_phone(\"63123456789\")  -> None             (Philippines +63, rejected)\n",
    "                    validate_sg_phone(\"81234567\")     -> \"+6581234567\"    (mobile number)\n",
    "                \"\"\"\n",
    "                if not digits_str or len(digits_str) < 8:\n",
    "                    return None\n",
    "                \n",
    "                # ========== DYNAMIC NON-SINGAPORE COUNTRY CODE BLACKLIST ==========\n",
    "                # Comprehensive list of international country codes that are NOT Singapore\n",
    "                # This prevents false positives from extracting parts of non-SG numbers\n",
    "                non_sg_codes = [\n",
    "                    # ASEAN Countries\n",
    "                    \"60\",   # Malaysia\n",
    "                    \"62\",   # Indonesia\n",
    "                    \"63\",   # Philippines\n",
    "                    \"66\",   # Thailand\n",
    "                    \"84\",   # Vietnam\n",
    "                    \"95\",   # Myanmar\n",
    "                    \"855\",  # Cambodia\n",
    "                    \"856\",  # Laos\n",
    "                    \"880\",  # Bangladesh\n",
    "                    \n",
    "                    # East Asia\n",
    "                    \"81\",   # Japan\n",
    "                    \"82\",   # South Korea\n",
    "                    \"86\",   # China\n",
    "                    \"852\",  # Hong Kong\n",
    "                    \"853\",  # Macau\n",
    "                    \"886\",  # Taiwan\n",
    "                    \n",
    "                    # South Asia\n",
    "                    \"91\",   # India\n",
    "                    \"92\",   # Pakistan\n",
    "                    \"93\",   # Afghanistan\n",
    "                    \"94\",   # Sri Lanka\n",
    "                    \n",
    "                    # Oceania\n",
    "                    \"61\",   # Australia\n",
    "                    \"64\",   # New Zealand\n",
    "                    \n",
    "                    # Others\n",
    "                    \"90\",   # Turkey\n",
    "                    \"98\",   # Iran\n",
    "                ]\n",
    "                \n",
    "                # ========== STEP 1: VALIDATE 8-DIGIT LOCAL FORMAT FIRST ==========\n",
    "                # CRITICAL FIX: Check 8-digit local numbers BEFORE country code rejection\n",
    "                # This prevents false positives like \"6337 8789\" being rejected as Philippines \"+63\"\n",
    "                \n",
    "                # FORMAT 1: Exactly 8 digits starting with 6/8/9 (local format, no country code)\n",
    "                # Handles: 6694 5996, 66945996, 6337 8789, 6694-5996, 6694.5996, 669 45996, etc.\n",
    "                # After stripping separators: 66945996, 63378789, etc.\n",
    "                # Action: Add +65 country code prefix\n",
    "                # NOTE: Must check this BEFORE country code rejection to avoid false positives\n",
    "                if len(digits_str) == 8 and digits_str[0] in \"689\":\n",
    "                    return \"+65\" + digits_str\n",
    "                \n",
    "                # ========== STEP 2: REJECT NON-SINGAPORE COUNTRY CODES ==========\n",
    "                # For numbers with 9+ digits, reject if they start with non-SG country code\n",
    "                # This prevents extraction of parts of foreign numbers like \"+60 3-9131 2823\"\n",
    "                # NOTE: We skip this check for 8-digit numbers (handled above) to avoid false positives\n",
    "                if len(digits_str) >= 9:\n",
    "                    for code in non_sg_codes:\n",
    "                        if digits_str.startswith(code):\n",
    "                            return None  # Not a Singapore number\n",
    "                \n",
    "                # ========== STEP 3: VALIDATE 10-DIGIT INTERNATIONAL FORMAT ==========\n",
    "                \n",
    "                # FORMAT 2: Exactly 10 digits starting with 65 and third digit is 6/8/9\n",
    "                # Handles: +65 6694 5996, +6566945996, 6566945996, 65-6694-5996, etc.\n",
    "                # After stripping separators: 6566945996\n",
    "                if len(digits_str) == 10 and digits_str.startswith(\"65\") and digits_str[2] in \"689\":\n",
    "                    return \"+\" + digits_str\n",
    "                    \n",
    "                # FORMAT 3: More than 10 digits - search for valid SG pattern within string\n",
    "                # This handles edge cases where phone number might be concatenated with other digits\n",
    "                # Example: \"Contact: 6566945996 or email\" -> digits: \"6566945996\" \n",
    "                elif len(digits_str) > 10:\n",
    "                    # Search for the pattern \"65\" followed by valid SG local number (6/8/9...)\n",
    "                    for i in range(len(digits_str) - 9):\n",
    "                        if digits_str[i:i+2] == \"65\" and digits_str[i+2] in \"689\":\n",
    "                            # EXTRA VALIDATION: Ensure \"65\" is not part of another country code\n",
    "                            # For example, in \"865...\", the \"65\" might be part of Cambodia +855\n",
    "                            if i > 0:\n",
    "                                # Check if preceding digits form part of a blacklisted code\n",
    "                                prev_digits = digits_str[max(0, i-2):i]\n",
    "                                is_part_of_other_code = any(\n",
    "                                    code.endswith(prev_digits + \"65\") \n",
    "                                    for code in non_sg_codes\n",
    "                                )\n",
    "                                if is_part_of_other_code:\n",
    "                                    continue  # Skip this match, it's part of another country code\n",
    "                            \n",
    "                            # Valid Singapore number found\n",
    "                            return \"+\" + digits_str[i:i+10]\n",
    "                \n",
    "                # ========== STEP 3: REJECT ALL OTHER CASES ==========\n",
    "                # Don't attempt to force-extract or guess\n",
    "                # No \"last 8 digits\" fallback to prevent false positives\n",
    "                return None\n",
    "            \n",
    "            # Method 1: Extract from tel: links (most reliable)\n",
    "            tel_links = [link for link in parent.select(\"a[href^='tel:'], a[href^='tel']\") \n",
    "                        if is_element_visible(link)]\n",
    "            \n",
    "            for a in tel_links:\n",
    "                tel_href = a.get(\"href\", \"\").replace(\"tel:\", \"\").strip()\n",
    "                # Extract digits and validate (validation function handles rejection)\n",
    "                digits_only = re.sub(r\"\\D\", \"\", tel_href)\n",
    "                formatted = validate_sg_phone(digits_only)\n",
    "                if formatted and formatted not in phones:\n",
    "                    phones.append(formatted)\n",
    "            \n",
    "            # Method 2: Extract from dt/dd structure (company info fields)\n",
    "            company_keywords = [\"company contact\", \"business contact\", \"office phone\", \n",
    "                              \"main phone\", \"business phone\", \"company phone\", \"contact number\", \n",
    "                              \"phone\", \"tel\", \"mobile\", \"call\", \"contact no\"]\n",
    "            exclude_keywords = [\"officer\", \"charge\", \"employee\", \"shareholder\", \"director\", \n",
    "                              \"registration\", \"person\", \"individual\", \"member\", \"partner\",\n",
    "                              \"manager\", \"owner\", \"proprietor\", \"authorized\", \"representative\",\n",
    "                              \"appointment\", \"designation\", \"name of\", \"appointed\"]\n",
    "            \n",
    "            visible_dt_tags = [dt for dt in parent.select(\"dt\") if is_element_visible(dt)]\n",
    "            \n",
    "            for dt in visible_dt_tags:\n",
    "                dt_text = dt.get_text(strip=True).lower()\n",
    "                \n",
    "                # Only extract company-level contacts (not personal)\n",
    "                is_company = any(kw in dt_text for kw in company_keywords)\n",
    "                is_personal = any(excl in dt_text for excl in exclude_keywords)\n",
    "                \n",
    "                if is_company and not is_personal:\n",
    "                    dd = dt.find_next_sibling(\"dd\")\n",
    "                    if dd and is_element_visible(dd):\n",
    "                        number_text = dd.get_text(\" \", strip=True)\n",
    "                        # Extract digits and validate (validation function handles rejection)\n",
    "                        all_digits = re.sub(r\"\\D\", \"\", number_text)\n",
    "                        formatted = validate_sg_phone(all_digits)\n",
    "                        if formatted and formatted not in phones:\n",
    "                            phones.append(formatted)\n",
    "            \n",
    "            # Method 3: Fallback text search (only if no phones found via structured data)\n",
    "            # This method uses comprehensive regex patterns to find phone numbers in free text\n",
    "            if not phones:\n",
    "                full_text = parent.get_text()\n",
    "                \n",
    "                # COMPREHENSIVE REGEX PATTERNS for all Singapore phone number formats\n",
    "                # Each pattern handles different separator combinations (spaces, dashes, dots, parentheses)\n",
    "                sg_patterns = [\n",
    "                    # Pattern 1: International format with + and any separators\n",
    "                    # Matches: +65 6694 5996, +65-6694-5996, +65.6694.5996, +656694 5996, +6566945996\n",
    "                    r\"\\+[\\s\\-\\.]*65[\\s\\-\\.]*[689][\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d\",\n",
    "                    \n",
    "                    # Pattern 2: Parentheses format (+65) or (65)\n",
    "                    # Matches: (+65) 6694 5996, (65) 6694 5996, (+65)66945996, (65)6694-5996\n",
    "                    r\"\\([\\s\\-\\.]*\\+?[\\s\\-\\.]*65[\\s\\-\\.]*\\)[\\s\\-\\.]*[689][\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d\",\n",
    "                    \n",
    "                    # Pattern 3: Country code in middle with parentheses\n",
    "                    # Matches: +65(6694)5996, +65 (6694) 5996, 65(6694)5996\n",
    "                    r\"\\+?[\\s\\-\\.]*65[\\s\\-\\.]*\\([\\s\\-\\.]*[689][\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\)[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d\",\n",
    "                    \n",
    "                    # Pattern 4: Country code without + (with mandatory separator to avoid false matches)\n",
    "                    # Matches: 65 6694 5996, 65-6694-5996, 65.6694.5996\n",
    "                    # Uses negative lookbehind/lookahead to ensure not part of longer number\n",
    "                    r\"(?<!\\d)65[\\s\\-\\.]+[689][\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d(?!\\d)\",\n",
    "                    \n",
    "                    # Pattern 5: 8-digit local format (with any separators)\n",
    "                    # Matches: 6694 5996, 66945996, 6694-5996, 6694.5996, 669 45996\n",
    "                    # Uses negative lookbehind/lookahead to avoid matching parts of longer numbers\n",
    "                    r\"(?<!\\d)[689][\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d[\\s\\-\\.]*\\d(?!\\d)\",\n",
    "                    \n",
    "                    # Pattern 6: Country code without separator (edge case)\n",
    "                    # Matches: 6566945996 (but only if preceded/followed by non-digit)\n",
    "                    r\"(?<!\\d)65[689]\\d{7}(?!\\d)\",\n",
    "                ]\n",
    "                \n",
    "                for pattern in sg_patterns:\n",
    "                    matches = re.findall(pattern, full_text)\n",
    "                    for match in matches:\n",
    "                        # Strip all non-digit characters for validation\n",
    "                        digits = re.sub(r\"\\D\", \"\", match)\n",
    "                        # Validate using our comprehensive validation function\n",
    "                        formatted = validate_sg_phone(digits)\n",
    "                        if formatted and formatted not in phones:\n",
    "                            phones.append(formatted)\n",
    "            # ========== END PHONE EXTRACTION ==========\n",
    "\n",
    "            # Extract website\n",
    "            valid_websites = []\n",
    "            for a in parent.select(\"a[href^=http]\"):\n",
    "                href = a.get(\"href\", \"\").strip()\n",
    "                href_lower = href.lower()\n",
    "                if not any(domain in href_lower for domain in SOCIAL_MEDIA_DOMAINS):\n",
    "                    if not any(skip in href_lower for skip in [\"recordowl\", \"apify.com\"]):\n",
    "                        if any(tld in href for tld in [\".com\", \".sg\", \".net\", \".org\", \".co\"]):\n",
    "                            valid_websites.append(href)\n",
    "            website = valid_websites[0] if valid_websites else None\n",
    "\n",
    "        # Extract social media links from entire page\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            href = a[\"href\"].strip().lower()\n",
    "            if \"facebook.com\" in href and href not in facebook_links:\n",
    "                facebook_links.append(href)\n",
    "            elif \"linkedin.com\" in href and href not in linkedin_links:\n",
    "                linkedin_links.append(href)\n",
    "            elif \"instagram.com\" in href and href not in instagram_links:\n",
    "                instagram_links.append(href)\n",
    "            elif \"tiktok.com\" in href and href not in tiktok_links:\n",
    "                tiktok_links.append(href)\n",
    "\n",
    "        # Extract registered address\n",
    "        address = None\n",
    "        try:\n",
    "            label_candidates = [\"registered address\", \"registered office address\", \"address\", \"principal place of business\"]\n",
    "            # Prefer structured dt/dd pairs\n",
    "            for dt in soup.select(\"dt\"):\n",
    "                dt_text_lower = dt.get_text(\" \", strip=True).lower()\n",
    "                if any(lbl in dt_text_lower for lbl in label_candidates):\n",
    "                    dd = dt.find_next_sibling(\"dd\")\n",
    "                    if dd:\n",
    "                        candidate = \" \".join(dd.get_text(\" \", strip=True).split())\n",
    "                        if candidate:\n",
    "                            address = candidate\n",
    "                            break\n",
    "            # Fallback: elements with id/aria containing 'address'\n",
    "            if not address:\n",
    "                addr_el = (soup.select_one(\"#address\") or\n",
    "                           soup.select_one(\"[id*='address']\") or\n",
    "                           soup.select_one(\"[aria-labelledby*='address']\"))\n",
    "                if addr_el:\n",
    "                    candidate = \" \".join(addr_el.get_text(\" \", strip=True).split())\n",
    "                    if candidate:\n",
    "                        address = candidate\n",
    "        except Exception:\n",
    "            address = None\n",
    "\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": emails if emails else None,\n",
    "            \"Phones\": phones if phones else None,\n",
    "            \"Website\": website,\n",
    "            \"Facebook\": list(set(facebook_links)) if facebook_links else None,\n",
    "            \"LinkedIn\": list(set(linkedin_links)) if linkedin_links else None,\n",
    "            \"Instagram\": list(set(instagram_links)) if instagram_links else None,\n",
    "            \"TikTok\": list(set(tiktok_links)) if tiktok_links else None,\n",
    "            \"address\": address,\n",
    "            \"RecordOwl_Link\": record_owl_url,\n",
    "        })\n",
    "        \n",
    "        # Print extraction results with actual phone numbers\n",
    "        if phones:\n",
    "            phone_list = \", \".join(phones)\n",
    "            print(f\"  âœ… Extracted: {len(emails) if emails else 0} email(s), {len(phones)} phone(s): {phone_list}\")\n",
    "        else:\n",
    "            print(f\"  âœ… Extracted: {len(emails) if emails else 0} email(s), Phone: None found\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Error parsing HTML for {uen}: {e}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"address\": None,\n",
    "            \"RecordOwl_Link\": record_owl_url or None,\n",
    "            \"Error\": f\"HTML parsing error: {str(e)}\"\n",
    "        })\n",
    "\n",
    "    # Dynamic sleep time to avoid rate limiting and 403 blocks\n",
    "    # Longer delays reduce detection and blocking\n",
    "    base_sleep = 20  # Increased from 10\n",
    "    random_addition = (idx % 10) + 5  # 5-14 seconds random\n",
    "    sleep_time = base_sleep + random_addition  # 25-34 seconds total\n",
    "\n",
    "    print(f\"  ðŸ’¤ Sleeping for {sleep_time}s before next request...\")\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "    # Extra delay after every 5th request to further avoid detection\n",
    "    if idx % 5 == 0:\n",
    "        extra_wait = 30\n",
    "        print(f\"  ðŸ›‘ Checkpoint pause: waiting extra {extra_wait}s...\")\n",
    "        time.sleep(extra_wait)\n",
    "\n",
    "New_Fresh_Leads = pd.DataFrame(all_results)\n",
    "\n",
    "# Ensure 'address' appears right after 'UEN'\n",
    "if 'address' in New_Fresh_Leads.columns and 'UEN' in New_Fresh_Leads.columns:\n",
    "    cols = list(New_Fresh_Leads.columns)\n",
    "    cols.insert(1, cols.pop(cols.index('address')))\n",
    "    New_Fresh_Leads = New_Fresh_Leads.loc[:, cols]\n",
    "\n",
    "print(\"\\nâœ… Scraping complete!\")\n",
    "print(f\"\\nðŸ“Š Results summary:\")\n",
    "print(f\"   Total processed: {len(New_Fresh_Leads)}\")\n",
    "print(f\"   With emails: {New_Fresh_Leads['Emails'].notna().sum()}\")\n",
    "print(f\"   With phones: {New_Fresh_Leads['Phones'].notna().sum()}\")\n",
    "print(f\"   With websites: {New_Fresh_Leads['Website'].notna().sum()}\")\n",
    "\n",
    "New_Fresh_Leads.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5db93a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>address</th>\n",
       "      <th>Emails</th>\n",
       "      <th>Phones</th>\n",
       "      <th>Website</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Instagram</th>\n",
       "      <th>TikTok</th>\n",
       "      <th>RecordOwl_Link</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53431824W</td>\n",
       "      <td>230 COMPASSVALE WALK #10-430 SINGAPORE 540230</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.tutorsville.sg/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/tutorsville-sg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202344030R</td>\n",
       "      <td>87 BEACH ROAD #04-03 CHYE SING BUILDING 189695</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6591943237]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/chem-affinity-le...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T15LL1885G</td>\n",
       "      <td>201E TAMPINES STREET 23 #01-122 SINGAPORE 527201</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6568176157]</td>\n",
       "      <td>https://edureachsg.com</td>\n",
       "      <td>[https://www.facebook.com/edureachservices]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/edureach-service...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53200915X</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Scraping error: Failed to load company page: n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201733719E</td>\n",
       "      <td>47 KALLANG PUDDING ROAD #01-01 THE CRESCENT @ ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6586860777]</td>\n",
       "      <td>https://jusinfants.com</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/jusinfantsplayhouse/]</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/jus-infants-macp...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53227394W</td>\n",
       "      <td>555 ANG MO KIO AVENUE 10 #01-1958 CHENG SAN PL...</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6598524810]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/maths-tablet</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202209857Z</td>\n",
       "      <td>54 CASHEW ROAD #02-02 CASHEW PARK CONDOMINIUM ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6598193093]</td>\n",
       "      <td>http://www.yorkearlyyears.com/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/york-education-p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201711911W</td>\n",
       "      <td>351 BRADDELL ROAD #03-01 351 ON BRADDELL SINGA...</td>\n",
       "      <td>[principal-rochester@maplebear.sg]</td>\n",
       "      <td>[+6562521488]</td>\n",
       "      <td>https://maplebear.sg/contact-us</td>\n",
       "      <td>[https://www.facebook.com/maplebearsg]</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/maplebear_rochester...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/maplebear-learni...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>201540131W</td>\n",
       "      <td>684A JURONG WEST STREET 64 #17-103 SINGAPORE 6...</td>\n",
       "      <td>[sg_4hands@outlook.com]</td>\n",
       "      <td>[+6594203111]</td>\n",
       "      <td>https://4handsda.com</td>\n",
       "      <td>[https://www.facebook.com/4handsda/]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/4hands-dental-as...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202337418G</td>\n",
       "      <td>433 CLEMENTI AVENUE 3 #01-258 120433</td>\n",
       "      <td>[enquiries@outoftheboxacademy.com]</td>\n",
       "      <td>[+6580664284]</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.facebook.com/outofboxacademy/, ht...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/otbstudentcare/]</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/out-of-the-box-a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          UEN                                            address  \\\n",
       "0   53431824W      230 COMPASSVALE WALK #10-430 SINGAPORE 540230   \n",
       "1  202344030R     87 BEACH ROAD #04-03 CHYE SING BUILDING 189695   \n",
       "2  T15LL1885G   201E TAMPINES STREET 23 #01-122 SINGAPORE 527201   \n",
       "3   53200915X                                               None   \n",
       "4  201733719E  47 KALLANG PUDDING ROAD #01-01 THE CRESCENT @ ...   \n",
       "5   53227394W  555 ANG MO KIO AVENUE 10 #01-1958 CHENG SAN PL...   \n",
       "6  202209857Z  54 CASHEW ROAD #02-02 CASHEW PARK CONDOMINIUM ...   \n",
       "7  201711911W  351 BRADDELL ROAD #03-01 351 ON BRADDELL SINGA...   \n",
       "8  201540131W  684A JURONG WEST STREET 64 #17-103 SINGAPORE 6...   \n",
       "9  202337418G               433 CLEMENTI AVENUE 3 #01-258 120433   \n",
       "\n",
       "                               Emails         Phones  \\\n",
       "0                                None           None   \n",
       "1                                None  [+6591943237]   \n",
       "2                                None  [+6568176157]   \n",
       "3                                None           None   \n",
       "4                                None  [+6586860777]   \n",
       "5                                None  [+6598524810]   \n",
       "6                                None  [+6598193093]   \n",
       "7  [principal-rochester@maplebear.sg]  [+6562521488]   \n",
       "8             [sg_4hands@outlook.com]  [+6594203111]   \n",
       "9  [enquiries@outoftheboxacademy.com]  [+6580664284]   \n",
       "\n",
       "                           Website  \\\n",
       "0      https://www.tutorsville.sg/   \n",
       "1                             None   \n",
       "2           https://edureachsg.com   \n",
       "3                             None   \n",
       "4           https://jusinfants.com   \n",
       "5                             None   \n",
       "6   http://www.yorkearlyyears.com/   \n",
       "7  https://maplebear.sg/contact-us   \n",
       "8             https://4handsda.com   \n",
       "9                             None   \n",
       "\n",
       "                                            Facebook LinkedIn  \\\n",
       "0                                               None     None   \n",
       "1                                               None     None   \n",
       "2        [https://www.facebook.com/edureachservices]     None   \n",
       "3                                               None     None   \n",
       "4                                               None     None   \n",
       "5                                               None     None   \n",
       "6                                               None     None   \n",
       "7             [https://www.facebook.com/maplebearsg]     None   \n",
       "8               [https://www.facebook.com/4handsda/]     None   \n",
       "9  [https://www.facebook.com/outofboxacademy/, ht...     None   \n",
       "\n",
       "                                           Instagram TikTok  \\\n",
       "0                                               None   None   \n",
       "1                                               None   None   \n",
       "2                                               None   None   \n",
       "3                                               None   None   \n",
       "4   [https://www.instagram.com/jusinfantsplayhouse/]   None   \n",
       "5                                               None   None   \n",
       "6                                               None   None   \n",
       "7  [https://www.instagram.com/maplebear_rochester...   None   \n",
       "8                                               None   None   \n",
       "9        [https://www.instagram.com/otbstudentcare/]   None   \n",
       "\n",
       "                                      RecordOwl_Link  \\\n",
       "0       https://recordowl.com/company/tutorsville-sg   \n",
       "1  https://recordowl.com/company/chem-affinity-le...   \n",
       "2  https://recordowl.com/company/edureach-service...   \n",
       "3                                               None   \n",
       "4  https://recordowl.com/company/jus-infants-macp...   \n",
       "5         https://recordowl.com/company/maths-tablet   \n",
       "6  https://recordowl.com/company/york-education-p...   \n",
       "7  https://recordowl.com/company/maplebear-learni...   \n",
       "8  https://recordowl.com/company/4hands-dental-as...   \n",
       "9  https://recordowl.com/company/out-of-the-box-a...   \n",
       "\n",
       "                                               Error  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  Scraping error: Failed to load company page: n...  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder columns: put 'address' immediately after 'UEN'\n",
    "if 'address' in New_Fresh_Leads.columns and 'UEN' in New_Fresh_Leads.columns:\n",
    "    cols = list(New_Fresh_Leads.columns)\n",
    "    cols.insert(1, cols.pop(cols.index('address')))\n",
    "    New_Fresh_Leads = New_Fresh_Leads.loc[:, cols]\n",
    "\n",
    "New_Fresh_Leads.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef4a99e",
   "metadata": {},
   "source": [
    "### Address Formatting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43f7d39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>Emails</th>\n",
       "      <th>Phones</th>\n",
       "      <th>Website</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Instagram</th>\n",
       "      <th>TikTok</th>\n",
       "      <th>RecordOwl_Link</th>\n",
       "      <th>Error</th>\n",
       "      <th>operational_street</th>\n",
       "      <th>operational_unit</th>\n",
       "      <th>operational_postal_code</th>\n",
       "      <th>operational_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53431824W</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.tutorsville.sg/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/tutorsville-sg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230 COMPASSVALE WALK</td>\n",
       "      <td>10-430</td>\n",
       "      <td>540230</td>\n",
       "      <td>230 COMPASSVALE WALK 10-430 Singapore 540230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202344030R</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6591943237]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/chem-affinity-le...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87 BEACH ROAD CHYE SING BUILDING</td>\n",
       "      <td>04-03</td>\n",
       "      <td>189695</td>\n",
       "      <td>87 BEACH ROAD CHYE SING BUILDING 04-03 Singapo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T15LL1885G</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6568176157]</td>\n",
       "      <td>https://edureachsg.com</td>\n",
       "      <td>[https://www.facebook.com/edureachservices]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/edureach-service...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201E TAMPINES STREET 23</td>\n",
       "      <td>01-122</td>\n",
       "      <td>527201</td>\n",
       "      <td>201E TAMPINES STREET 23 01-122 Singapore 527201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53200915X</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Scraping error: Failed to load company page: n...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201733719E</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6586860777]</td>\n",
       "      <td>https://jusinfants.com</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/jusinfantsplayhouse/]</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/jus-infants-macp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47 KALLANG PUDDING ROAD THE CRESCENT @ KALLANG</td>\n",
       "      <td>01-01</td>\n",
       "      <td>349318</td>\n",
       "      <td>47 KALLANG PUDDING ROAD THE CRESCENT @ KALLANG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53227394W</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6598524810]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/maths-tablet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555 ANG MO KIO AVENUE 10 CHENG SAN PLACE</td>\n",
       "      <td>01-1958</td>\n",
       "      <td>560555</td>\n",
       "      <td>555 ANG MO KIO AVENUE 10 CHENG SAN PLACE 01-19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202209857Z</td>\n",
       "      <td>None</td>\n",
       "      <td>[+6598193093]</td>\n",
       "      <td>http://www.yorkearlyyears.com/</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/york-education-p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54 CASHEW ROAD CASHEW PARK CONDOMINIUM</td>\n",
       "      <td>02-02</td>\n",
       "      <td>679637</td>\n",
       "      <td>54 CASHEW ROAD CASHEW PARK CONDOMINIUM 02-02 S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>201711911W</td>\n",
       "      <td>[principal-rochester@maplebear.sg]</td>\n",
       "      <td>[+6562521488]</td>\n",
       "      <td>https://maplebear.sg/contact-us</td>\n",
       "      <td>[https://www.facebook.com/maplebearsg]</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/maplebear_rochester...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/maplebear-learni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>351 BRADDELL ROAD 351 ON BRADDELL</td>\n",
       "      <td>03-01</td>\n",
       "      <td>579713</td>\n",
       "      <td>351 BRADDELL ROAD 351 ON BRADDELL 03-01 Singap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>201540131W</td>\n",
       "      <td>[sg_4hands@outlook.com]</td>\n",
       "      <td>[+6594203111]</td>\n",
       "      <td>https://4handsda.com</td>\n",
       "      <td>[https://www.facebook.com/4handsda/]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/4hands-dental-as...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>684A JURONG WEST STREET 64</td>\n",
       "      <td>17-103</td>\n",
       "      <td>641684</td>\n",
       "      <td>684A JURONG WEST STREET 64 17-103 Singapore 64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202337418G</td>\n",
       "      <td>[enquiries@outoftheboxacademy.com]</td>\n",
       "      <td>[+6580664284]</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.facebook.com/outofboxacademy/, ht...</td>\n",
       "      <td>None</td>\n",
       "      <td>[https://www.instagram.com/otbstudentcare/]</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/out-of-the-box-a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>433 CLEMENTI AVENUE 3</td>\n",
       "      <td>01-258</td>\n",
       "      <td>120433</td>\n",
       "      <td>433 CLEMENTI AVENUE 3 01-258 Singapore 120433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          UEN                              Emails         Phones  \\\n",
       "0   53431824W                                None           None   \n",
       "1  202344030R                                None  [+6591943237]   \n",
       "2  T15LL1885G                                None  [+6568176157]   \n",
       "3   53200915X                                None           None   \n",
       "4  201733719E                                None  [+6586860777]   \n",
       "5   53227394W                                None  [+6598524810]   \n",
       "6  202209857Z                                None  [+6598193093]   \n",
       "7  201711911W  [principal-rochester@maplebear.sg]  [+6562521488]   \n",
       "8  201540131W             [sg_4hands@outlook.com]  [+6594203111]   \n",
       "9  202337418G  [enquiries@outoftheboxacademy.com]  [+6580664284]   \n",
       "\n",
       "                           Website  \\\n",
       "0      https://www.tutorsville.sg/   \n",
       "1                             None   \n",
       "2           https://edureachsg.com   \n",
       "3                             None   \n",
       "4           https://jusinfants.com   \n",
       "5                             None   \n",
       "6   http://www.yorkearlyyears.com/   \n",
       "7  https://maplebear.sg/contact-us   \n",
       "8             https://4handsda.com   \n",
       "9                             None   \n",
       "\n",
       "                                            Facebook LinkedIn  \\\n",
       "0                                               None     None   \n",
       "1                                               None     None   \n",
       "2        [https://www.facebook.com/edureachservices]     None   \n",
       "3                                               None     None   \n",
       "4                                               None     None   \n",
       "5                                               None     None   \n",
       "6                                               None     None   \n",
       "7             [https://www.facebook.com/maplebearsg]     None   \n",
       "8               [https://www.facebook.com/4handsda/]     None   \n",
       "9  [https://www.facebook.com/outofboxacademy/, ht...     None   \n",
       "\n",
       "                                           Instagram TikTok  \\\n",
       "0                                               None   None   \n",
       "1                                               None   None   \n",
       "2                                               None   None   \n",
       "3                                               None   None   \n",
       "4   [https://www.instagram.com/jusinfantsplayhouse/]   None   \n",
       "5                                               None   None   \n",
       "6                                               None   None   \n",
       "7  [https://www.instagram.com/maplebear_rochester...   None   \n",
       "8                                               None   None   \n",
       "9        [https://www.instagram.com/otbstudentcare/]   None   \n",
       "\n",
       "                                      RecordOwl_Link  \\\n",
       "0       https://recordowl.com/company/tutorsville-sg   \n",
       "1  https://recordowl.com/company/chem-affinity-le...   \n",
       "2  https://recordowl.com/company/edureach-service...   \n",
       "3                                               None   \n",
       "4  https://recordowl.com/company/jus-infants-macp...   \n",
       "5         https://recordowl.com/company/maths-tablet   \n",
       "6  https://recordowl.com/company/york-education-p...   \n",
       "7  https://recordowl.com/company/maplebear-learni...   \n",
       "8  https://recordowl.com/company/4hands-dental-as...   \n",
       "9  https://recordowl.com/company/out-of-the-box-a...   \n",
       "\n",
       "                                               Error  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  Scraping error: Failed to load company page: n...   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "6                                                NaN   \n",
       "7                                                NaN   \n",
       "8                                                NaN   \n",
       "9                                                NaN   \n",
       "\n",
       "                               operational_street operational_unit  \\\n",
       "0                            230 COMPASSVALE WALK           10-430   \n",
       "1                87 BEACH ROAD CHYE SING BUILDING            04-03   \n",
       "2                         201E TAMPINES STREET 23           01-122   \n",
       "3                                            None             None   \n",
       "4  47 KALLANG PUDDING ROAD THE CRESCENT @ KALLANG            01-01   \n",
       "5        555 ANG MO KIO AVENUE 10 CHENG SAN PLACE          01-1958   \n",
       "6          54 CASHEW ROAD CASHEW PARK CONDOMINIUM            02-02   \n",
       "7               351 BRADDELL ROAD 351 ON BRADDELL            03-01   \n",
       "8                      684A JURONG WEST STREET 64           17-103   \n",
       "9                           433 CLEMENTI AVENUE 3           01-258   \n",
       "\n",
       "  operational_postal_code                                operational_address  \n",
       "0                  540230       230 COMPASSVALE WALK 10-430 Singapore 540230  \n",
       "1                  189695  87 BEACH ROAD CHYE SING BUILDING 04-03 Singapo...  \n",
       "2                  527201    201E TAMPINES STREET 23 01-122 Singapore 527201  \n",
       "3                    None                                               None  \n",
       "4                  349318  47 KALLANG PUDDING ROAD THE CRESCENT @ KALLANG...  \n",
       "5                  560555  555 ANG MO KIO AVENUE 10 CHENG SAN PLACE 01-19...  \n",
       "6                  679637  54 CASHEW ROAD CASHEW PARK CONDOMINIUM 02-02 S...  \n",
       "7                  579713  351 BRADDELL ROAD 351 ON BRADDELL 03-01 Singap...  \n",
       "8                  641684  684A JURONG WEST STREET 64 17-103 Singapore 64...  \n",
       "9                  120433      433 CLEMENTI AVENUE 3 01-258 Singapore 120433  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Pre-compile patterns for speed\n",
    "POSTAL_RE = re.compile(r\"(?:\\bSingapore\\b\\s*)?(?P<postal>\\d{6})(?!\\d)\", re.IGNORECASE)\n",
    "UNIT_RES = [\n",
    "    re.compile(r\"#\\s*[A-Za-z0-9]{1,4}\\s*[-â€“]\\s*[A-Za-z0-9]{1,4}\", re.IGNORECASE),\n",
    "    re.compile(r\"\\bunit\\s*[#:]?\\s*[A-Za-z0-9]{1,4}\\s*[-â€“]\\s*[A-Za-z0-9]{1,4}\\b\", re.IGNORECASE),\n",
    "    re.compile(r\"\\bunit\\s*[#:]?\\s*[A-Za-z0-9]{1,5}\\b\", re.IGNORECASE),\n",
    "]\n",
    "\n",
    "def normalize_spaces(text: str) -> str:\n",
    "    text = re.sub(r\"[\\n\\r\\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    return text.strip(\" ,;|/\")\n",
    "\n",
    "def extract_postal(text: str) -> tuple[str, str | None]:\n",
    "    if not text:\n",
    "        return text, None\n",
    "    matches = list(POSTAL_RE.finditer(text))\n",
    "    if matches:\n",
    "        m = matches[-1]\n",
    "        postal = m.group(\"postal\")\n",
    "        start, end = m.span()\n",
    "        cleaned = text[:start] + text[end:]\n",
    "        cleaned = re.sub(r\"\\bSingapore\\b\", \"\", cleaned, flags=re.IGNORECASE)\n",
    "        return normalize_spaces(cleaned), postal\n",
    "    return normalize_spaces(text), None\n",
    "\n",
    "def extract_unit(text: str) -> tuple[str, str | None]:\n",
    "    if not text:\n",
    "        return text, None\n",
    "    for rx in UNIT_RES:\n",
    "        m = rx.search(text)\n",
    "        if m:\n",
    "            unit_raw = m.group(0)\n",
    "            cleaned = normalize_spaces(text[:m.start()] + text[m.end():])\n",
    "            unit_digits = re.sub(r\"^unit\\s*[#:]?\\s*\", \"\", unit_raw, flags=re.IGNORECASE)\n",
    "            unit_digits = normalize_spaces(unit_digits)\n",
    "            unit_digits = unit_digits.replace(' â€“ ', '-').replace('â€“', '-').replace(' ', '')\n",
    "            unit_digits = unit_digits.lstrip('#')\n",
    "            return cleaned, unit_digits\n",
    "    return normalize_spaces(text), None\n",
    "\n",
    "def clean_street(text: str) -> str | None:\n",
    "    if not text:\n",
    "        return None\n",
    "    text = normalize_spaces(text)\n",
    "    text = re.sub(r\"\\s*,\\s*\", \", \", text)\n",
    "    return text if text.isupper() else text.title()\n",
    "\n",
    "def split_address_sg(address: str) -> dict:\n",
    "    if not isinstance(address, str) or not address.strip():\n",
    "        return {\"street\": None, \"unit\": None, \"postal_code\": None, \"address_clean\": None}\n",
    "    raw = normalize_spaces(address)\n",
    "    without_postal, postal = extract_postal(raw)\n",
    "    without_unit, unit = extract_unit(without_postal)\n",
    "    without_unit = normalize_spaces(re.sub(r\"\\bSingapore\\b\", \"\", without_unit, flags=re.IGNORECASE))\n",
    "    street = clean_street(without_unit)\n",
    "    address_clean = normalize_spaces(\" \".join(x for x in [street or \"\", unit or \"\", f\"Singapore {postal}\" if postal else \"\"] if x))\n",
    "    return {\"street\": street, \"unit\": unit, \"postal_code\": postal, \"address_clean\": address_clean}\n",
    "\n",
    "# Apply to current result DF -> create a new dataframe with clean components\n",
    "if 'address' not in New_Fresh_Leads.columns:\n",
    "    raise ValueError(\"Column 'address' not found in New_Fresh_Leads. Run the scraping cell first.\")\n",
    "\n",
    "parsed_df = pd.DataFrame(list(New_Fresh_Leads[\"address\"].apply(split_address_sg)))\n",
    "\n",
    "# New DataFrame with clean address fields and without raw 'address'\n",
    "Cleaned_New_Fresh_Leads = New_Fresh_Leads.copy()\n",
    "if 'address' in Cleaned_New_Fresh_Leads.columns:\n",
    "    Cleaned_New_Fresh_Leads = Cleaned_New_Fresh_Leads.drop(columns=['address'])\n",
    "Cleaned_New_Fresh_Leads[\"operational_street\"] = parsed_df[\"street\"]\n",
    "Cleaned_New_Fresh_Leads[\"operational_unit\"] = parsed_df[\"unit\"]\n",
    "Cleaned_New_Fresh_Leads[\"operational_postal_code\"] = parsed_df[\"postal_code\"]\n",
    "Cleaned_New_Fresh_Leads[\"operational_address\"] = parsed_df[\"address_clean\"]\n",
    "\n",
    "# Save full result to a new DataFrame and display all columns\n",
    "New_Fresh_Leads_Operational = Cleaned_New_Fresh_Leads.copy()\n",
    "New_Fresh_Leads_Operational\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d354f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Fresh_Leads_Operational.to_csv(\"New_Fresh_Leads_Operational.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
