{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "328e86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767bf86c",
   "metadata": {},
   "source": [
    "### Getting Master DB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa7f0eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ACRA_REGISTERED_NAME</th>\n",
       "      <th>BRAND_NAME</th>\n",
       "      <th>SSIC_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04799400B</td>\n",
       "      <td>AIK BEE TEXTILE CO</td>\n",
       "      <td>AIK BEE TEXTILE CO</td>\n",
       "      <td>46411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03376200K</td>\n",
       "      <td>SERANGOON GARDEN CLINIC AND DISPENSARY</td>\n",
       "      <td>GARDEN CLINIC</td>\n",
       "      <td>550263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06239600E</td>\n",
       "      <td>SALON DE BENZIMEN</td>\n",
       "      <td>SALON DE BENZIMEN</td>\n",
       "      <td>96021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06952000C</td>\n",
       "      <td>SU LAN LADIES FASHION</td>\n",
       "      <td>SU LAN LADIES FASHION</td>\n",
       "      <td>14103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10381600C</td>\n",
       "      <td>SIN HAI PRINTING SERVICE</td>\n",
       "      <td>SIN HAI PRINTING SERVICE</td>\n",
       "      <td>18113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7444</th>\n",
       "      <td>201734006N</td>\n",
       "      <td>MISTER MOBILE HOUGANG PTE. LTD.</td>\n",
       "      <td>MISTER MOBILE (HOUGANG)</td>\n",
       "      <td>95120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7445</th>\n",
       "      <td>202210879W</td>\n",
       "      <td>MISTER MOBILE CHINATOWN PTE. LTD.</td>\n",
       "      <td>MISTER MOBILE (CHINATOWN)</td>\n",
       "      <td>47411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7446</th>\n",
       "      <td>202205507G</td>\n",
       "      <td>MISTER MOBILE PTE. LTD.</td>\n",
       "      <td>MISTER MOBILE HQ</td>\n",
       "      <td>64202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7454</th>\n",
       "      <td>53473046M</td>\n",
       "      <td>BLOONIES</td>\n",
       "      <td>BLOONIES</td>\n",
       "      <td>47742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7455</th>\n",
       "      <td>53478373B</td>\n",
       "      <td>BLOOMSNBALLOONS</td>\n",
       "      <td>BLOOMS AND BALLOONS</td>\n",
       "      <td>47742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6734 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             UEN                    ACRA_REGISTERED_NAME  \\\n",
       "0      04799400B                      AIK BEE TEXTILE CO   \n",
       "1      03376200K  SERANGOON GARDEN CLINIC AND DISPENSARY   \n",
       "2      06239600E                       SALON DE BENZIMEN   \n",
       "3      06952000C                   SU LAN LADIES FASHION   \n",
       "4      10381600C                SIN HAI PRINTING SERVICE   \n",
       "...          ...                                     ...   \n",
       "7444  201734006N         MISTER MOBILE HOUGANG PTE. LTD.   \n",
       "7445  202210879W       MISTER MOBILE CHINATOWN PTE. LTD.   \n",
       "7446  202205507G                 MISTER MOBILE PTE. LTD.   \n",
       "7454   53473046M                                BLOONIES   \n",
       "7455   53478373B                         BLOOMSNBALLOONS   \n",
       "\n",
       "                     BRAND_NAME  SSIC_CODE  \n",
       "0            AIK BEE TEXTILE CO      46411  \n",
       "1                 GARDEN CLINIC     550263  \n",
       "2             SALON DE BENZIMEN      96021  \n",
       "3         SU LAN LADIES FASHION      14103  \n",
       "4      SIN HAI PRINTING SERVICE      18113  \n",
       "...                         ...        ...  \n",
       "7444    MISTER MOBILE (HOUGANG)      95120  \n",
       "7445  MISTER MOBILE (CHINATOWN)      47411  \n",
       "7446           MISTER MOBILE HQ      64202  \n",
       "7454                   BLOONIES      47742  \n",
       "7455        BLOOMS AND BALLOONS      47742  \n",
       "\n",
       "[6734 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- CONFIG ---\n",
    "file_path = \"./Master DB/Master_DB_oct22.xlsx\"\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def clean_uen(u: str) -> str | None:\n",
    "    if pd.isna(u):\n",
    "        return None\n",
    "    return re.sub(r\"[^A-Z0-9]\", \"\", str(u).upper().strip())\n",
    "\n",
    "def clean_text(text: str) -> str | None:\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    text = str(text).strip().upper()\n",
    "    return None if text == \"NAN\" else text\n",
    "\n",
    "def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert all column names to uppercase, replace non-alphanumeric with single underscore, remove trailing underscores.\"\"\"\n",
    "    new_cols = []\n",
    "    for col in df.columns:\n",
    "        col_std = re.sub(r\"[^A-Z0-9]\", \"_\", col.upper().strip())\n",
    "        col_std = re.sub(r\"_+\", \"_\", col_std)  # Replace multiple underscores with single\n",
    "        col_std = col_std.strip(\"_\")  # Remove leading/trailing underscores\n",
    "        new_cols.append(col_std)\n",
    "    df.columns = new_cols\n",
    "    return df\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "master_db_df = pd.read_excel(file_path)\n",
    "\n",
    "# --- SELECT RELEVANT COLUMNS ---\n",
    "columns_to_keep = [\n",
    "    \"Company Registration Number (UEN)\",\n",
    "    \"ACRA REGISTERED NAME\",\n",
    "    \"Brand/Deal Name/Business Name\",\n",
    "    \"Primary SSIC Code\",\n",
    "    \"PIC NAME 1 Contact Number\",\n",
    "    \"PIC 1 email address\",\n",
    "    \"Website URL\",\n",
    "    \"Parent Industry Type\",\n",
    "    \"Sub Industry\"\n",
    "]\n",
    "master_db_df = master_db_df[columns_to_keep].copy()\n",
    "\n",
    "# --- STANDARDIZE COLUMN NAMES ---\n",
    "master_db_df = standardize_columns(master_db_df)\n",
    "\n",
    "# --- CLEANING & RENAME SPECIFIC COLUMNS ---\n",
    "# Dynamically find the UEN column (first column containing 'UEN')\n",
    "uen_col = [c for c in master_db_df.columns if \"UEN\" in c][0]\n",
    "master_db_df[\"UEN\"] = master_db_df[uen_col].apply(clean_uen)\n",
    "master_db_df = master_db_df.drop(columns=[uen_col])\n",
    "\n",
    "# Rename other columns consistently\n",
    "rename_map = {\n",
    "    \"BRAND_DEAL_NAME_BUSINESS_NAME\": \"BRAND_NAME\",\n",
    "    \"PRIMARY_SSIC_CODE\": \"SSIC_CODE\",\n",
    "    \"ACRA_REGISTERED_NAME\": \"ACRA_REGISTERED_NAME\"\n",
    "}\n",
    "master_db_df = master_db_df.rename(columns={k: v for k, v in rename_map.items() if k in master_db_df.columns})\n",
    "\n",
    "# Clean text columns\n",
    "for col in [\"ACRA_REGISTERED_NAME\", \"BRAND_NAME\"]:\n",
    "    if col in master_db_df.columns:\n",
    "        master_db_df[col] = master_db_df[col].apply(clean_text)\n",
    "\n",
    "# Convert SSIC_CODE to integer if exists\n",
    "if \"SSIC_CODE\" in master_db_df.columns:\n",
    "    master_db_df[\"SSIC_CODE\"] = master_db_df[\"SSIC_CODE\"].astype(\"Int64\")\n",
    "\n",
    "# Keep only required columns if they exist\n",
    "required_cols = [\"UEN\", \"ACRA_REGISTERED_NAME\", \"BRAND_NAME\", \"SSIC_CODE\"]\n",
    "master_db_df = master_db_df[[c for c in required_cols if c in master_db_df.columns]]\n",
    "\n",
    "# Filter out rows with missing or empty UEN\n",
    "master_db_df = master_db_df[master_db_df[\"UEN\"].notna() & (master_db_df[\"UEN\"].str.strip() != \"\")]\n",
    "\n",
    "master_db_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e98cff",
   "metadata": {},
   "source": [
    "### Getting ACRA Data (Filter by Live, Live Company only & non relevant ssic code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e678fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Folder containing your CSVs\n",
    "# -------------------------------------------------------------\n",
    "folder_path = \"Acra_Data\"\n",
    "\n",
    "# Get all CSV file paths inside the folder\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "# Read and combine all CSVs\n",
    "# Using low_memory=False to avoid DtypeWarning for mixed types\n",
    "df = pd.concat((pd.read_csv(f, low_memory=False) for f in csv_files), ignore_index=True)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Convert all column names to uppercase\n",
    "# -------------------------------------------------------------\n",
    "df.columns = df.columns.str.upper()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Select relevant columns (now in uppercase)\n",
    "# -------------------------------------------------------------\n",
    "acra_data = df[[\n",
    "    \"UEN\",\n",
    "    \"ENTITY_NAME\",\n",
    "    \"BUSINESS_CONSTITUTION_DESCRIPTION\",\n",
    "    \"ENTITY_TYPE_DESCRIPTION\",\n",
    "    \"ENTITY_STATUS_DESCRIPTION\",\n",
    "    \"REGISTRATION_INCORPORATION_DATE\",\n",
    "    \"PRIMARY_SSIC_CODE\",\n",
    "    \"STREET_NAME\",\n",
    "    \"POSTAL_CODE\"\n",
    "]].copy()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Convert to proper data types\n",
    "# -------------------------------------------------------------\n",
    "acra_data['UEN'] = acra_data['UEN'].astype('string')\n",
    "acra_data['ENTITY_NAME'] = acra_data['ENTITY_NAME'].astype('string')\n",
    "acra_data['BUSINESS_CONSTITUTION_DESCRIPTION'] = acra_data['BUSINESS_CONSTITUTION_DESCRIPTION'].astype('string')\n",
    "acra_data['ENTITY_TYPE_DESCRIPTION'] = acra_data['ENTITY_TYPE_DESCRIPTION'].astype('string')\n",
    "acra_data['ENTITY_STATUS_DESCRIPTION'] = acra_data['ENTITY_STATUS_DESCRIPTION'].astype('string')\n",
    "acra_data['REGISTRATION_INCORPORATION_DATE'] = pd.to_datetime(acra_data['REGISTRATION_INCORPORATION_DATE'], errors='coerce')\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Clean string columns — trim, remove extra spaces, uppercase\n",
    "# -------------------------------------------------------------\n",
    "for col in [\n",
    "    'UEN',\n",
    "    'ENTITY_NAME',\n",
    "    'BUSINESS_CONSTITUTION_DESCRIPTION',\n",
    "    'ENTITY_TYPE_DESCRIPTION',\n",
    "    'ENTITY_STATUS_DESCRIPTION',\n",
    "    'STREET_NAME',\n",
    "    'POSTAL_CODE'\n",
    "]:\n",
    "    acra_data[col] = (\n",
    "        acra_data[col]\n",
    "        .fillna('')\n",
    "        .str.strip()\n",
    "        .str.replace(r'\\s+', ' ', regex=True)\n",
    "        .str.upper()\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Replace placeholders with NaN for standardization\n",
    "# -------------------------------------------------------------\n",
    "acra_data.replace(['NA', 'N/A', '-', ''], np.nan, inplace=True)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Convert registration date to dd-mm-yyyy string (optional)\n",
    "# -------------------------------------------------------------\n",
    "acra_data['REGISTRATION_INCORPORATION_DATE'] = acra_data['REGISTRATION_INCORPORATION_DATE'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Filter only live entities (LIVE COMPANY or LIVE)\n",
    "# -------------------------------------------------------------\n",
    "acra_data = acra_data[\n",
    "    acra_data['ENTITY_STATUS_DESCRIPTION'].isin(['LIVE COMPANY', 'LIVE'])\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Exclude specific PRIMARY_SSIC_CODE values (supposedly the data would be 600k plus but when we exclude this would lessen)\n",
    "# -------------------------------------------------------------\n",
    "exclude_codes = [\n",
    "    46900, 47719, 47749, 47539, 47536, 56123,\n",
    "    10711, 10712, 10719, 10732, 10733, 93209\n",
    "]\n",
    "\n",
    "acra_data = acra_data[~acra_data['PRIMARY_SSIC_CODE'].isin(exclude_codes)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37b264bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ENTITY_NAME</th>\n",
       "      <th>BUSINESS_CONSTITUTION_DESCRIPTION</th>\n",
       "      <th>ENTITY_TYPE_DESCRIPTION</th>\n",
       "      <th>ENTITY_STATUS_DESCRIPTION</th>\n",
       "      <th>REGISTRATION_INCORPORATION_DATE</th>\n",
       "      <th>PRIMARY_SSIC_CODE</th>\n",
       "      <th>STREET_NAME</th>\n",
       "      <th>POSTAL_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00182000A</td>\n",
       "      <td>AIK SENG HENG</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>07-02-1975</td>\n",
       "      <td>46302</td>\n",
       "      <td>FISHERY PORT ROAD</td>\n",
       "      <td>619742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00233500W</td>\n",
       "      <td>ASIA STORE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>28-10-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>SIMS AVENUE</td>\n",
       "      <td>387509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00733000J</td>\n",
       "      <td>AIK CHE HIONG</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>02-11-1974</td>\n",
       "      <td>32909</td>\n",
       "      <td>ANG MO KIO INDUSTRIAL PARK 2A</td>\n",
       "      <td>568049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00927000X</td>\n",
       "      <td>A WALIMOHAMED BROS</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>12-11-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>JELLICOE ROAD</td>\n",
       "      <td>208767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01173000E</td>\n",
       "      <td>ANG TECK MOH DEPARTMENT STORE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>30-10-1974</td>\n",
       "      <td>47711</td>\n",
       "      <td>WOODLANDS STREET 12</td>\n",
       "      <td>738623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537323</th>\n",
       "      <td>T25LL0518K</td>\n",
       "      <td>ZEUS BARBERS LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>16-05-2025</td>\n",
       "      <td>96021</td>\n",
       "      <td>KELANTAN LANE</td>\n",
       "      <td>200031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537324</th>\n",
       "      <td>T25LL0858C</td>\n",
       "      <td>ZENSE SPACE LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>01-08-2025</td>\n",
       "      <td>43301</td>\n",
       "      <td>YISHUN INDUSTRIAL STREET 1</td>\n",
       "      <td>768161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537325</th>\n",
       "      <td>T25LL0870A</td>\n",
       "      <td>ZIQZEQ PROCUREMENT LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>04-08-2025</td>\n",
       "      <td>70209</td>\n",
       "      <td>SIN MING LANE</td>\n",
       "      <td>573969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537326</th>\n",
       "      <td>T25LL1049B</td>\n",
       "      <td>ZHONG XIN TRAVEL LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>08-09-2025</td>\n",
       "      <td>79102</td>\n",
       "      <td>JALAN BAHAGIA</td>\n",
       "      <td>320034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537327</th>\n",
       "      <td>T25LL1066B</td>\n",
       "      <td>ZDT DRIVES LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>14-09-2025</td>\n",
       "      <td>47533</td>\n",
       "      <td>FERNVALE ROAD</td>\n",
       "      <td>792466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537328 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               UEN                    ENTITY_NAME  \\\n",
       "0        00182000A                  AIK SENG HENG   \n",
       "1        00233500W                     ASIA STORE   \n",
       "2        00733000J                  AIK CHE HIONG   \n",
       "3        00927000X             A WALIMOHAMED BROS   \n",
       "4        01173000E  ANG TECK MOH DEPARTMENT STORE   \n",
       "...            ...                            ...   \n",
       "537323  T25LL0518K               ZEUS BARBERS LLP   \n",
       "537324  T25LL0858C                ZENSE SPACE LLP   \n",
       "537325  T25LL0870A         ZIQZEQ PROCUREMENT LLP   \n",
       "537326  T25LL1049B           ZHONG XIN TRAVEL LLP   \n",
       "537327  T25LL1066B                 ZDT DRIVES LLP   \n",
       "\n",
       "       BUSINESS_CONSTITUTION_DESCRIPTION           ENTITY_TYPE_DESCRIPTION  \\\n",
       "0                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "1                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "2                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "3                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "4                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "...                                  ...                               ...   \n",
       "537323                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537324                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537325                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537326                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537327                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "\n",
       "       ENTITY_STATUS_DESCRIPTION REGISTRATION_INCORPORATION_DATE  \\\n",
       "0                           LIVE                      07-02-1975   \n",
       "1                           LIVE                      28-10-1974   \n",
       "2                           LIVE                      02-11-1974   \n",
       "3                           LIVE                      12-11-1974   \n",
       "4                           LIVE                      30-10-1974   \n",
       "...                          ...                             ...   \n",
       "537323                      LIVE                      16-05-2025   \n",
       "537324                      LIVE                      01-08-2025   \n",
       "537325                      LIVE                      04-08-2025   \n",
       "537326                      LIVE                      08-09-2025   \n",
       "537327                      LIVE                      14-09-2025   \n",
       "\n",
       "        PRIMARY_SSIC_CODE                    STREET_NAME POSTAL_CODE  \n",
       "0                   46302              FISHERY PORT ROAD      619742  \n",
       "1                   46411                    SIMS AVENUE      387509  \n",
       "2                   32909  ANG MO KIO INDUSTRIAL PARK 2A      568049  \n",
       "3                   46411                  JELLICOE ROAD      208767  \n",
       "4                   47711            WOODLANDS STREET 12      738623  \n",
       "...                   ...                            ...         ...  \n",
       "537323              96021                  KELANTAN LANE      200031  \n",
       "537324              43301     YISHUN INDUSTRIAL STREET 1      768161  \n",
       "537325              70209                  SIN MING LANE      573969  \n",
       "537326              79102                  JALAN BAHAGIA      320034  \n",
       "537327              47533                  FERNVALE ROAD      792466  \n",
       "\n",
       "[537328 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acra_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec969fc",
   "metadata": {},
   "source": [
    "### Getting SSIC Industry code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32f4bc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARENT_INDUSTRY</th>\n",
       "      <th>INDUSTRY_TYPE</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>SSIC_CODES</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47711</td>\n",
       "      <td>Retail Sale Of Clothing For Adults</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47712</td>\n",
       "      <td>Retail Sale Of Children And Infants' Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47715</td>\n",
       "      <td>Retail Sale Of Sewing And Clothing Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47719</td>\n",
       "      <td>Retail Sale Of Clothing, Footwear And Leather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47510</td>\n",
       "      <td>Retail Sale Of Textiles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PARENT_INDUSTRY INDUSTRY_TYPE       SUB_INDUSTRY  SSIC_CODES  \\\n",
       "0          Retail        Retail  Fashion & Apparel       47711   \n",
       "1          Retail        Retail  Fashion & Apparel       47712   \n",
       "2          Retail        Retail  Fashion & Apparel       47715   \n",
       "3          Retail        Retail  Fashion & Apparel       47719   \n",
       "4          Retail        Retail  Fashion & Apparel       47510   \n",
       "\n",
       "                                         DESCRIPTION  \n",
       "0                 Retail Sale Of Clothing For Adults  \n",
       "1      Retail Sale Of Children And Infants' Clothing  \n",
       "2     Retail Sale Of Sewing And Clothing Accessories  \n",
       "3  Retail Sale Of Clothing, Footwear And Leather ...  \n",
       "4                            Retail Sale Of Textiles  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "file_path = \"./SSIC_Code/mapped_ssic_code.xlsx\"\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "mapped_ssic_code = pd.read_excel(file_path)\n",
    "\n",
    "# --- STANDARDIZE COLUMN NAMES ---\n",
    "# Uppercase, strip spaces, replace spaces with underscores\n",
    "mapped_ssic_code.columns = (\n",
    "    mapped_ssic_code.columns\n",
    "    .str.strip()\n",
    "    .str.upper()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")\n",
    "\n",
    "# --- KEEP ONLY DESIRED COLUMNS ---\n",
    "columns_to_keep = [\"PARENT_INDUSTRY\", \"INDUSTRY_TYPE\", \"SUB_INDUSTRY\", \"SSIC_CODES\", \"DESCRIPTION\"]\n",
    "mapped_ssic_code = mapped_ssic_code[columns_to_keep].copy()\n",
    "\n",
    "# --- CLEAN SSIC_CODES COLUMN ---\n",
    "mapped_ssic_code[\"SSIC_CODES\"] = (\n",
    "    pd.to_numeric(mapped_ssic_code[\"SSIC_CODES\"], errors=\"coerce\")  # safely convert to numeric\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# --- CLEAN TEXT COLUMNS ---\n",
    "text_cols = [\"PARENT_INDUSTRY\", \"INDUSTRY_TYPE\", \"SUB_INDUSTRY\", \"DESCRIPTION\"]\n",
    "mapped_ssic_code[text_cols] = mapped_ssic_code[text_cols].apply(\n",
    "    lambda col: col.astype(str).str.strip().str.title()\n",
    ")\n",
    "\n",
    "# --- REMOVE DUPLICATES & RESET INDEX ---\n",
    "mapped_ssic_code = mapped_ssic_code.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "mapped_ssic_code.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac763a73",
   "metadata": {},
   "source": [
    "### Merge ACRA data with SSIC code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e62740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PRIMARY_SSIC_CODE to int\n",
    "acra_data[\"PRIMARY_SSIC_CODE\"] = (\n",
    "    pd.to_numeric(acra_data[\"PRIMARY_SSIC_CODE\"], errors=\"coerce\")\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# Merge based on SSIC code\n",
    "acra_data_filtered = acra_data.merge(\n",
    "    mapped_ssic_code,\n",
    "    how=\"left\",\n",
    "    left_on=\"PRIMARY_SSIC_CODE\",\n",
    "    right_on=\"SSIC_CODES\"\n",
    ")\n",
    "\n",
    "# Optional: drop the duplicate 'SSIC CODES' column (keep only PRIMARY_SSIC_CODE)\n",
    "acra_data_filtered = acra_data_filtered.drop(columns=[\"SSIC_CODES\"], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ede8f881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ENTITY_NAME</th>\n",
       "      <th>BUSINESS_CONSTITUTION_DESCRIPTION</th>\n",
       "      <th>ENTITY_TYPE_DESCRIPTION</th>\n",
       "      <th>ENTITY_STATUS_DESCRIPTION</th>\n",
       "      <th>REGISTRATION_INCORPORATION_DATE</th>\n",
       "      <th>PRIMARY_SSIC_CODE</th>\n",
       "      <th>STREET_NAME</th>\n",
       "      <th>POSTAL_CODE</th>\n",
       "      <th>PARENT_INDUSTRY</th>\n",
       "      <th>INDUSTRY_TYPE</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00182000A</td>\n",
       "      <td>AIK SENG HENG</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>07-02-1975</td>\n",
       "      <td>46302</td>\n",
       "      <td>FISHERY PORT ROAD</td>\n",
       "      <td>619742</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Food, Beverages &amp; Tobacco</td>\n",
       "      <td>Wholesale Of Livestock, Meat, Poultry, Eggs An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00233500W</td>\n",
       "      <td>ASIA STORE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>28-10-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>SIMS AVENUE</td>\n",
       "      <td>387509</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Textiles And Leathers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00733000J</td>\n",
       "      <td>AIK CHE HIONG</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>02-11-1974</td>\n",
       "      <td>32909</td>\n",
       "      <td>ANG MO KIO INDUSTRIAL PARK 2A</td>\n",
       "      <td>568049</td>\n",
       "      <td>Others</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Other Specialised Manufacturing &amp; Distribution</td>\n",
       "      <td>Other Manufacturing Industries N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00927000X</td>\n",
       "      <td>A WALIMOHAMED BROS</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>12-11-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>JELLICOE ROAD</td>\n",
       "      <td>208767</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Textiles And Leathers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01173000E</td>\n",
       "      <td>ANG TECK MOH DEPARTMENT STORE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>30-10-1974</td>\n",
       "      <td>47711</td>\n",
       "      <td>WOODLANDS STREET 12</td>\n",
       "      <td>738623</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>Retail Sale Of Clothing For Adults</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537323</th>\n",
       "      <td>T25LL0518K</td>\n",
       "      <td>ZEUS BARBERS LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>16-05-2025</td>\n",
       "      <td>96021</td>\n",
       "      <td>KELANTAN LANE</td>\n",
       "      <td>200031</td>\n",
       "      <td>Services</td>\n",
       "      <td>Services</td>\n",
       "      <td>Hair Salons &amp; Barbershops</td>\n",
       "      <td>Hairdressing Salons/Shops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537324</th>\n",
       "      <td>T25LL0858C</td>\n",
       "      <td>ZENSE SPACE LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>01-08-2025</td>\n",
       "      <td>43301</td>\n",
       "      <td>YISHUN INDUSTRIAL STREET 1</td>\n",
       "      <td>768161</td>\n",
       "      <td>Others</td>\n",
       "      <td>Built Environment &amp; Infrastructure</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Renovation Contractors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537325</th>\n",
       "      <td>T25LL0870A</td>\n",
       "      <td>ZIQZEQ PROCUREMENT LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>04-08-2025</td>\n",
       "      <td>70209</td>\n",
       "      <td>SIN MING LANE</td>\n",
       "      <td>573969</td>\n",
       "      <td>Others</td>\n",
       "      <td>Finance, Legal &amp; Real Estate</td>\n",
       "      <td>Legal, Accounting &amp; Consultancy Activities</td>\n",
       "      <td>Management Consultancy Services N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537326</th>\n",
       "      <td>T25LL1049B</td>\n",
       "      <td>ZHONG XIN TRAVEL LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>08-09-2025</td>\n",
       "      <td>79102</td>\n",
       "      <td>JALAN BAHAGIA</td>\n",
       "      <td>320034</td>\n",
       "      <td>Others</td>\n",
       "      <td>Tourism, Agency</td>\n",
       "      <td>Travel Agencies &amp; Tour Operators</td>\n",
       "      <td>Travel Agencies And Tour Operators (Mainly Out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537327</th>\n",
       "      <td>T25LL1066B</td>\n",
       "      <td>ZDT DRIVES LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>14-09-2025</td>\n",
       "      <td>47533</td>\n",
       "      <td>FERNVALE ROAD</td>\n",
       "      <td>792466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537328 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               UEN                    ENTITY_NAME  \\\n",
       "0        00182000A                  AIK SENG HENG   \n",
       "1        00233500W                     ASIA STORE   \n",
       "2        00733000J                  AIK CHE HIONG   \n",
       "3        00927000X             A WALIMOHAMED BROS   \n",
       "4        01173000E  ANG TECK MOH DEPARTMENT STORE   \n",
       "...            ...                            ...   \n",
       "537323  T25LL0518K               ZEUS BARBERS LLP   \n",
       "537324  T25LL0858C                ZENSE SPACE LLP   \n",
       "537325  T25LL0870A         ZIQZEQ PROCUREMENT LLP   \n",
       "537326  T25LL1049B           ZHONG XIN TRAVEL LLP   \n",
       "537327  T25LL1066B                 ZDT DRIVES LLP   \n",
       "\n",
       "       BUSINESS_CONSTITUTION_DESCRIPTION           ENTITY_TYPE_DESCRIPTION  \\\n",
       "0                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "1                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "2                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "3                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "4                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "...                                  ...                               ...   \n",
       "537323                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537324                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537325                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537326                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537327                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "\n",
       "       ENTITY_STATUS_DESCRIPTION REGISTRATION_INCORPORATION_DATE  \\\n",
       "0                           LIVE                      07-02-1975   \n",
       "1                           LIVE                      28-10-1974   \n",
       "2                           LIVE                      02-11-1974   \n",
       "3                           LIVE                      12-11-1974   \n",
       "4                           LIVE                      30-10-1974   \n",
       "...                          ...                             ...   \n",
       "537323                      LIVE                      16-05-2025   \n",
       "537324                      LIVE                      01-08-2025   \n",
       "537325                      LIVE                      04-08-2025   \n",
       "537326                      LIVE                      08-09-2025   \n",
       "537327                      LIVE                      14-09-2025   \n",
       "\n",
       "        PRIMARY_SSIC_CODE                    STREET_NAME POSTAL_CODE  \\\n",
       "0                   46302              FISHERY PORT ROAD      619742   \n",
       "1                   46411                    SIMS AVENUE      387509   \n",
       "2                   32909  ANG MO KIO INDUSTRIAL PARK 2A      568049   \n",
       "3                   46411                  JELLICOE ROAD      208767   \n",
       "4                   47711            WOODLANDS STREET 12      738623   \n",
       "...                   ...                            ...         ...   \n",
       "537323              96021                  KELANTAN LANE      200031   \n",
       "537324              43301     YISHUN INDUSTRIAL STREET 1      768161   \n",
       "537325              70209                  SIN MING LANE      573969   \n",
       "537326              79102                  JALAN BAHAGIA      320034   \n",
       "537327              47533                  FERNVALE ROAD      792466   \n",
       "\n",
       "       PARENT_INDUSTRY                       INDUSTRY_TYPE  \\\n",
       "0               Others                     Wholesale Trade   \n",
       "1               Others                     Wholesale Trade   \n",
       "2               Others                       Manufacturing   \n",
       "3               Others                     Wholesale Trade   \n",
       "4               Retail                              Retail   \n",
       "...                ...                                 ...   \n",
       "537323        Services                            Services   \n",
       "537324          Others  Built Environment & Infrastructure   \n",
       "537325          Others        Finance, Legal & Real Estate   \n",
       "537326          Others                     Tourism, Agency   \n",
       "537327             NaN                                 NaN   \n",
       "\n",
       "                                          SUB_INDUSTRY  \\\n",
       "0                            Food, Beverages & Tobacco   \n",
       "1                                      Household Goods   \n",
       "2       Other Specialised Manufacturing & Distribution   \n",
       "3                                      Household Goods   \n",
       "4                                    Fashion & Apparel   \n",
       "...                                                ...   \n",
       "537323                       Hair Salons & Barbershops   \n",
       "537324                                    Construction   \n",
       "537325      Legal, Accounting & Consultancy Activities   \n",
       "537326                Travel Agencies & Tour Operators   \n",
       "537327                                             NaN   \n",
       "\n",
       "                                              DESCRIPTION  \n",
       "0       Wholesale Of Livestock, Meat, Poultry, Eggs An...  \n",
       "1                      Wholesale Of Textiles And Leathers  \n",
       "2                   Other Manufacturing Industries N.E.C.  \n",
       "3                      Wholesale Of Textiles And Leathers  \n",
       "4                      Retail Sale Of Clothing For Adults  \n",
       "...                                                   ...  \n",
       "537323                          Hairdressing Salons/Shops  \n",
       "537324                             Renovation Contractors  \n",
       "537325             Management Consultancy Services N.E.C.  \n",
       "537326  Travel Agencies And Tour Operators (Mainly Out...  \n",
       "537327                                                NaN  \n",
       "\n",
       "[537328 rows x 13 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acra_data_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9289e8b3",
   "metadata": {},
   "source": [
    "### FIlter Acra data with Master DB to get list of companies havent been researched  by MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c28478d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533824, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Ensure both UEN columns are strings for accurate matching\n",
    "acra_data_filtered['UEN'] = acra_data_filtered['UEN'].astype(str).str.strip().str.upper()\n",
    "master_db_df['UEN'] = master_db_df['UEN'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Filter out rows in acra_data_filtered whose UEN is already in master_db_df\n",
    "acra_data_filtered = acra_data_filtered[~acra_data_filtered['UEN'].isin(master_db_df['UEN'])]\n",
    "\n",
    "acra_data_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd24ab",
   "metadata": {},
   "source": [
    "### Filter by  Industry (Wholesale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa058f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ENTITY_NAME</th>\n",
       "      <th>BUSINESS_CONSTITUTION_DESCRIPTION</th>\n",
       "      <th>ENTITY_TYPE_DESCRIPTION</th>\n",
       "      <th>ENTITY_STATUS_DESCRIPTION</th>\n",
       "      <th>REGISTRATION_INCORPORATION_DATE</th>\n",
       "      <th>PRIMARY_SSIC_CODE</th>\n",
       "      <th>STREET_NAME</th>\n",
       "      <th>POSTAL_CODE</th>\n",
       "      <th>PARENT_INDUSTRY</th>\n",
       "      <th>INDUSTRY_TYPE</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00182000A</td>\n",
       "      <td>AIK SENG HENG</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>07-02-1975</td>\n",
       "      <td>46302</td>\n",
       "      <td>FISHERY PORT ROAD</td>\n",
       "      <td>619742</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Food, Beverages &amp; Tobacco</td>\n",
       "      <td>Wholesale Of Livestock, Meat, Poultry, Eggs An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00233500W</td>\n",
       "      <td>ASIA STORE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>28-10-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>SIMS AVENUE</td>\n",
       "      <td>387509</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Textiles And Leathers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00927000X</td>\n",
       "      <td>A WALIMOHAMED BROS</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>12-11-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>JELLICOE ROAD</td>\n",
       "      <td>208767</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Textiles And Leathers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>04129500E</td>\n",
       "      <td>AIK HOE &amp; CO</td>\n",
       "      <td>SOLE-PROPRIETOR</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>23-01-1975</td>\n",
       "      <td>46551</td>\n",
       "      <td>KELANTAN ROAD</td>\n",
       "      <td>200028</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Machinery, Equipment &amp; Supplies</td>\n",
       "      <td>Wholesale Of Marine Equipment And Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>04545400X</td>\n",
       "      <td>AIK HUAT AND COMPANY</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>17-01-1975</td>\n",
       "      <td>46441</td>\n",
       "      <td>KAKI BUKIT AVENUE 1</td>\n",
       "      <td>417943</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Sporting Goods And Equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537268</th>\n",
       "      <td>T17LP0162L</td>\n",
       "      <td>ZYA HOLDINGS LIMITED PARTNERSHIP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>21-10-2017</td>\n",
       "      <td>46100</td>\n",
       "      <td>NATHAN ROAD</td>\n",
       "      <td>248728</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Other Specialised Wholesale</td>\n",
       "      <td>Wholesale On A Fee Or Commission Basis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537298</th>\n",
       "      <td>T22LL0564C</td>\n",
       "      <td>ZEN ENGINEERING &amp; TRADING LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>31-05-2022</td>\n",
       "      <td>46543</td>\n",
       "      <td>TOH GUAN ROAD EAST</td>\n",
       "      <td>608586</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Machinery, Equipment &amp; Supplies</td>\n",
       "      <td>Wholesale Of Lifts, Escalators And Industrial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537302</th>\n",
       "      <td>T23LL0056G</td>\n",
       "      <td>ZECRYNE LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>13-01-2023</td>\n",
       "      <td>46301</td>\n",
       "      <td>BUKIT BATOK STREET 25</td>\n",
       "      <td>658881</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Food, Beverages &amp; Tobacco</td>\n",
       "      <td>Wholesale Of Fruits And Vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537313</th>\n",
       "      <td>T24LL0528K</td>\n",
       "      <td>ZOHMH LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>07-05-2024</td>\n",
       "      <td>46303</td>\n",
       "      <td>WOODLANDS AVENUE 4</td>\n",
       "      <td>730844</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Food, Beverages &amp; Tobacco</td>\n",
       "      <td>Wholesale Of A General Line Of Groceries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537318</th>\n",
       "      <td>T24LL1189H</td>\n",
       "      <td>Z CONNECT LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>30-10-2024</td>\n",
       "      <td>46436</td>\n",
       "      <td>GAMBAS CRESCENT</td>\n",
       "      <td>757087</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Audio And Video Equipment (Except...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38428 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               UEN                          ENTITY_NAME  \\\n",
       "0        00182000A                        AIK SENG HENG   \n",
       "1        00233500W                           ASIA STORE   \n",
       "3        00927000X                   A WALIMOHAMED BROS   \n",
       "12       04129500E                         AIK HOE & CO   \n",
       "14       04545400X                 AIK HUAT AND COMPANY   \n",
       "...            ...                                  ...   \n",
       "537268  T17LP0162L     ZYA HOLDINGS LIMITED PARTNERSHIP   \n",
       "537298  T22LL0564C        ZEN ENGINEERING & TRADING LLP   \n",
       "537302  T23LL0056G                          ZECRYNE LLP   \n",
       "537313  T24LL0528K  ZOHMH LIMITED LIABILITY PARTNERSHIP   \n",
       "537318  T24LL1189H                        Z CONNECT LLP   \n",
       "\n",
       "       BUSINESS_CONSTITUTION_DESCRIPTION           ENTITY_TYPE_DESCRIPTION  \\\n",
       "0                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "1                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "3                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "12                       SOLE-PROPRIETOR  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "14                           PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "...                                  ...                               ...   \n",
       "537268                              <NA>               LIMITED PARTNERSHIP   \n",
       "537298                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537302                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537313                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537318                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "\n",
       "       ENTITY_STATUS_DESCRIPTION REGISTRATION_INCORPORATION_DATE  \\\n",
       "0                           LIVE                      07-02-1975   \n",
       "1                           LIVE                      28-10-1974   \n",
       "3                           LIVE                      12-11-1974   \n",
       "12                          LIVE                      23-01-1975   \n",
       "14                          LIVE                      17-01-1975   \n",
       "...                          ...                             ...   \n",
       "537268                      LIVE                      21-10-2017   \n",
       "537298                      LIVE                      31-05-2022   \n",
       "537302                      LIVE                      13-01-2023   \n",
       "537313                      LIVE                      07-05-2024   \n",
       "537318                      LIVE                      30-10-2024   \n",
       "\n",
       "        PRIMARY_SSIC_CODE            STREET_NAME POSTAL_CODE PARENT_INDUSTRY  \\\n",
       "0                   46302      FISHERY PORT ROAD      619742          Others   \n",
       "1                   46411            SIMS AVENUE      387509          Others   \n",
       "3                   46411          JELLICOE ROAD      208767          Others   \n",
       "12                  46551          KELANTAN ROAD      200028          Others   \n",
       "14                  46441    KAKI BUKIT AVENUE 1      417943          Others   \n",
       "...                   ...                    ...         ...             ...   \n",
       "537268              46100            NATHAN ROAD      248728          Others   \n",
       "537298              46543     TOH GUAN ROAD EAST      608586          Others   \n",
       "537302              46301  BUKIT BATOK STREET 25      658881          Others   \n",
       "537313              46303     WOODLANDS AVENUE 4      730844          Others   \n",
       "537318              46436        GAMBAS CRESCENT      757087          Others   \n",
       "\n",
       "          INDUSTRY_TYPE                     SUB_INDUSTRY  \\\n",
       "0       Wholesale Trade        Food, Beverages & Tobacco   \n",
       "1       Wholesale Trade                  Household Goods   \n",
       "3       Wholesale Trade                  Household Goods   \n",
       "12      Wholesale Trade  Machinery, Equipment & Supplies   \n",
       "14      Wholesale Trade                  Household Goods   \n",
       "...                 ...                              ...   \n",
       "537268  Wholesale Trade      Other Specialised Wholesale   \n",
       "537298  Wholesale Trade  Machinery, Equipment & Supplies   \n",
       "537302  Wholesale Trade        Food, Beverages & Tobacco   \n",
       "537313  Wholesale Trade        Food, Beverages & Tobacco   \n",
       "537318  Wholesale Trade                  Household Goods   \n",
       "\n",
       "                                              DESCRIPTION  \n",
       "0       Wholesale Of Livestock, Meat, Poultry, Eggs An...  \n",
       "1                      Wholesale Of Textiles And Leathers  \n",
       "3                      Wholesale Of Textiles And Leathers  \n",
       "12          Wholesale Of Marine Equipment And Accessories  \n",
       "14              Wholesale Of Sporting Goods And Equipment  \n",
       "...                                                   ...  \n",
       "537268             Wholesale On A Fee Or Commission Basis  \n",
       "537298  Wholesale Of Lifts, Escalators And Industrial ...  \n",
       "537302                 Wholesale Of Fruits And Vegetables  \n",
       "537313           Wholesale Of A General Line Of Groceries  \n",
       "537318  Wholesale Of Audio And Video Equipment (Except...  \n",
       "\n",
       "[38428 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wholesale data\n",
    "ssic_codes = [\n",
    "    \"46\", \"461\", \"4610\", \"46100\", \"462\", \"4621\", \"46211\", \"46212\", \"46213\", \"46219\",\n",
    "    \"4622\", \"46221\", \"46222\", \"46223\", \"46224\", \"46225\", \"46229\", \"463\", \"4630\", \"46301\",\n",
    "    \"46302\", \"46303\", \"46304\", \"46305\", \"46306\", \"46307\", \"46308\", \"46309\", \"464\", \"4641\",\n",
    "    \"46411\", \"46412\", \"46413\", \"46414\", \"46415\", \"46416\", \"4642\", \"46421\", \"46422\", \"46423\",\n",
    "    \"46424\", \"46429\", \"4643\", \"46431\", \"46432\", \"46433\", \"46434\", \"46435\", \"46436\", \"46439\",\n",
    "    \"4644\", \"46441\", \"46442\", \"46443\", \"46444\", \"46445\", \"46449\", \"4645\", \"46451\", \"46452\",\n",
    "    \"46453\", \"46459\", \"4646\", \"46461\", \"46462\", \"4647\", \"46471\", \"46472\", \"46473\", \"46474\",\n",
    "    \"46479\", \"4649\", \"46491\", \"46492\", \"46499\", \"465\", \"4651\", \"46511\", \"46512\", \"46513\",\n",
    "    \"46514\", \"4652\", \"46521\", \"46522\", \"46523\", \"4653\", \"46530\", \"4654\", \"46541\", \"46542\",\n",
    "    \"46543\", \"46544\", \"46549\", \"4655\", \"46551\", \"46552\", \"46559\", \"4656\", \"46561\", \"46562\",\n",
    "    \"46563\", \"4659\", \"46591\", \"46592\", \"46593\", \"46594\", \"46595\", \"46599\", \"466\", \"4661\",\n",
    "    \"46610\", \"4662\", \"46620\", \"4663\", \"46631\", \"46632\", \"46633\", \"46634\", \"46635\", \"46639\",\n",
    "    \"4664\", \"46641\", \"46642\", \"46643\", \"46649\", \"4665\", \"46651\", \"46659\", \"4666\", \"46661\",\n",
    "    \"46662\", \"469\", \"4690\", \"46900\"\n",
    "]\n",
    "\n",
    "\n",
    "acra_data_filtered_wholesale = acra_data_filtered[\n",
    "    (\n",
    "        (acra_data_filtered[\"ENTITY_STATUS_DESCRIPTION\"].str.lower() == \"live\") |\n",
    "        (acra_data_filtered[\"ENTITY_STATUS_DESCRIPTION\"].str.lower() == \"live company\")\n",
    "    )\n",
    "    &\n",
    "    (acra_data_filtered[\"PRIMARY_SSIC_CODE\"].astype(str).isin(ssic_codes))\n",
    "]\n",
    "\n",
    "\n",
    "acra_data_filtered_wholesale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c23d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is UEN unique?: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(255, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recordowl_results = pd.read_excel(\"Fresh_Leads.xlsx\")\n",
    "# is_unique = recordowl_results['UEN'].is_unique\n",
    "# print(\"Is UEN unique?:\", is_unique)\n",
    "\n",
    "# recordowl_results.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6edf012",
   "metadata": {},
   "source": [
    "### Get RecordOwl Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Copy to avoid SettingWithCopyWarning ---\n",
    "acra_data_filtered_wholesale = acra_data_filtered_wholesale.copy()\n",
    "\n",
    "# --- Ensure the column is in datetime format ---\n",
    "acra_data_filtered_wholesale[\"REGISTRATION_INCORPORATION_DATE\"] = pd.to_datetime(\n",
    "    acra_data_filtered_wholesale[\"REGISTRATION_INCORPORATION_DATE\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# --- Filter for companies registered after 2015-01-01 ---\n",
    "filtered = acra_data_filtered_wholesale[\n",
    "    acra_data_filtered_wholesale[\"REGISTRATION_INCORPORATION_DATE\"] > \"2015-01-01\"\n",
    "].copy()\n",
    "\n",
    "# --- UPDATE HERE: Remove rows if UEN exists in recordowl_results.xlsx ---\n",
    "recordowl_results = pd.read_excel(\"Fresh_Leads.xlsx\")\n",
    "\n",
    "# Standardize UEN column names (if needed)\n",
    "recordowl_results.columns = recordowl_results.columns.str.upper()\n",
    "\n",
    "# Ensure both dataframes have a 'UEN' column\n",
    "if \"UEN\" in recordowl_results.columns and \"UEN\" in filtered.columns:\n",
    "    filtered = filtered[~filtered[\"UEN\"].isin(recordowl_results[\"UEN\"])]\n",
    "else:\n",
    "    raise ValueError(\"Column 'UEN' not found in one of the dataframes.\")\n",
    "\n",
    "# --- Sample 50 rows from the filtered data ---\n",
    "acra_data_filtered_wholesale_10 = filtered.sample(n=200, random_state=42).reset_index(drop=True)\n",
    "\n",
    "acra_data_filtered_wholesale_10.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e80581",
   "metadata": {},
   "outputs": [],
   "source": [
    "acra_data_filtered_wholesale_10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0877d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fresh_Leads = pd.read_excel(\"Fresh_Leads.xlsx\")\n",
    "\n",
    "result = Fresh_Leads[\"UEN\"].isin(acra_data_filtered_wholesale_10[\"UEN\"]).any()\n",
    "print(\"Yes\" if result else \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# acra_data_filtered_wholesale_10 = pd.DataFrame({\n",
    "#     \"UEN\": [\"201903934W\"]\n",
    "# })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3cd46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from apify_client import ApifyClient\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from requests.exceptions import HTTPError, ConnectionError\n",
    "from urllib3.exceptions import ProtocolError\n",
    "\n",
    "client = ApifyClient(\"apify_api_70MQolLF1jPd03YWnerLin0VMSa5WO3YziN4\")\n",
    "\n",
    "SOCIAL_MEDIA_DOMAINS = [\n",
    "    \"facebook.com\", \"linkedin.com\", \"instagram.com\", \"youtube.com\",\n",
    "    \"tiktok.com\", \"twitter.com\", \"x.com\", \"pinterest.com\"\n",
    "]\n",
    "\n",
    "def fetch_dataset_items_safe(dataset_client, max_retries=5, initial_wait=3):\n",
    "    \"\"\"Safely fetch dataset items with multiple retry strategies.\"\"\"\n",
    "    dataset_items = []\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Strategy 1: Try using iterate_items() (streaming)\n",
    "            try:\n",
    "                dataset_items = list(dataset_client.iterate_items())\n",
    "                if dataset_items:\n",
    "                    return dataset_items\n",
    "            except (HTTPError, ConnectionError, ProtocolError, Exception) as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = initial_wait * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"  ⚠️ Iteration method failed (attempt {attempt + 1}/{max_retries}), trying direct fetch in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  ⚠️ Iteration method failed after all retries, trying direct fetch...\")\n",
    "            \n",
    "            # Strategy 2: Try using list_items() (direct pagination)\n",
    "            try:\n",
    "                offset = 0\n",
    "                limit = 100\n",
    "                while True:\n",
    "                    page = dataset_client.list_items(offset=offset, limit=limit, clean=True)\n",
    "                    if not page.items:\n",
    "                        break\n",
    "                    dataset_items.extend(page.items)\n",
    "                    if len(page.items) < limit:\n",
    "                        break\n",
    "                    offset += limit\n",
    "                \n",
    "                if dataset_items:\n",
    "                    return dataset_items\n",
    "            except (HTTPError, ConnectionError, ProtocolError, Exception) as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = initial_wait * (2 ** attempt)\n",
    "                    print(f\"  ⚠️ Direct fetch failed (attempt {attempt + 1}/{max_retries}), retrying in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  ❌ All fetch methods failed: {e}\")\n",
    "                    return []\n",
    "                    \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = initial_wait * (2 ** attempt)\n",
    "                print(f\"  ⚠️ Unexpected error (attempt {attempt + 1}/{max_retries}), retrying in {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"  ❌ Failed after all retries: {e}\")\n",
    "                return []\n",
    "    \n",
    "    return dataset_items\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for idx, (i, row) in enumerate(acra_data_filtered_wholesale_10.iterrows(), 1):\n",
    "    uen = str(row[\"UEN\"]).strip()\n",
    "    print(f\"\\n🔎 Processing {uen} ({idx}/{len(acra_data_filtered_wholesale_10)})\")\n",
    "\n",
    "    # Build pageFunction with proper escaping\n",
    "    page_function = f\"\"\"\n",
    "    async function pageFunction(context) {{\n",
    "        const {{ page, log, request }} = context;\n",
    "        const uen = \"{uen}\";\n",
    "        log.info(\"Visiting RecordOwl for UEN: \" + uen);\n",
    "\n",
    "        try {{\n",
    "            await page.waitForSelector(\"input[placeholder='Search company name, industry, or address']\", {{ timeout: 30000 }});\n",
    "            const input = await page.$(\"input[placeholder='Search company name, industry, or address']\");\n",
    "            await input.click({{ clickCount: 3 }});\n",
    "            await input.type(uen, {{ delay: 100 }});\n",
    "\n",
    "            await Promise.all([\n",
    "                page.waitForNavigation({{ waitUntil: 'networkidle2', timeout: 60000 }}).catch(() => null),\n",
    "                page.click(\"button[type='submit']\")\n",
    "            ]);\n",
    "\n",
    "            // Wait for results with longer timeout\n",
    "            try {{\n",
    "                await page.waitForSelector(\"a[href*='/company/']\", {{ timeout: 45000 }});\n",
    "            }} catch (e) {{\n",
    "                log.info(\"No company links found, might be not found\");\n",
    "                return {{ status: 'not_found', uen }};\n",
    "            }}\n",
    "\n",
    "            const companyLink = await page.$$eval(\"a[href*='/company/']\", (links, uen) => {{\n",
    "                for (const a of links) {{\n",
    "                    const text = a.innerText || \"\";\n",
    "                    const href = a.href || \"\";\n",
    "                    if (text.includes(uen) || href.includes(uen.toLowerCase())) return a.href;\n",
    "                }}\n",
    "                return links.length > 0 ? links[0].href : null;\n",
    "            }}, uen);\n",
    "\n",
    "            if (!companyLink) return {{ status: 'not_found', uen }};\n",
    "\n",
    "            if (page.url() !== companyLink) {{\n",
    "                await page.goto(companyLink, {{ waitUntil: 'networkidle2', timeout: 60000 }});\n",
    "            }}\n",
    "\n",
    "            await new Promise(r => setTimeout(r, 3000)); // Increased wait time\n",
    "            const html_content = await page.content();\n",
    "            const title = await page.title();\n",
    "            const url = page.url();\n",
    "\n",
    "            return {{ status: 'success', uen, url, title, html_content }};\n",
    "        }} catch (err) {{\n",
    "            log.error(\"Error in pageFunction: \" + err.message);\n",
    "            return {{ status: 'error', uen, error: err.message }};\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    run_input = {\n",
    "        \"startUrls\": [{\"url\": \"https://recordowl.com/\"}],\n",
    "        \"useChrome\": True,\n",
    "        \"headless\": True,\n",
    "        \"stealth\": True,\n",
    "        \"pageFunction\": page_function,\n",
    "    }\n",
    "\n",
    "    run = None\n",
    "    try:\n",
    "        # Start the run (same as original working code)\n",
    "        print(f\"  📡 Starting Apify run for {uen}...\")\n",
    "        run = client.actor(\"apify/puppeteer-scraper\").call(run_input=run_input)\n",
    "        \n",
    "        # Wait for the run to finish (poll the status)\n",
    "        print(f\"  ⏳ Waiting for run to complete...\")\n",
    "        run_client = client.run(run[\"id\"])\n",
    "        run_client.wait_for_finish()\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Apify call failed for {uen}: {e}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": None,\n",
    "            \"Error\": f\"Apify call failed: {str(e)}\"\n",
    "        })\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "\n",
    "    if not run or \"defaultDatasetId\" not in run:\n",
    "        print(f\"  ⚠️ No valid dataset returned for {uen}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": None,\n",
    "            \"Error\": \"No dataset returned\"\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Wait for dataset to be ready\n",
    "    print(f\"  ⏳ Waiting for dataset to be ready...\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    scraped_html, record_owl_url = None, None\n",
    "    \n",
    "    # Fetch dataset items with improved error handling\n",
    "    dataset_items = fetch_dataset_items_safe(\n",
    "        client.dataset(run[\"defaultDatasetId\"]),\n",
    "        max_retries=5,\n",
    "        initial_wait=3\n",
    "    )\n",
    "    \n",
    "    # Process items\n",
    "    for item in dataset_items:\n",
    "        if item.get(\"status\") == \"success\":\n",
    "            scraped_html = item.get(\"html_content\", \"\")\n",
    "            record_owl_url = item.get(\"url\")\n",
    "            print(f\"  ✅ Successfully scraped {uen}\")\n",
    "        elif item.get(\"status\") == \"not_found\":\n",
    "            print(f\"  ⚠️ Company not found for UEN {uen}\")\n",
    "        elif item.get(\"status\") == \"error\":\n",
    "            print(f\"  ❌ Error for {uen}: {item.get('error')}\")\n",
    "\n",
    "    if not scraped_html:\n",
    "        print(f\"  ⚠️ No HTML content retrieved for {uen}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": record_owl_url or None,\n",
    "            \"Error\": \"No HTML content retrieved\"\n",
    "        })\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "\n",
    "    # Parse HTML\n",
    "    try:\n",
    "        soup = BeautifulSoup(scraped_html, \"html.parser\")\n",
    "        parent = soup.select_one(\"div.max-w-7xl.mx-auto.lg\\\\:py-6.sm\\\\:px-6.lg\\\\:px-8\")\n",
    "\n",
    "        emails, phones, website = [], [], None\n",
    "        facebook_links, linkedin_links, instagram_links, tiktok_links = [], [], [], []\n",
    "\n",
    "        if parent:\n",
    "            # Extract emails\n",
    "            for a in parent.select(\"a[href^=mailto]\"):\n",
    "                email = a.get(\"href\", \"\").replace(\"mailto:\", \"\").strip()\n",
    "                if email and email not in emails and \"@\" in email:\n",
    "                    emails.append(email)\n",
    "\n",
    "            # ========== COMPREHENSIVE PHONE EXTRACTION ==========\n",
    "            # This extracts Singapore phone numbers with ANY spacing/formatting:\n",
    "            # - \"65 63 19 2960\" (spaces between digits)\n",
    "            # - \"6563192960\" (no spaces)\n",
    "            # - \"+65-6319-2960\" (dashes)\n",
    "            # - \"65 6 3 1 9 2 9 6 0\" (space between every digit)\n",
    "            # - \"(65) 6319 2960\" (with parentheses)\n",
    "            # Method: Extract ALL digits first, then validate pattern\n",
    "            print(f\"  🔍 Searching for phone numbers...\")\n",
    "            \n",
    "            # Method 1: Look for tel: links (most reliable)\n",
    "            tel_links = parent.select(\"a[href^='tel:'], a[href^='tel']\")\n",
    "            if tel_links:\n",
    "                print(f\"  📱 Found {len(tel_links)} tel: links\")\n",
    "            \n",
    "            for a in tel_links:\n",
    "                tel_href = a.get(\"href\", \"\").replace(\"tel:\", \"\").strip()\n",
    "                tel_text = a.get_text(strip=True)\n",
    "                print(f\"  📞 Tel link - href: '{tel_href}', text: '{tel_text}'\")\n",
    "                \n",
    "                # Extract all digits from tel link\n",
    "                digits_only = re.sub(r\"\\D\", \"\", tel_href)\n",
    "                print(f\"  🔢 Tel digits: {digits_only}\")\n",
    "                \n",
    "                # Handle different digit lengths\n",
    "                if len(digits_only) == 10 and digits_only.startswith(\"65\") and digits_only[2] in \"689\":\n",
    "                    # 10 digits starting with 65 (e.g., \"6563192960\")\n",
    "                    formatted = \"+\" + digits_only\n",
    "                    if formatted not in phones:\n",
    "                        phones.append(formatted)\n",
    "                        print(f\"  ✅ Added from tel link (10 digits): {formatted}\")\n",
    "                elif len(digits_only) == 8 and digits_only[0] in \"689\":\n",
    "                    # 8 digits starting with 6/8/9 (e.g., \"63192960\")\n",
    "                    formatted = \"+65\" + digits_only\n",
    "                    if formatted not in phones:\n",
    "                        phones.append(formatted)\n",
    "                        print(f\"  ✅ Added from tel link (8 digits): {formatted}\")\n",
    "                elif len(digits_only) > 10:\n",
    "                    # More than 10 digits, try to find valid pattern\n",
    "                    print(f\"  🔍 Searching within {len(digits_only)} digits for valid pattern...\")\n",
    "                    found = False\n",
    "                    # Look for 65 followed by 6/8/9\n",
    "                    for i in range(len(digits_only) - 9):\n",
    "                        if digits_only[i:i+2] == \"65\" and digits_only[i+2] in \"689\":\n",
    "                            formatted = \"+\" + digits_only[i:i+10]\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from tel link (extracted): {formatted}\")\n",
    "                            found = True\n",
    "                            break\n",
    "                    if not found:\n",
    "                        # Try last 8 digits if they start with 6/8/9\n",
    "                        if digits_only[-8] in \"689\":\n",
    "                            formatted = \"+65\" + digits_only[-8:]\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from tel link (last 8 digits): {formatted}\")\n",
    "            \n",
    "            # Method 2: Look in dt/dd structure with broader keywords\n",
    "            dt_tags = parent.select(\"dt\")\n",
    "            if dt_tags:\n",
    "                print(f\"  📋 Found {len(dt_tags)} dt tags\")\n",
    "            \n",
    "            for dt in dt_tags:\n",
    "                dt_text = dt.get_text(strip=True).lower()\n",
    "                # Check for phone-related keywords but exclude non-phone fields\n",
    "                exclude_keywords = [\"officer\", \"charge\", \"employee\", \"shareholder\", \"director\", \"registration\"]\n",
    "                phone_keywords = [\"contact number\", \"phone\", \"tel\", \"mobile\", \"call\", \"contact no\"]\n",
    "                \n",
    "                is_phone_field = any(kw in dt_text for kw in phone_keywords)\n",
    "                is_excluded = any(excl in dt_text for excl in exclude_keywords)\n",
    "                \n",
    "                if is_phone_field and not is_excluded:\n",
    "                    dd = dt.find_next_sibling(\"dd\")\n",
    "                    if dd:\n",
    "                        number_text = dd.get_text(\" \", strip=True)\n",
    "                        print(f\"  📝 Field '{dt_text}': {number_text}\")\n",
    "                        \n",
    "                        # Extract all digits and check if it forms a valid phone number\n",
    "                        all_digits = re.sub(r\"\\D\", \"\", number_text)\n",
    "                        print(f\"  🔢 Extracted digits: {all_digits}\")\n",
    "                        \n",
    "                        # Check for Singapore phone patterns in the digits\n",
    "                        # Pattern 1: 10 digits starting with 65\n",
    "                        if len(all_digits) == 10 and all_digits.startswith(\"65\") and all_digits[2] in \"689\":\n",
    "                            formatted = \"+\" + all_digits\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from dt/dd (10 digits): {formatted}\")\n",
    "                        # Pattern 2: 8 digits starting with 6, 8, or 9\n",
    "                        elif len(all_digits) == 8 and all_digits[0] in \"689\":\n",
    "                            formatted = \"+65\" + all_digits\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from dt/dd (8 digits): {formatted}\")\n",
    "                        # Pattern 3: More than 10 digits, try to extract 10-digit number starting with 65\n",
    "                        elif len(all_digits) > 10:\n",
    "                            # Look for 65 followed by 6/8/9 in the digit string\n",
    "                            for i in range(len(all_digits) - 9):\n",
    "                                if all_digits[i:i+2] == \"65\" and all_digits[i+2] in \"689\":\n",
    "                                    potential_number = all_digits[i:i+10]\n",
    "                                    formatted = \"+\" + potential_number\n",
    "                                    if formatted not in phones:\n",
    "                                        phones.append(formatted)\n",
    "                                        print(f\"  ✅ Added from dt/dd (extracted): {formatted}\")\n",
    "                                    break\n",
    "            \n",
    "            # Method 3: Search entire parent for phone patterns if none found\n",
    "            if not phones:\n",
    "                print(f\"  🔎 No phones found yet, searching entire content...\")\n",
    "                full_text = parent.get_text()\n",
    "                \n",
    "                # Ultra-comprehensive patterns to catch ALL spacing variations\n",
    "                # These patterns allow unlimited spaces/dashes between digits\n",
    "                patterns = [\n",
    "                    # Pattern 1: +65 with any spacing (e.g., \"+65 6 3 1 9 2 9 6 0\", \"+65-6319-2960\")\n",
    "                    r\"\\+[\\s\\-]*65[\\s\\-]+[689][\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d\",\n",
    "                    # Pattern 2: (65) with any spacing\n",
    "                    r\"\\([\\s\\-]*65[\\s\\-]*\\)[\\s\\-]*[689][\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d\",\n",
    "                    # Pattern 3: 65 without + or () but with space/dash (e.g., \"65 6 3 1 9 2 9 6 0\", \"65-6319-2960\")\n",
    "                    r\"(?<!\\d)65[\\s\\-]+[689][\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d(?!\\d)\",\n",
    "                    # Pattern 4: Just 8 digits starting with 6/8/9 with any spacing\n",
    "                    r\"(?<!\\d)[689][\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d(?!\\d)\",\n",
    "                ]\n",
    "                \n",
    "                for pattern_idx, pattern in enumerate(patterns, 1):\n",
    "                    matches = re.findall(pattern, full_text)\n",
    "                    if matches:\n",
    "                        print(f\"  🔍 Pattern {pattern_idx} found {len(matches)} potential matches\")\n",
    "                    \n",
    "                    for match in matches:\n",
    "                        # Extract only digits\n",
    "                        digits = re.sub(r\"\\D\", \"\", match)\n",
    "                        print(f\"  🔢 Pattern {pattern_idx} match: '{match.strip()}' → digits: '{digits}'\")\n",
    "                        \n",
    "                        # Validate and format\n",
    "                        if len(digits) == 10 and digits.startswith(\"65\") and digits[2] in \"689\":\n",
    "                            formatted = \"+\" + digits\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from pattern {pattern_idx} (10 digits): {formatted}\")\n",
    "                        elif len(digits) == 8 and digits[0] in \"689\":\n",
    "                            formatted = \"+65\" + digits\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from pattern {pattern_idx} (8 digits): {formatted}\")\n",
    "                        elif len(digits) > 10:\n",
    "                            # Try to find a valid 10-digit number within\n",
    "                            for i in range(len(digits) - 9):\n",
    "                                if digits[i:i+2] == \"65\" and digits[i+2] in \"689\":\n",
    "                                    potential = digits[i:i+10]\n",
    "                                    formatted = \"+\" + potential\n",
    "                                    if formatted not in phones:\n",
    "                                        phones.append(formatted)\n",
    "                                        print(f\"  ✅ Added from pattern {pattern_idx} (extracted): {formatted}\")\n",
    "                                    break\n",
    "            \n",
    "            if phones:\n",
    "                print(f\"  ✅ Total phones found: {phones}\")\n",
    "            else:\n",
    "                print(f\"  ⚠️ WARNING: No phone numbers found for {uen}\")\n",
    "                print(f\"  📄 Showing first 500 chars of parent HTML for debugging:\")\n",
    "                print(parent.prettify()[:500] + \"...\")\n",
    "            # ========== END PHONE EXTRACTION ==========\n",
    "\n",
    "            # Extract website\n",
    "            valid_websites = []\n",
    "            for a in parent.select(\"a[href^=http]\"):\n",
    "                href = a.get(\"href\", \"\").strip()\n",
    "                href_lower = href.lower()\n",
    "                if not any(domain in href_lower for domain in SOCIAL_MEDIA_DOMAINS):\n",
    "                    if not any(skip in href_lower for skip in [\"recordowl\", \"apify.com\"]):\n",
    "                        if any(tld in href for tld in [\".com\", \".sg\", \".net\", \".org\", \".co\"]):\n",
    "                            valid_websites.append(href)\n",
    "            website = valid_websites[0] if valid_websites else None\n",
    "\n",
    "        # Extract social media links from entire page\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            href = a[\"href\"].strip().lower()\n",
    "            if \"facebook.com\" in href and href not in facebook_links:\n",
    "                facebook_links.append(href)\n",
    "            elif \"linkedin.com\" in href and href not in linkedin_links:\n",
    "                linkedin_links.append(href)\n",
    "            elif \"instagram.com\" in href and href not in instagram_links:\n",
    "                instagram_links.append(href)\n",
    "            elif \"tiktok.com\" in href and href not in tiktok_links:\n",
    "                tiktok_links.append(href)\n",
    "\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": emails if emails else None,\n",
    "            \"Phones\": phones if phones else None,\n",
    "            \"Website\": website,\n",
    "            \"Facebook\": list(set(facebook_links)) if facebook_links else None,\n",
    "            \"LinkedIn\": list(set(linkedin_links)) if linkedin_links else None,\n",
    "            \"Instagram\": list(set(instagram_links)) if instagram_links else None,\n",
    "            \"TikTok\": list(set(tiktok_links)) if tiktok_links else None,\n",
    "            \"RecordOwl_Link\": record_owl_url,\n",
    "        })\n",
    "        print(f\"  ✅ Processed {uen}: {len(emails) if emails else 0} emails, {len(phones) if phones else 0} phones\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error parsing HTML for {uen}: {e}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": record_owl_url or None,\n",
    "            \"Error\": f\"HTML parsing error: {str(e)}\"\n",
    "        })\n",
    "\n",
    "    # Dynamic sleep time to avoid rate limiting\n",
    "    sleep_time = 10 + (idx % 5)  # 10-14 seconds\n",
    "    print(f\"  💤 Sleeping for {sleep_time}s before next request...\")\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "Fresh_Leads = pd.DataFrame(all_results)\n",
    "print(\"\\n✅ Scraping complete!\")\n",
    "print(f\"\\n📊 Results summary:\")\n",
    "print(f\"   Total processed: {len(Fresh_Leads)}\")\n",
    "print(f\"   With emails: {Fresh_Leads['Emails'].notna().sum()}\")\n",
    "print(f\"   With phones: {Fresh_Leads['Phones'].notna().sum()}\")\n",
    "print(f\"   With websites: {Fresh_Leads['Website'].notna().sum()}\")\n",
    "Fresh_Leads.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce63aaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fresh_Leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f9de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fresh_Leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fresh_Leads_with_phones = Fresh_Leads[Fresh_Leads[\"Phones\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16729c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fresh_Leads_with_phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc6ed80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load both Excel files\n",
    "file_path_1 = \"Fresh_Leads.xlsx\"\n",
    "Fresh_Leads = pd.read_excel(file_path_1)\n",
    "\n",
    "# file_path_2 = \"recordowl_results_4.xlsx\"\n",
    "# recordowl_results_4 = pd.read_excel(file_path_2)\n",
    "\n",
    "# Append (combine) them\n",
    "combined_df = pd.concat([Fresh_Leads, Fresh_Leads_with_phones], ignore_index=True)\n",
    "\n",
    "# Optional: Save to a new Excel file\n",
    "combined_df.to_excel(\"Fresh_Leads_New.xlsx\", index=False)\n",
    "\n",
    "# Preview\n",
    "combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257fbbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_non_nan = combined_df['Phones'].notna().sum()\n",
    "print(count_non_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663bb4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8a8987c",
   "metadata": {},
   "source": [
    "### Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2534df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from apify_client import ApifyClient\n",
    "\n",
    "# client = ApifyClient(\"apify_api_0HQ8fc5fw5T1aosdacxKQNQYVBAEwi3tXaJc\")\n",
    "\n",
    "# uen = \"202333361N\"\n",
    "# scraped_html = None  # Will hold the HTML content\n",
    "\n",
    "# run_input = {\n",
    "#     \"startUrls\": [{\"url\": \"https://recordowl.com/\"}],\n",
    "#     \"useChrome\": True,\n",
    "#     \"headless\": True,\n",
    "#     \"stealth\": True,\n",
    "#     \"pageFunction\": f\"\"\"\n",
    "#     async function pageFunction(context) {{\n",
    "#         const {{ page, log, request }} = context;\n",
    "#         const uen = \"{uen}\";\n",
    "#         log.info(\"🌐 Visiting \" + request.url);\n",
    "\n",
    "#         try {{\n",
    "#             // Wait for search input and type UEN\n",
    "#             await page.waitForSelector(\"input[placeholder='Search company name, industry, or address']\", {{ timeout: 30000 }});\n",
    "#             const input = await page.$(\"input[placeholder='Search company name, industry, or address']\");\n",
    "#             await input.click({{ clickCount: 3 }});\n",
    "#             await input.type(uen, {{ delay: 80 }});\n",
    "#             log.info(\"✅ Typed UEN: \" + uen);\n",
    "\n",
    "#             // Click search button and wait for navigation or results\n",
    "#             const [response] = await Promise.all([\n",
    "#                 page.waitForNavigation({{ waitUntil: \"networkidle2\", timeout: 60000 }}).catch(() => null), // in case no full navigation\n",
    "#                 page.click(\"button[type='submit']\"),\n",
    "#             ]);\n",
    "#             log.info(\"🔍 Clicked search button\");\n",
    "\n",
    "#             // Wait for company link(s) to appear\n",
    "#             await page.waitForSelector(\"a[href*='/company/']\", {{ timeout: 40000 }});\n",
    "\n",
    "#             // Get the first matching company link\n",
    "#             const companyLink = await page.$$eval(\"a[href*='/company/']\", (links, uen) => {{\n",
    "#                 for (const a of links) {{\n",
    "#                     if (a.innerText.includes(uen) || a.href.includes(uen)) return a.href;\n",
    "#                 }}\n",
    "#                 return links.length > 0 ? links[0].href : null;\n",
    "#             }}, uen);\n",
    "\n",
    "#             if (!companyLink) return {{ status: \"not_found\", uen }};\n",
    "\n",
    "#             // Navigate to the company page (if different)\n",
    "#             if (page.url() !== companyLink) {{\n",
    "#                 await page.goto(companyLink, {{ waitUntil: \"networkidle2\", timeout: 60000 }});\n",
    "#             }}\n",
    "\n",
    "#             // Small wait to ensure content is fully loaded\n",
    "#             await new Promise(resolve => setTimeout(resolve, 2000));\n",
    "\n",
    "#             // Extract HTML\n",
    "#             const html_content = await page.content();\n",
    "#             const title = await page.title();\n",
    "#             const url = page.url();\n",
    "\n",
    "#             return {{ status: \"success\", uen, url, title, html_content }};\n",
    "#         }} catch (err) {{\n",
    "#             log.error(\"❌ Error: \" + err.message);\n",
    "#             return {{ status: \"error\", uen, error: err.message }};\n",
    "#         }}\n",
    "#     }}\n",
    "#     \"\"\"\n",
    "# }\n",
    "\n",
    "# # Run the scraper\n",
    "# run = client.actor(\"apify/puppeteer-scraper\").call(run_input=run_input)\n",
    "\n",
    "# # Store HTML into variable\n",
    "# for item in client.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
    "#     if item.get(\"status\") == \"success\":\n",
    "#         scraped_html = item.get(\"html_content\", \"\")\n",
    "#         record_owl_url = item.get(\"url\")  \n",
    "        \n",
    "#         print(\"✅ Scraped successfully\")\n",
    "#         print(\"Title:\", item.get(\"title\"))\n",
    "#         print(\"RecordOwl URL:\", record_owl_url)\n",
    "#     elif item.get(\"status\") == \"not_found\":\n",
    "#         print(f\"⚠️ Company not found for UEN {uen}\")\n",
    "#     else:\n",
    "#         print(\"❌ Error:\", item.get(\"error\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81796f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from bs4 import BeautifulSoup\n",
    "# import re\n",
    "\n",
    "# # scraped_html and record_owl_url come from the Apify scraping code above\n",
    "# # record_owl_url = item.get(\"url\") from the Apify result\n",
    "\n",
    "# # --- PARSE HTML ---\n",
    "# soup = BeautifulSoup(scraped_html, \"html.parser\")\n",
    "\n",
    "# # --- TARGET MAIN CONTAINER ---\n",
    "# parent = soup.select_one(\"div.max-w-7xl.mx-auto.lg\\\\:py-6.sm\\\\:px-6.lg\\\\:px-8\")\n",
    "\n",
    "# emails, phones, website = [], [], None\n",
    "# facebook_links, linkedin_links, instagram_links, tiktok_links = [], [], [], []\n",
    "# number_of_employees = None\n",
    "\n",
    "# # -------------------------------------------------------------\n",
    "# # Extract Contact Info (Emails, Phones, Website)\n",
    "# # -------------------------------------------------------------\n",
    "# if parent:\n",
    "#     for a in parent.select(\"a[href^=mailto]\"):\n",
    "#         email = a.get(\"href\").replace(\"mailto:\", \"\").strip()\n",
    "#         if email not in emails:\n",
    "#             emails.append(email)\n",
    "\n",
    "#     for dt in parent.select(\"dt\"):\n",
    "#         label = dt.get_text(strip=True).lower()\n",
    "#         if \"contact number\" in label:\n",
    "#             dd = dt.find_next_sibling(\"dd\")\n",
    "#             if dd:\n",
    "#                 number_text = dd.get_text(\" \", strip=True)\n",
    "#                 phone_pattern = r\"(?:\\+65\\s*|65)?(?:\\d\\s*){8,}\"\n",
    "#                 for match in re.findall(phone_pattern, number_text):\n",
    "#                     p_clean = re.sub(r\"\\D\", \"\", match)\n",
    "#                     if p_clean.startswith(\"65\") and not p_clean.startswith(\"+65\"):\n",
    "#                         p_clean = \"+\" + p_clean\n",
    "#                     elif not p_clean.startswith(\"+65\"):\n",
    "#                         p_clean = \"+65\" + p_clean\n",
    "#                     if p_clean not in phones:\n",
    "#                         phones.append(p_clean)\n",
    "\n",
    "#     for a in parent.select(\"a[href^=http]\"):\n",
    "#         href = a.get(\"href\").strip()\n",
    "#         if any(skip in href.lower() for skip in [\"recordowl\", \"apify.com\"]):\n",
    "#             continue\n",
    "#         if (\".com\" in href or \".sg\" in href) and not href.startswith((\"mailto:\", \"tel:\")):\n",
    "#             website = href\n",
    "#             break\n",
    "\n",
    "# # -------------------------------------------------------------\n",
    "# # Extract Social Media Links\n",
    "# # -------------------------------------------------------------\n",
    "# for a in soup.find_all(\"a\", href=True):\n",
    "#     href = a[\"href\"].strip().lower()\n",
    "#     if \"facebook.com\" in href:\n",
    "#         facebook_links.append(href)\n",
    "#     elif \"linkedin.com\" in href:\n",
    "#         linkedin_links.append(href)\n",
    "#     elif \"instagram.com\" in href:\n",
    "#         instagram_links.append(href)\n",
    "#     elif \"tiktok.com\" in href:\n",
    "#         tiktok_links.append(href)\n",
    "\n",
    "# facebook_links = list(set(facebook_links))\n",
    "# linkedin_links = list(set(linkedin_links))\n",
    "# instagram_links = list(set(instagram_links))\n",
    "# tiktok_links = list(set(tiktok_links))\n",
    "\n",
    "# # -------------------------------------------------------------\n",
    "# # Extract Number of Employees\n",
    "# # -------------------------------------------------------------\n",
    "# for li in soup.select(\"li\"):\n",
    "#     li_text = li.get_text(\" \", strip=True).lower()\n",
    "#     if \"number of employees\" in li_text:\n",
    "#         p_tags = li.find_all(\"p\")\n",
    "#         for i, p in enumerate(p_tags):\n",
    "#             if \"new value\" in p.get_text(strip=True).lower() and i + 1 < len(p_tags):\n",
    "#                 number_of_employees = p_tags[i + 1].get_text(strip=True)\n",
    "#                 break\n",
    "#         if number_of_employees:\n",
    "#             break\n",
    "\n",
    "# # -------------------------------------------------------------\n",
    "# # SAVE RESULTS TO DATAFRAME (use None for empty values)\n",
    "# # -------------------------------------------------------------\n",
    "# result_df = pd.DataFrame([{\n",
    "#     \"Emails\": emails if emails else None,\n",
    "#     \"Phones\": phones if phones else None,\n",
    "#     \"Website\": website if website else None,\n",
    "#     \"Facebook\": facebook_links if facebook_links else None,\n",
    "#     \"LinkedIn\": linkedin_links if linkedin_links else None,\n",
    "#     \"Instagram\": instagram_links if instagram_links else None,\n",
    "#     \"TikTok\": tiktok_links if tiktok_links else None,\n",
    "#     \"Number_of_Employees\": number_of_employees if number_of_employees else None,\n",
    "#     \"RecordOwl_Link\": record_owl_url if record_owl_url else None,\n",
    "# }])\n",
    "\n",
    "# display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccaea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import httpx\n",
    "# import asyncio\n",
    "\n",
    "# # =====================================================\n",
    "# # Validate Website (only if no phone number)\n",
    "# # =====================================================\n",
    "# async def check_url(url: str) -> bool:\n",
    "#     \"\"\"Return True if the URL is reachable (status < 400).\"\"\"\n",
    "#     if not url:\n",
    "#         return False\n",
    "#     try:\n",
    "#         async with httpx.AsyncClient(follow_redirects=True, timeout=5) as client:\n",
    "#             response = await client.head(url)\n",
    "#             return response.status_code < 400\n",
    "#     except Exception:\n",
    "#         return False\n",
    "\n",
    "\n",
    "# async def validate_if_needed(df):\n",
    "#     \"\"\"Validate websites only if phone number is missing.\"\"\"\n",
    "#     for i, row in df.iterrows():\n",
    "#         url = row.get(\"Website\")\n",
    "#         phone = row.get(\"Phones\")\n",
    "\n",
    "#         # Skip validation if phone exists\n",
    "#         if phone:\n",
    "#             df.at[i, \"Website_Valid\"] = None\n",
    "#             continue\n",
    "\n",
    "#         # Validate website if no phone\n",
    "#         if url:\n",
    "#             is_valid = await check_url(url)\n",
    "#             df.at[i, \"Website_Valid\"] = \"valid\" if is_valid else \"invalid\"\n",
    "#         else:\n",
    "#             df.at[i, \"Website_Valid\"] = \"invalid\"\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "# # =====================================================\n",
    "# # Run async validation safely inside Jupyter\n",
    "# # =====================================================\n",
    "# result_df = await validate_if_needed(result_df)\n",
    "\n",
    "# # =====================================================\n",
    "# # Final output\n",
    "# # =====================================================\n",
    "# display(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c268400",
   "metadata": {},
   "source": [
    "### If contact number is invalid, then webscrapped website to get contact number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e742795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "# import os\n",
    "# from apify_client import ApifyClient\n",
    "\n",
    "# # --- Initialize Apify client ---\n",
    "# APIFY_TOKEN = os.getenv(\"APIFY_TOKEN\", \"apify_api_0HQ8fc5fw5T1aosdacxKQNQYVBAEwi3tXaJc\")\n",
    "# client = ApifyClient(APIFY_TOKEN)\n",
    "\n",
    "# # --- Async wrapper so you can run in Jupyter ---\n",
    "# async def enrich_with_contact_info(df):\n",
    "#     \"\"\"Scrape contact info for rows where Website_Valid == 'valid' and Phones is empty.\"\"\"\n",
    "#     updated_df = df.copy()\n",
    "\n",
    "#     for i, row in df.iterrows():\n",
    "#         website = row.get(\"Website\")\n",
    "#         status = row.get(\"Website_Valid\")\n",
    "#         phone = row.get(\"Phones\")\n",
    "\n",
    "#         if not website or status != \"valid\" or phone:\n",
    "#             continue  # Skip invalid or already complete rows\n",
    "\n",
    "#         print(f\"🔍 Scraping contact page for: {website}\")\n",
    "\n",
    "#         # --- Apify scraping run input ---\n",
    "#         run_input = {\n",
    "#             \"startUrls\": [{\"url\": website}],\n",
    "#             \"pageFunction\": r\"\"\"\n",
    "#                 async function pageFunction(context) {\n",
    "#                     const $ = context.jQuery;\n",
    "#                     const isContact = context.request.userData?.isContact || false;\n",
    "\n",
    "#                     if (!isContact) {\n",
    "#                         let contactUrl = null;\n",
    "#                         $('a[href]').each((i, el) => {\n",
    "#                             const href = $(el).attr('href').toLowerCase();\n",
    "#                             if (href.includes('contact')) {\n",
    "#                                 contactUrl = href.startsWith('http') ? href : window.location.origin + href;\n",
    "#                                 return false;\n",
    "#                             }\n",
    "#                         });\n",
    "\n",
    "#                         if (contactUrl) {\n",
    "#                             await context.enqueueRequest({ url: contactUrl, userData: { isContact: true } });\n",
    "#                             context.log.info(`Enqueued contact page: ${contactUrl}`);\n",
    "#                         }\n",
    "#                         return null;\n",
    "#                     }\n",
    "\n",
    "#                     function isVisible(el) {\n",
    "#                         return el.offsetParent !== null;\n",
    "#                     }\n",
    "\n",
    "#                     let emails = $('a[href^=\"mailto\"]').filter((i, el) => isVisible(el))\n",
    "#                         .map((i, el) => $(el).attr('href').replace('mailto:', '').trim())\n",
    "#                         .get();\n",
    "\n",
    "#                     let phones = $('a[href^=\"tel\"]').filter((i, el) => isVisible(el))\n",
    "#                         .map((i, el) => $(el).attr('href').replace(/[^0-9]/g, ''))\n",
    "#                         .get();\n",
    "\n",
    "#                     emails = [...new Set(emails)];\n",
    "#                     phones = [...new Set(phones)];\n",
    "\n",
    "#                     return {\n",
    "#                         contactUrl: context.request.url,\n",
    "#                         emails: emails.length ? emails : [],\n",
    "#                         phones: phones.length ? phones : []\n",
    "#                     };\n",
    "#                 }\n",
    "#             \"\"\",\n",
    "#             \"injectJQuery\": True,\n",
    "#             \"useChrome\": True,\n",
    "#             \"headless\": True,\n",
    "#             \"proxyConfiguration\": {\"useApifyProxy\": True},\n",
    "#         }\n",
    "\n",
    "#         # --- Run the Apify scraper ---\n",
    "#         try:\n",
    "#             run = client.actor(\"moJRLRc85AitArpNN\").call(run_input=run_input)\n",
    "#             dataset = client.dataset(run[\"defaultDatasetId\"])\n",
    "#             results = list(dataset.iterate_items())\n",
    "#             contact_results = [r for r in results if r and (r.get(\"emails\") or r.get(\"phones\"))]\n",
    "\n",
    "#             if contact_results:\n",
    "#                 scraped = contact_results[0]\n",
    "#                 updated_df.at[i, \"Emails\"] = scraped.get(\"emails\", None)\n",
    "#                 updated_df.at[i, \"Phones\"] = scraped.get(\"phones\", None)\n",
    "#                 updated_df.at[i, \"Contact_Page\"] = scraped.get(\"contactUrl\", None)\n",
    "#                 print(f\"✅ Found: {scraped.get('phones', [])} / {scraped.get('emails', [])}\")\n",
    "#             else:\n",
    "#                 print(\"⚠️ No contact data found.\")\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"❌ Error scraping {website}: {e}\")\n",
    "\n",
    "#     return updated_df\n",
    "\n",
    "\n",
    "# # --- Run the scraper for valid websites ---\n",
    "# result_df = await enrich_with_contact_info(result_df)\n",
    "\n",
    "# # --- Display updated results ---\n",
    "# display(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9c9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
