{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "328e86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from apify_client import ApifyClient\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from requests.exceptions import HTTPError, ConnectionError\n",
    "from urllib3.exceptions import ProtocolError\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767bf86c",
   "metadata": {},
   "source": [
    "### Getting Master DB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa7f0eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ACRA_REGISTERED_NAME</th>\n",
       "      <th>BRAND_NAME</th>\n",
       "      <th>SSIC_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04799400B</td>\n",
       "      <td>AIK BEE TEXTILE CO</td>\n",
       "      <td>AIK BEE TEXTILE CO</td>\n",
       "      <td>46411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03376200K</td>\n",
       "      <td>SERANGOON GARDEN CLINIC AND DISPENSARY</td>\n",
       "      <td>GARDEN CLINIC</td>\n",
       "      <td>550263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06239600E</td>\n",
       "      <td>SALON DE BENZIMEN</td>\n",
       "      <td>SALON DE BENZIMEN</td>\n",
       "      <td>96021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06952000C</td>\n",
       "      <td>SU LAN LADIES FASHION</td>\n",
       "      <td>SU LAN LADIES FASHION</td>\n",
       "      <td>14103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10381600C</td>\n",
       "      <td>SIN HAI PRINTING SERVICE</td>\n",
       "      <td>SIN HAI PRINTING SERVICE</td>\n",
       "      <td>18113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7444</th>\n",
       "      <td>201734006N</td>\n",
       "      <td>MISTER MOBILE HOUGANG PTE. LTD.</td>\n",
       "      <td>MISTER MOBILE (HOUGANG)</td>\n",
       "      <td>95120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7445</th>\n",
       "      <td>202210879W</td>\n",
       "      <td>MISTER MOBILE CHINATOWN PTE. LTD.</td>\n",
       "      <td>MISTER MOBILE (CHINATOWN)</td>\n",
       "      <td>47411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7446</th>\n",
       "      <td>202205507G</td>\n",
       "      <td>MISTER MOBILE PTE. LTD.</td>\n",
       "      <td>MISTER MOBILE HQ</td>\n",
       "      <td>64202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7454</th>\n",
       "      <td>53473046M</td>\n",
       "      <td>BLOONIES</td>\n",
       "      <td>BLOONIES</td>\n",
       "      <td>47742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7455</th>\n",
       "      <td>53478373B</td>\n",
       "      <td>BLOOMSNBALLOONS</td>\n",
       "      <td>BLOOMS AND BALLOONS</td>\n",
       "      <td>47742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6734 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             UEN                    ACRA_REGISTERED_NAME  \\\n",
       "0      04799400B                      AIK BEE TEXTILE CO   \n",
       "1      03376200K  SERANGOON GARDEN CLINIC AND DISPENSARY   \n",
       "2      06239600E                       SALON DE BENZIMEN   \n",
       "3      06952000C                   SU LAN LADIES FASHION   \n",
       "4      10381600C                SIN HAI PRINTING SERVICE   \n",
       "...          ...                                     ...   \n",
       "7444  201734006N         MISTER MOBILE HOUGANG PTE. LTD.   \n",
       "7445  202210879W       MISTER MOBILE CHINATOWN PTE. LTD.   \n",
       "7446  202205507G                 MISTER MOBILE PTE. LTD.   \n",
       "7454   53473046M                                BLOONIES   \n",
       "7455   53478373B                         BLOOMSNBALLOONS   \n",
       "\n",
       "                     BRAND_NAME  SSIC_CODE  \n",
       "0            AIK BEE TEXTILE CO      46411  \n",
       "1                 GARDEN CLINIC     550263  \n",
       "2             SALON DE BENZIMEN      96021  \n",
       "3         SU LAN LADIES FASHION      14103  \n",
       "4      SIN HAI PRINTING SERVICE      18113  \n",
       "...                         ...        ...  \n",
       "7444    MISTER MOBILE (HOUGANG)      95120  \n",
       "7445  MISTER MOBILE (CHINATOWN)      47411  \n",
       "7446           MISTER MOBILE HQ      64202  \n",
       "7454                   BLOONIES      47742  \n",
       "7455        BLOOMS AND BALLOONS      47742  \n",
       "\n",
       "[6734 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- CONFIG ---\n",
    "file_path = \"./Master DB/Master_DB_oct22.xlsx\"\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def clean_uen(u: str) -> str | None:\n",
    "    if pd.isna(u):\n",
    "        return None\n",
    "    return re.sub(r\"[^A-Z0-9]\", \"\", str(u).upper().strip())\n",
    "\n",
    "def clean_text(text: str) -> str | None:\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    text = str(text).strip().upper()\n",
    "    return None if text == \"NAN\" else text\n",
    "\n",
    "def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert all column names to uppercase, replace non-alphanumeric with single underscore, remove trailing underscores.\"\"\"\n",
    "    new_cols = []\n",
    "    for col in df.columns:\n",
    "        col_std = re.sub(r\"[^A-Z0-9]\", \"_\", col.upper().strip())\n",
    "        col_std = re.sub(r\"_+\", \"_\", col_std)  # Replace multiple underscores with single\n",
    "        col_std = col_std.strip(\"_\")  # Remove leading/trailing underscores\n",
    "        new_cols.append(col_std)\n",
    "    df.columns = new_cols\n",
    "    return df\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "master_db_df = pd.read_excel(file_path)\n",
    "\n",
    "# --- SELECT RELEVANT COLUMNS ---\n",
    "columns_to_keep = [\n",
    "    \"Company Registration Number (UEN)\",\n",
    "    \"ACRA REGISTERED NAME\",\n",
    "    \"Brand/Deal Name/Business Name\",\n",
    "    \"Primary SSIC Code\",\n",
    "    \"PIC NAME 1 Contact Number\",\n",
    "    \"PIC 1 email address\",\n",
    "    \"Website URL\",\n",
    "    \"Parent Industry Type\",\n",
    "    \"Sub Industry\"\n",
    "]\n",
    "master_db_df = master_db_df[columns_to_keep].copy()\n",
    "\n",
    "# --- STANDARDIZE COLUMN NAMES ---\n",
    "master_db_df = standardize_columns(master_db_df)\n",
    "\n",
    "# --- CLEANING & RENAME SPECIFIC COLUMNS ---\n",
    "# Dynamically find the UEN column (first column containing 'UEN')\n",
    "uen_col = [c for c in master_db_df.columns if \"UEN\" in c][0]\n",
    "master_db_df[\"UEN\"] = master_db_df[uen_col].apply(clean_uen)\n",
    "master_db_df = master_db_df.drop(columns=[uen_col])\n",
    "\n",
    "# Rename other columns consistently\n",
    "rename_map = {\n",
    "    \"BRAND_DEAL_NAME_BUSINESS_NAME\": \"BRAND_NAME\",\n",
    "    \"PRIMARY_SSIC_CODE\": \"SSIC_CODE\",\n",
    "    \"ACRA_REGISTERED_NAME\": \"ACRA_REGISTERED_NAME\"\n",
    "}\n",
    "master_db_df = master_db_df.rename(columns={k: v for k, v in rename_map.items() if k in master_db_df.columns})\n",
    "\n",
    "# Clean text columns\n",
    "for col in [\"ACRA_REGISTERED_NAME\", \"BRAND_NAME\"]:\n",
    "    if col in master_db_df.columns:\n",
    "        master_db_df[col] = master_db_df[col].apply(clean_text)\n",
    "\n",
    "# Convert SSIC_CODE to integer if exists\n",
    "if \"SSIC_CODE\" in master_db_df.columns:\n",
    "    master_db_df[\"SSIC_CODE\"] = master_db_df[\"SSIC_CODE\"].astype(\"Int64\")\n",
    "\n",
    "# Keep only required columns if they exist\n",
    "required_cols = [\"UEN\", \"ACRA_REGISTERED_NAME\", \"BRAND_NAME\", \"SSIC_CODE\"]\n",
    "master_db_df = master_db_df[[c for c in required_cols if c in master_db_df.columns]]\n",
    "\n",
    "# Filter out rows with missing or empty UEN\n",
    "master_db_df = master_db_df[master_db_df[\"UEN\"].notna() & (master_db_df[\"UEN\"].str.strip() != \"\")]\n",
    "\n",
    "master_db_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e98cff",
   "metadata": {},
   "source": [
    "### Getting ACRA Data (Filter by Live, Live Company only & non relevant ssic code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e678fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# Folder containing your CSVs\n",
    "# -------------------------------------------------------------\n",
    "folder_path = \"Acra_Data\"\n",
    "\n",
    "# Get all CSV file paths inside the folder\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "# Read and combine all CSVs\n",
    "# Using low_memory=False to avoid DtypeWarning for mixed types\n",
    "df = pd.concat((pd.read_csv(f, low_memory=False) for f in csv_files), ignore_index=True)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Convert all column names to uppercase\n",
    "# -------------------------------------------------------------\n",
    "df.columns = df.columns.str.upper()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Select relevant columns (now in uppercase)\n",
    "# -------------------------------------------------------------\n",
    "acra_data = df[[\n",
    "    \"UEN\",\n",
    "    \"ENTITY_NAME\",\n",
    "    \"BUSINESS_CONSTITUTION_DESCRIPTION\",\n",
    "    \"ENTITY_TYPE_DESCRIPTION\",\n",
    "    \"ENTITY_STATUS_DESCRIPTION\",\n",
    "    \"REGISTRATION_INCORPORATION_DATE\",\n",
    "    \"PRIMARY_SSIC_CODE\",\n",
    "    \"STREET_NAME\",\n",
    "    \"POSTAL_CODE\"\n",
    "]].copy()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Convert to proper data types\n",
    "# -------------------------------------------------------------\n",
    "acra_data['UEN'] = acra_data['UEN'].astype('string')\n",
    "acra_data['ENTITY_NAME'] = acra_data['ENTITY_NAME'].astype('string')\n",
    "acra_data['BUSINESS_CONSTITUTION_DESCRIPTION'] = acra_data['BUSINESS_CONSTITUTION_DESCRIPTION'].astype('string')\n",
    "acra_data['ENTITY_TYPE_DESCRIPTION'] = acra_data['ENTITY_TYPE_DESCRIPTION'].astype('string')\n",
    "acra_data['ENTITY_STATUS_DESCRIPTION'] = acra_data['ENTITY_STATUS_DESCRIPTION'].astype('string')\n",
    "acra_data['REGISTRATION_INCORPORATION_DATE'] = pd.to_datetime(acra_data['REGISTRATION_INCORPORATION_DATE'], errors='coerce')\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Clean string columns — trim, remove extra spaces, uppercase\n",
    "# -------------------------------------------------------------\n",
    "for col in [\n",
    "    'UEN',\n",
    "    'ENTITY_NAME',\n",
    "    'BUSINESS_CONSTITUTION_DESCRIPTION',\n",
    "    'ENTITY_TYPE_DESCRIPTION',\n",
    "    'ENTITY_STATUS_DESCRIPTION',\n",
    "    'STREET_NAME',\n",
    "    'POSTAL_CODE'\n",
    "]:\n",
    "    acra_data[col] = (\n",
    "        acra_data[col]\n",
    "        .fillna('')\n",
    "        .str.strip()\n",
    "        .str.replace(r'\\s+', ' ', regex=True)\n",
    "        .str.upper()\n",
    "    )\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Replace placeholders with NaN for standardization\n",
    "# -------------------------------------------------------------\n",
    "acra_data.replace(['NA', 'N/A', '-', ''], np.nan, inplace=True)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Convert registration date to dd-mm-yyyy string (optional)\n",
    "# -------------------------------------------------------------\n",
    "acra_data['REGISTRATION_INCORPORATION_DATE'] = acra_data['REGISTRATION_INCORPORATION_DATE'].dt.strftime('%d-%m-%Y')\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Filter only live entities (LIVE COMPANY or LIVE)\n",
    "# -------------------------------------------------------------\n",
    "acra_data = acra_data[\n",
    "    acra_data['ENTITY_STATUS_DESCRIPTION'].isin(['LIVE COMPANY', 'LIVE'])\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Exclude specific PRIMARY_SSIC_CODE values (supposedly the data would be 600k plus but when we exclude this would lessen)\n",
    "# -------------------------------------------------------------\n",
    "exclude_codes = [\n",
    "    46900, 47719, 47749, 47539, 47536, 56123,\n",
    "    10711, 10712, 10719, 10732, 10733, 93209\n",
    "]\n",
    "\n",
    "acra_data = acra_data[~acra_data['PRIMARY_SSIC_CODE'].isin(exclude_codes)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37b264bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ENTITY_NAME</th>\n",
       "      <th>BUSINESS_CONSTITUTION_DESCRIPTION</th>\n",
       "      <th>ENTITY_TYPE_DESCRIPTION</th>\n",
       "      <th>ENTITY_STATUS_DESCRIPTION</th>\n",
       "      <th>REGISTRATION_INCORPORATION_DATE</th>\n",
       "      <th>PRIMARY_SSIC_CODE</th>\n",
       "      <th>STREET_NAME</th>\n",
       "      <th>POSTAL_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00182000A</td>\n",
       "      <td>AIK SENG HENG</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>07-02-1975</td>\n",
       "      <td>46302</td>\n",
       "      <td>FISHERY PORT ROAD</td>\n",
       "      <td>619742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00233500W</td>\n",
       "      <td>ASIA STORE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>28-10-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>SIMS AVENUE</td>\n",
       "      <td>387509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00733000J</td>\n",
       "      <td>AIK CHE HIONG</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>02-11-1974</td>\n",
       "      <td>32909</td>\n",
       "      <td>ANG MO KIO INDUSTRIAL PARK 2A</td>\n",
       "      <td>568049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00927000X</td>\n",
       "      <td>A WALIMOHAMED BROS</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>12-11-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>JELLICOE ROAD</td>\n",
       "      <td>208767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01173000E</td>\n",
       "      <td>ANG TECK MOH DEPARTMENT STORE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>30-10-1974</td>\n",
       "      <td>47711</td>\n",
       "      <td>WOODLANDS STREET 12</td>\n",
       "      <td>738623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537323</th>\n",
       "      <td>T25LL0518K</td>\n",
       "      <td>ZEUS BARBERS LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>16-05-2025</td>\n",
       "      <td>96021</td>\n",
       "      <td>KELANTAN LANE</td>\n",
       "      <td>200031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537324</th>\n",
       "      <td>T25LL0858C</td>\n",
       "      <td>ZENSE SPACE LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>01-08-2025</td>\n",
       "      <td>43301</td>\n",
       "      <td>YISHUN INDUSTRIAL STREET 1</td>\n",
       "      <td>768161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537325</th>\n",
       "      <td>T25LL0870A</td>\n",
       "      <td>ZIQZEQ PROCUREMENT LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>04-08-2025</td>\n",
       "      <td>70209</td>\n",
       "      <td>SIN MING LANE</td>\n",
       "      <td>573969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537326</th>\n",
       "      <td>T25LL1049B</td>\n",
       "      <td>ZHONG XIN TRAVEL LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>08-09-2025</td>\n",
       "      <td>79102</td>\n",
       "      <td>JALAN BAHAGIA</td>\n",
       "      <td>320034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537327</th>\n",
       "      <td>T25LL1066B</td>\n",
       "      <td>ZDT DRIVES LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>14-09-2025</td>\n",
       "      <td>47533</td>\n",
       "      <td>FERNVALE ROAD</td>\n",
       "      <td>792466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537328 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               UEN                    ENTITY_NAME  \\\n",
       "0        00182000A                  AIK SENG HENG   \n",
       "1        00233500W                     ASIA STORE   \n",
       "2        00733000J                  AIK CHE HIONG   \n",
       "3        00927000X             A WALIMOHAMED BROS   \n",
       "4        01173000E  ANG TECK MOH DEPARTMENT STORE   \n",
       "...            ...                            ...   \n",
       "537323  T25LL0518K               ZEUS BARBERS LLP   \n",
       "537324  T25LL0858C                ZENSE SPACE LLP   \n",
       "537325  T25LL0870A         ZIQZEQ PROCUREMENT LLP   \n",
       "537326  T25LL1049B           ZHONG XIN TRAVEL LLP   \n",
       "537327  T25LL1066B                 ZDT DRIVES LLP   \n",
       "\n",
       "       BUSINESS_CONSTITUTION_DESCRIPTION           ENTITY_TYPE_DESCRIPTION  \\\n",
       "0                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "1                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "2                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "3                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "4                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "...                                  ...                               ...   \n",
       "537323                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537324                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537325                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537326                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537327                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "\n",
       "       ENTITY_STATUS_DESCRIPTION REGISTRATION_INCORPORATION_DATE  \\\n",
       "0                           LIVE                      07-02-1975   \n",
       "1                           LIVE                      28-10-1974   \n",
       "2                           LIVE                      02-11-1974   \n",
       "3                           LIVE                      12-11-1974   \n",
       "4                           LIVE                      30-10-1974   \n",
       "...                          ...                             ...   \n",
       "537323                      LIVE                      16-05-2025   \n",
       "537324                      LIVE                      01-08-2025   \n",
       "537325                      LIVE                      04-08-2025   \n",
       "537326                      LIVE                      08-09-2025   \n",
       "537327                      LIVE                      14-09-2025   \n",
       "\n",
       "        PRIMARY_SSIC_CODE                    STREET_NAME POSTAL_CODE  \n",
       "0                   46302              FISHERY PORT ROAD      619742  \n",
       "1                   46411                    SIMS AVENUE      387509  \n",
       "2                   32909  ANG MO KIO INDUSTRIAL PARK 2A      568049  \n",
       "3                   46411                  JELLICOE ROAD      208767  \n",
       "4                   47711            WOODLANDS STREET 12      738623  \n",
       "...                   ...                            ...         ...  \n",
       "537323              96021                  KELANTAN LANE      200031  \n",
       "537324              43301     YISHUN INDUSTRIAL STREET 1      768161  \n",
       "537325              70209                  SIN MING LANE      573969  \n",
       "537326              79102                  JALAN BAHAGIA      320034  \n",
       "537327              47533                  FERNVALE ROAD      792466  \n",
       "\n",
       "[537328 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acra_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec969fc",
   "metadata": {},
   "source": [
    "### Getting SSIC Industry code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32f4bc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARENT_INDUSTRY</th>\n",
       "      <th>INDUSTRY_TYPE</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>SSIC_CODES</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47711</td>\n",
       "      <td>Retail Sale Of Clothing For Adults</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47712</td>\n",
       "      <td>Retail Sale Of Children And Infants' Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47715</td>\n",
       "      <td>Retail Sale Of Sewing And Clothing Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47719</td>\n",
       "      <td>Retail Sale Of Clothing, Footwear And Leather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>47510</td>\n",
       "      <td>Retail Sale Of Textiles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PARENT_INDUSTRY INDUSTRY_TYPE       SUB_INDUSTRY  SSIC_CODES  \\\n",
       "0          Retail        Retail  Fashion & Apparel       47711   \n",
       "1          Retail        Retail  Fashion & Apparel       47712   \n",
       "2          Retail        Retail  Fashion & Apparel       47715   \n",
       "3          Retail        Retail  Fashion & Apparel       47719   \n",
       "4          Retail        Retail  Fashion & Apparel       47510   \n",
       "\n",
       "                                         DESCRIPTION  \n",
       "0                 Retail Sale Of Clothing For Adults  \n",
       "1      Retail Sale Of Children And Infants' Clothing  \n",
       "2     Retail Sale Of Sewing And Clothing Accessories  \n",
       "3  Retail Sale Of Clothing, Footwear And Leather ...  \n",
       "4                            Retail Sale Of Textiles  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "file_path = \"./SSIC_Code/mapped_ssic_code.xlsx\"\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "mapped_ssic_code = pd.read_excel(file_path)\n",
    "\n",
    "# --- STANDARDIZE COLUMN NAMES ---\n",
    "# Uppercase, strip spaces, replace spaces with underscores\n",
    "mapped_ssic_code.columns = (\n",
    "    mapped_ssic_code.columns\n",
    "    .str.strip()\n",
    "    .str.upper()\n",
    "    .str.replace(\" \", \"_\")\n",
    ")\n",
    "\n",
    "# --- KEEP ONLY DESIRED COLUMNS ---\n",
    "columns_to_keep = [\"PARENT_INDUSTRY\", \"INDUSTRY_TYPE\", \"SUB_INDUSTRY\", \"SSIC_CODES\", \"DESCRIPTION\"]\n",
    "mapped_ssic_code = mapped_ssic_code[columns_to_keep].copy()\n",
    "\n",
    "# --- CLEAN SSIC_CODES COLUMN ---\n",
    "mapped_ssic_code[\"SSIC_CODES\"] = (\n",
    "    pd.to_numeric(mapped_ssic_code[\"SSIC_CODES\"], errors=\"coerce\")  # safely convert to numeric\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# --- CLEAN TEXT COLUMNS ---\n",
    "text_cols = [\"PARENT_INDUSTRY\", \"INDUSTRY_TYPE\", \"SUB_INDUSTRY\", \"DESCRIPTION\"]\n",
    "mapped_ssic_code[text_cols] = mapped_ssic_code[text_cols].apply(\n",
    "    lambda col: col.astype(str).str.strip().str.title()\n",
    ")\n",
    "\n",
    "# --- REMOVE DUPLICATES & RESET INDEX ---\n",
    "mapped_ssic_code = mapped_ssic_code.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "mapped_ssic_code.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac763a73",
   "metadata": {},
   "source": [
    "### Merge ACRA data with SSIC code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e62740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert PRIMARY_SSIC_CODE to int\n",
    "acra_data[\"PRIMARY_SSIC_CODE\"] = (\n",
    "    pd.to_numeric(acra_data[\"PRIMARY_SSIC_CODE\"], errors=\"coerce\")\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "# Merge based on SSIC code\n",
    "acra_data_filtered = acra_data.merge(\n",
    "    mapped_ssic_code,\n",
    "    how=\"left\",\n",
    "    left_on=\"PRIMARY_SSIC_CODE\",\n",
    "    right_on=\"SSIC_CODES\"\n",
    ")\n",
    "\n",
    "# Optional: drop the duplicate 'SSIC CODES' column (keep only PRIMARY_SSIC_CODE)\n",
    "acra_data_filtered = acra_data_filtered.drop(columns=[\"SSIC_CODES\"], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ede8f881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ENTITY_NAME</th>\n",
       "      <th>BUSINESS_CONSTITUTION_DESCRIPTION</th>\n",
       "      <th>ENTITY_TYPE_DESCRIPTION</th>\n",
       "      <th>ENTITY_STATUS_DESCRIPTION</th>\n",
       "      <th>REGISTRATION_INCORPORATION_DATE</th>\n",
       "      <th>PRIMARY_SSIC_CODE</th>\n",
       "      <th>STREET_NAME</th>\n",
       "      <th>POSTAL_CODE</th>\n",
       "      <th>PARENT_INDUSTRY</th>\n",
       "      <th>INDUSTRY_TYPE</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00182000A</td>\n",
       "      <td>AIK SENG HENG</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>07-02-1975</td>\n",
       "      <td>46302</td>\n",
       "      <td>FISHERY PORT ROAD</td>\n",
       "      <td>619742</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Food, Beverages &amp; Tobacco</td>\n",
       "      <td>Wholesale Of Livestock, Meat, Poultry, Eggs An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00233500W</td>\n",
       "      <td>ASIA STORE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>28-10-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>SIMS AVENUE</td>\n",
       "      <td>387509</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Textiles And Leathers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00733000J</td>\n",
       "      <td>AIK CHE HIONG</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>02-11-1974</td>\n",
       "      <td>32909</td>\n",
       "      <td>ANG MO KIO INDUSTRIAL PARK 2A</td>\n",
       "      <td>568049</td>\n",
       "      <td>Others</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Other Specialised Manufacturing &amp; Distribution</td>\n",
       "      <td>Other Manufacturing Industries N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00927000X</td>\n",
       "      <td>A WALIMOHAMED BROS</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>12-11-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>JELLICOE ROAD</td>\n",
       "      <td>208767</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Textiles And Leathers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01173000E</td>\n",
       "      <td>ANG TECK MOH DEPARTMENT STORE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>30-10-1974</td>\n",
       "      <td>47711</td>\n",
       "      <td>WOODLANDS STREET 12</td>\n",
       "      <td>738623</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Fashion &amp; Apparel</td>\n",
       "      <td>Retail Sale Of Clothing For Adults</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537323</th>\n",
       "      <td>T25LL0518K</td>\n",
       "      <td>ZEUS BARBERS LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>16-05-2025</td>\n",
       "      <td>96021</td>\n",
       "      <td>KELANTAN LANE</td>\n",
       "      <td>200031</td>\n",
       "      <td>Services</td>\n",
       "      <td>Services</td>\n",
       "      <td>Hair Salons &amp; Barbershops</td>\n",
       "      <td>Hairdressing Salons/Shops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537324</th>\n",
       "      <td>T25LL0858C</td>\n",
       "      <td>ZENSE SPACE LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>01-08-2025</td>\n",
       "      <td>43301</td>\n",
       "      <td>YISHUN INDUSTRIAL STREET 1</td>\n",
       "      <td>768161</td>\n",
       "      <td>Others</td>\n",
       "      <td>Built Environment &amp; Infrastructure</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Renovation Contractors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537325</th>\n",
       "      <td>T25LL0870A</td>\n",
       "      <td>ZIQZEQ PROCUREMENT LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>04-08-2025</td>\n",
       "      <td>70209</td>\n",
       "      <td>SIN MING LANE</td>\n",
       "      <td>573969</td>\n",
       "      <td>Others</td>\n",
       "      <td>Finance, Legal &amp; Real Estate</td>\n",
       "      <td>Legal, Accounting &amp; Consultancy Activities</td>\n",
       "      <td>Management Consultancy Services N.E.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537326</th>\n",
       "      <td>T25LL1049B</td>\n",
       "      <td>ZHONG XIN TRAVEL LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>08-09-2025</td>\n",
       "      <td>79102</td>\n",
       "      <td>JALAN BAHAGIA</td>\n",
       "      <td>320034</td>\n",
       "      <td>Others</td>\n",
       "      <td>Tourism, Agency</td>\n",
       "      <td>Travel Agencies &amp; Tour Operators</td>\n",
       "      <td>Travel Agencies And Tour Operators (Mainly Out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537327</th>\n",
       "      <td>T25LL1066B</td>\n",
       "      <td>ZDT DRIVES LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>14-09-2025</td>\n",
       "      <td>47533</td>\n",
       "      <td>FERNVALE ROAD</td>\n",
       "      <td>792466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537328 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               UEN                    ENTITY_NAME  \\\n",
       "0        00182000A                  AIK SENG HENG   \n",
       "1        00233500W                     ASIA STORE   \n",
       "2        00733000J                  AIK CHE HIONG   \n",
       "3        00927000X             A WALIMOHAMED BROS   \n",
       "4        01173000E  ANG TECK MOH DEPARTMENT STORE   \n",
       "...            ...                            ...   \n",
       "537323  T25LL0518K               ZEUS BARBERS LLP   \n",
       "537324  T25LL0858C                ZENSE SPACE LLP   \n",
       "537325  T25LL0870A         ZIQZEQ PROCUREMENT LLP   \n",
       "537326  T25LL1049B           ZHONG XIN TRAVEL LLP   \n",
       "537327  T25LL1066B                 ZDT DRIVES LLP   \n",
       "\n",
       "       BUSINESS_CONSTITUTION_DESCRIPTION           ENTITY_TYPE_DESCRIPTION  \\\n",
       "0                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "1                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "2                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "3                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "4                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "...                                  ...                               ...   \n",
       "537323                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537324                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537325                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537326                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537327                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "\n",
       "       ENTITY_STATUS_DESCRIPTION REGISTRATION_INCORPORATION_DATE  \\\n",
       "0                           LIVE                      07-02-1975   \n",
       "1                           LIVE                      28-10-1974   \n",
       "2                           LIVE                      02-11-1974   \n",
       "3                           LIVE                      12-11-1974   \n",
       "4                           LIVE                      30-10-1974   \n",
       "...                          ...                             ...   \n",
       "537323                      LIVE                      16-05-2025   \n",
       "537324                      LIVE                      01-08-2025   \n",
       "537325                      LIVE                      04-08-2025   \n",
       "537326                      LIVE                      08-09-2025   \n",
       "537327                      LIVE                      14-09-2025   \n",
       "\n",
       "        PRIMARY_SSIC_CODE                    STREET_NAME POSTAL_CODE  \\\n",
       "0                   46302              FISHERY PORT ROAD      619742   \n",
       "1                   46411                    SIMS AVENUE      387509   \n",
       "2                   32909  ANG MO KIO INDUSTRIAL PARK 2A      568049   \n",
       "3                   46411                  JELLICOE ROAD      208767   \n",
       "4                   47711            WOODLANDS STREET 12      738623   \n",
       "...                   ...                            ...         ...   \n",
       "537323              96021                  KELANTAN LANE      200031   \n",
       "537324              43301     YISHUN INDUSTRIAL STREET 1      768161   \n",
       "537325              70209                  SIN MING LANE      573969   \n",
       "537326              79102                  JALAN BAHAGIA      320034   \n",
       "537327              47533                  FERNVALE ROAD      792466   \n",
       "\n",
       "       PARENT_INDUSTRY                       INDUSTRY_TYPE  \\\n",
       "0               Others                     Wholesale Trade   \n",
       "1               Others                     Wholesale Trade   \n",
       "2               Others                       Manufacturing   \n",
       "3               Others                     Wholesale Trade   \n",
       "4               Retail                              Retail   \n",
       "...                ...                                 ...   \n",
       "537323        Services                            Services   \n",
       "537324          Others  Built Environment & Infrastructure   \n",
       "537325          Others        Finance, Legal & Real Estate   \n",
       "537326          Others                     Tourism, Agency   \n",
       "537327             NaN                                 NaN   \n",
       "\n",
       "                                          SUB_INDUSTRY  \\\n",
       "0                            Food, Beverages & Tobacco   \n",
       "1                                      Household Goods   \n",
       "2       Other Specialised Manufacturing & Distribution   \n",
       "3                                      Household Goods   \n",
       "4                                    Fashion & Apparel   \n",
       "...                                                ...   \n",
       "537323                       Hair Salons & Barbershops   \n",
       "537324                                    Construction   \n",
       "537325      Legal, Accounting & Consultancy Activities   \n",
       "537326                Travel Agencies & Tour Operators   \n",
       "537327                                             NaN   \n",
       "\n",
       "                                              DESCRIPTION  \n",
       "0       Wholesale Of Livestock, Meat, Poultry, Eggs An...  \n",
       "1                      Wholesale Of Textiles And Leathers  \n",
       "2                   Other Manufacturing Industries N.E.C.  \n",
       "3                      Wholesale Of Textiles And Leathers  \n",
       "4                      Retail Sale Of Clothing For Adults  \n",
       "...                                                   ...  \n",
       "537323                          Hairdressing Salons/Shops  \n",
       "537324                             Renovation Contractors  \n",
       "537325             Management Consultancy Services N.E.C.  \n",
       "537326  Travel Agencies And Tour Operators (Mainly Out...  \n",
       "537327                                                NaN  \n",
       "\n",
       "[537328 rows x 13 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acra_data_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9289e8b3",
   "metadata": {},
   "source": [
    "### FIlter Acra data with Master DB to get list of companies havent been researched  by MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c28478d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533824, 13)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Ensure both UEN columns are strings for accurate matching\n",
    "acra_data_filtered['UEN'] = acra_data_filtered['UEN'].astype(str).str.strip().str.upper()\n",
    "master_db_df['UEN'] = master_db_df['UEN'].astype(str).str.strip().str.upper()\n",
    "\n",
    "# Filter out rows in acra_data_filtered whose UEN is already in master_db_df\n",
    "acra_data_filtered = acra_data_filtered[~acra_data_filtered['UEN'].isin(master_db_df['UEN'])]\n",
    "\n",
    "acra_data_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bd24ab",
   "metadata": {},
   "source": [
    "### Filter by  Industry (Wholesale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa058f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ENTITY_NAME</th>\n",
       "      <th>BUSINESS_CONSTITUTION_DESCRIPTION</th>\n",
       "      <th>ENTITY_TYPE_DESCRIPTION</th>\n",
       "      <th>ENTITY_STATUS_DESCRIPTION</th>\n",
       "      <th>REGISTRATION_INCORPORATION_DATE</th>\n",
       "      <th>PRIMARY_SSIC_CODE</th>\n",
       "      <th>STREET_NAME</th>\n",
       "      <th>POSTAL_CODE</th>\n",
       "      <th>PARENT_INDUSTRY</th>\n",
       "      <th>INDUSTRY_TYPE</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00182000A</td>\n",
       "      <td>AIK SENG HENG</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>07-02-1975</td>\n",
       "      <td>46302</td>\n",
       "      <td>FISHERY PORT ROAD</td>\n",
       "      <td>619742</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Food, Beverages &amp; Tobacco</td>\n",
       "      <td>Wholesale Of Livestock, Meat, Poultry, Eggs An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00233500W</td>\n",
       "      <td>ASIA STORE</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>28-10-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>SIMS AVENUE</td>\n",
       "      <td>387509</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Textiles And Leathers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00927000X</td>\n",
       "      <td>A WALIMOHAMED BROS</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>12-11-1974</td>\n",
       "      <td>46411</td>\n",
       "      <td>JELLICOE ROAD</td>\n",
       "      <td>208767</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Textiles And Leathers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>04129500E</td>\n",
       "      <td>AIK HOE &amp; CO</td>\n",
       "      <td>SOLE-PROPRIETOR</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>23-01-1975</td>\n",
       "      <td>46551</td>\n",
       "      <td>KELANTAN ROAD</td>\n",
       "      <td>200028</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Machinery, Equipment &amp; Supplies</td>\n",
       "      <td>Wholesale Of Marine Equipment And Accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>04545400X</td>\n",
       "      <td>AIK HUAT AND COMPANY</td>\n",
       "      <td>PARTNERSHIP</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>17-01-1975</td>\n",
       "      <td>46441</td>\n",
       "      <td>KAKI BUKIT AVENUE 1</td>\n",
       "      <td>417943</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Sporting Goods And Equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537268</th>\n",
       "      <td>T17LP0162L</td>\n",
       "      <td>ZYA HOLDINGS LIMITED PARTNERSHIP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>21-10-2017</td>\n",
       "      <td>46100</td>\n",
       "      <td>NATHAN ROAD</td>\n",
       "      <td>248728</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Other Specialised Wholesale</td>\n",
       "      <td>Wholesale On A Fee Or Commission Basis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537298</th>\n",
       "      <td>T22LL0564C</td>\n",
       "      <td>ZEN ENGINEERING &amp; TRADING LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>31-05-2022</td>\n",
       "      <td>46543</td>\n",
       "      <td>TOH GUAN ROAD EAST</td>\n",
       "      <td>608586</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Machinery, Equipment &amp; Supplies</td>\n",
       "      <td>Wholesale Of Lifts, Escalators And Industrial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537302</th>\n",
       "      <td>T23LL0056G</td>\n",
       "      <td>ZECRYNE LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>13-01-2023</td>\n",
       "      <td>46301</td>\n",
       "      <td>BUKIT BATOK STREET 25</td>\n",
       "      <td>658881</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Food, Beverages &amp; Tobacco</td>\n",
       "      <td>Wholesale Of Fruits And Vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537313</th>\n",
       "      <td>T24LL0528K</td>\n",
       "      <td>ZOHMH LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>07-05-2024</td>\n",
       "      <td>46303</td>\n",
       "      <td>WOODLANDS AVENUE 4</td>\n",
       "      <td>730844</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Food, Beverages &amp; Tobacco</td>\n",
       "      <td>Wholesale Of A General Line Of Groceries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537318</th>\n",
       "      <td>T24LL1189H</td>\n",
       "      <td>Z CONNECT LLP</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LIMITED LIABILITY PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>30-10-2024</td>\n",
       "      <td>46436</td>\n",
       "      <td>GAMBAS CRESCENT</td>\n",
       "      <td>757087</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Audio And Video Equipment (Except...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38428 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               UEN                          ENTITY_NAME  \\\n",
       "0        00182000A                        AIK SENG HENG   \n",
       "1        00233500W                           ASIA STORE   \n",
       "3        00927000X                   A WALIMOHAMED BROS   \n",
       "12       04129500E                         AIK HOE & CO   \n",
       "14       04545400X                 AIK HUAT AND COMPANY   \n",
       "...            ...                                  ...   \n",
       "537268  T17LP0162L     ZYA HOLDINGS LIMITED PARTNERSHIP   \n",
       "537298  T22LL0564C        ZEN ENGINEERING & TRADING LLP   \n",
       "537302  T23LL0056G                          ZECRYNE LLP   \n",
       "537313  T24LL0528K  ZOHMH LIMITED LIABILITY PARTNERSHIP   \n",
       "537318  T24LL1189H                        Z CONNECT LLP   \n",
       "\n",
       "       BUSINESS_CONSTITUTION_DESCRIPTION           ENTITY_TYPE_DESCRIPTION  \\\n",
       "0                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "1                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "3                            PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "12                       SOLE-PROPRIETOR  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "14                           PARTNERSHIP  SOLE PROPRIETORSHIP/ PARTNERSHIP   \n",
       "...                                  ...                               ...   \n",
       "537268                              <NA>               LIMITED PARTNERSHIP   \n",
       "537298                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537302                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537313                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "537318                              <NA>     LIMITED LIABILITY PARTNERSHIP   \n",
       "\n",
       "       ENTITY_STATUS_DESCRIPTION REGISTRATION_INCORPORATION_DATE  \\\n",
       "0                           LIVE                      07-02-1975   \n",
       "1                           LIVE                      28-10-1974   \n",
       "3                           LIVE                      12-11-1974   \n",
       "12                          LIVE                      23-01-1975   \n",
       "14                          LIVE                      17-01-1975   \n",
       "...                          ...                             ...   \n",
       "537268                      LIVE                      21-10-2017   \n",
       "537298                      LIVE                      31-05-2022   \n",
       "537302                      LIVE                      13-01-2023   \n",
       "537313                      LIVE                      07-05-2024   \n",
       "537318                      LIVE                      30-10-2024   \n",
       "\n",
       "        PRIMARY_SSIC_CODE            STREET_NAME POSTAL_CODE PARENT_INDUSTRY  \\\n",
       "0                   46302      FISHERY PORT ROAD      619742          Others   \n",
       "1                   46411            SIMS AVENUE      387509          Others   \n",
       "3                   46411          JELLICOE ROAD      208767          Others   \n",
       "12                  46551          KELANTAN ROAD      200028          Others   \n",
       "14                  46441    KAKI BUKIT AVENUE 1      417943          Others   \n",
       "...                   ...                    ...         ...             ...   \n",
       "537268              46100            NATHAN ROAD      248728          Others   \n",
       "537298              46543     TOH GUAN ROAD EAST      608586          Others   \n",
       "537302              46301  BUKIT BATOK STREET 25      658881          Others   \n",
       "537313              46303     WOODLANDS AVENUE 4      730844          Others   \n",
       "537318              46436        GAMBAS CRESCENT      757087          Others   \n",
       "\n",
       "          INDUSTRY_TYPE                     SUB_INDUSTRY  \\\n",
       "0       Wholesale Trade        Food, Beverages & Tobacco   \n",
       "1       Wholesale Trade                  Household Goods   \n",
       "3       Wholesale Trade                  Household Goods   \n",
       "12      Wholesale Trade  Machinery, Equipment & Supplies   \n",
       "14      Wholesale Trade                  Household Goods   \n",
       "...                 ...                              ...   \n",
       "537268  Wholesale Trade      Other Specialised Wholesale   \n",
       "537298  Wholesale Trade  Machinery, Equipment & Supplies   \n",
       "537302  Wholesale Trade        Food, Beverages & Tobacco   \n",
       "537313  Wholesale Trade        Food, Beverages & Tobacco   \n",
       "537318  Wholesale Trade                  Household Goods   \n",
       "\n",
       "                                              DESCRIPTION  \n",
       "0       Wholesale Of Livestock, Meat, Poultry, Eggs An...  \n",
       "1                      Wholesale Of Textiles And Leathers  \n",
       "3                      Wholesale Of Textiles And Leathers  \n",
       "12          Wholesale Of Marine Equipment And Accessories  \n",
       "14              Wholesale Of Sporting Goods And Equipment  \n",
       "...                                                   ...  \n",
       "537268             Wholesale On A Fee Or Commission Basis  \n",
       "537298  Wholesale Of Lifts, Escalators And Industrial ...  \n",
       "537302                 Wholesale Of Fruits And Vegetables  \n",
       "537313           Wholesale Of A General Line Of Groceries  \n",
       "537318  Wholesale Of Audio And Video Equipment (Except...  \n",
       "\n",
       "[38428 rows x 13 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wholesale data\n",
    "ssic_codes = [\n",
    "    \"46\", \"461\", \"4610\", \"46100\", \"462\", \"4621\", \"46211\", \"46212\", \"46213\", \"46219\",\n",
    "    \"4622\", \"46221\", \"46222\", \"46223\", \"46224\", \"46225\", \"46229\", \"463\", \"4630\", \"46301\",\n",
    "    \"46302\", \"46303\", \"46304\", \"46305\", \"46306\", \"46307\", \"46308\", \"46309\", \"464\", \"4641\",\n",
    "    \"46411\", \"46412\", \"46413\", \"46414\", \"46415\", \"46416\", \"4642\", \"46421\", \"46422\", \"46423\",\n",
    "    \"46424\", \"46429\", \"4643\", \"46431\", \"46432\", \"46433\", \"46434\", \"46435\", \"46436\", \"46439\",\n",
    "    \"4644\", \"46441\", \"46442\", \"46443\", \"46444\", \"46445\", \"46449\", \"4645\", \"46451\", \"46452\",\n",
    "    \"46453\", \"46459\", \"4646\", \"46461\", \"46462\", \"4647\", \"46471\", \"46472\", \"46473\", \"46474\",\n",
    "    \"46479\", \"4649\", \"46491\", \"46492\", \"46499\", \"465\", \"4651\", \"46511\", \"46512\", \"46513\",\n",
    "    \"46514\", \"4652\", \"46521\", \"46522\", \"46523\", \"4653\", \"46530\", \"4654\", \"46541\", \"46542\",\n",
    "    \"46543\", \"46544\", \"46549\", \"4655\", \"46551\", \"46552\", \"46559\", \"4656\", \"46561\", \"46562\",\n",
    "    \"46563\", \"4659\", \"46591\", \"46592\", \"46593\", \"46594\", \"46595\", \"46599\", \"466\", \"4661\",\n",
    "    \"46610\", \"4662\", \"46620\", \"4663\", \"46631\", \"46632\", \"46633\", \"46634\", \"46635\", \"46639\",\n",
    "    \"4664\", \"46641\", \"46642\", \"46643\", \"46649\", \"4665\", \"46651\", \"46659\", \"4666\", \"46661\",\n",
    "    \"46662\", \"469\", \"4690\", \"46900\"\n",
    "]\n",
    "\n",
    "\n",
    "acra_data_filtered_wholesale = acra_data_filtered[\n",
    "    (\n",
    "        (acra_data_filtered[\"ENTITY_STATUS_DESCRIPTION\"].str.lower() == \"live\") |\n",
    "        (acra_data_filtered[\"ENTITY_STATUS_DESCRIPTION\"].str.lower() == \"live company\")\n",
    "    )\n",
    "    &\n",
    "    (acra_data_filtered[\"PRIMARY_SSIC_CODE\"].astype(str).isin(ssic_codes))\n",
    "]\n",
    "\n",
    "\n",
    "acra_data_filtered_wholesale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d89c23d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recordowl_results = pd.read_excel(\"Fresh_Leads.xlsx\")\n",
    "# is_unique = recordowl_results['UEN'].is_unique\n",
    "# print(\"Is UEN unique?:\", is_unique)\n",
    "\n",
    "# recordowl_results.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6edf012",
   "metadata": {},
   "source": [
    "### Filter with Fresh Leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87dc3716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>ENTITY_NAME</th>\n",
       "      <th>BUSINESS_CONSTITUTION_DESCRIPTION</th>\n",
       "      <th>ENTITY_TYPE_DESCRIPTION</th>\n",
       "      <th>ENTITY_STATUS_DESCRIPTION</th>\n",
       "      <th>REGISTRATION_INCORPORATION_DATE</th>\n",
       "      <th>PRIMARY_SSIC_CODE</th>\n",
       "      <th>STREET_NAME</th>\n",
       "      <th>POSTAL_CODE</th>\n",
       "      <th>PARENT_INDUSTRY</th>\n",
       "      <th>INDUSTRY_TYPE</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53480073D</td>\n",
       "      <td>HUMBLE BREWS</td>\n",
       "      <td>SOLE-PROPRIETOR</td>\n",
       "      <td>SOLE PROPRIETORSHIP/ PARTNERSHIP</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>26-01-2024</td>\n",
       "      <td>46223</td>\n",
       "      <td>TOH YI DRIVE</td>\n",
       "      <td>590006</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Agricultural Raw Materials &amp; Live Animals</td>\n",
       "      <td>Wholesale Of Coffee, Cocoa And Tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202303828W</td>\n",
       "      <td>WINE &amp; BUBBLES PTE. LTD.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>02-02-2023</td>\n",
       "      <td>46307</td>\n",
       "      <td>STURDEE ROAD</td>\n",
       "      <td>207855</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Food, Beverages &amp; Tobacco</td>\n",
       "      <td>Wholesale Of Liquor, Soft Drinks And Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202542730M</td>\n",
       "      <td>NUVIAA PTE. LTD.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>24-09-2025</td>\n",
       "      <td>46413</td>\n",
       "      <td>YISHUN INDUSTRIAL STREET 1</td>\n",
       "      <td>768162</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Children And Infants' Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201828332D</td>\n",
       "      <td>DE MAJESTIC VINES PTE. LTD.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>17-08-2018</td>\n",
       "      <td>46307</td>\n",
       "      <td>ANSON ROAD</td>\n",
       "      <td>79903</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Food, Beverages &amp; Tobacco</td>\n",
       "      <td>Wholesale Of Liquor, Soft Drinks And Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201813214E</td>\n",
       "      <td>CARDE DESIGN PTE. LTD.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>LOCAL COMPANY</td>\n",
       "      <td>LIVE COMPANY</td>\n",
       "      <td>18-04-2018</td>\n",
       "      <td>46431</td>\n",
       "      <td>UPPER CROSS STREET</td>\n",
       "      <td>58357</td>\n",
       "      <td>Others</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>Household Goods</td>\n",
       "      <td>Wholesale Of Furniture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          UEN                  ENTITY_NAME BUSINESS_CONSTITUTION_DESCRIPTION  \\\n",
       "0   53480073D                 HUMBLE BREWS                   SOLE-PROPRIETOR   \n",
       "1  202303828W     WINE & BUBBLES PTE. LTD.                              <NA>   \n",
       "2  202542730M             NUVIAA PTE. LTD.                              <NA>   \n",
       "3  201828332D  DE MAJESTIC VINES PTE. LTD.                              <NA>   \n",
       "4  201813214E       CARDE DESIGN PTE. LTD.                              <NA>   \n",
       "\n",
       "            ENTITY_TYPE_DESCRIPTION ENTITY_STATUS_DESCRIPTION  \\\n",
       "0  SOLE PROPRIETORSHIP/ PARTNERSHIP                      LIVE   \n",
       "1                     LOCAL COMPANY              LIVE COMPANY   \n",
       "2                     LOCAL COMPANY              LIVE COMPANY   \n",
       "3                     LOCAL COMPANY              LIVE COMPANY   \n",
       "4                     LOCAL COMPANY              LIVE COMPANY   \n",
       "\n",
       "  REGISTRATION_INCORPORATION_DATE  PRIMARY_SSIC_CODE  \\\n",
       "0                      26-01-2024              46223   \n",
       "1                      02-02-2023              46307   \n",
       "2                      24-09-2025              46413   \n",
       "3                      17-08-2018              46307   \n",
       "4                      18-04-2018              46431   \n",
       "\n",
       "                  STREET_NAME POSTAL_CODE PARENT_INDUSTRY    INDUSTRY_TYPE  \\\n",
       "0                TOH YI DRIVE      590006          Others  Wholesale Trade   \n",
       "1                STURDEE ROAD      207855          Others  Wholesale Trade   \n",
       "2  YISHUN INDUSTRIAL STREET 1      768162          Others  Wholesale Trade   \n",
       "3                  ANSON ROAD       79903          Others  Wholesale Trade   \n",
       "4          UPPER CROSS STREET       58357          Others  Wholesale Trade   \n",
       "\n",
       "                                SUB_INDUSTRY  \\\n",
       "0  Agricultural Raw Materials & Live Animals   \n",
       "1                  Food, Beverages & Tobacco   \n",
       "2                            Household Goods   \n",
       "3                  Food, Beverages & Tobacco   \n",
       "4                            Household Goods   \n",
       "\n",
       "                                      DESCRIPTION  \n",
       "0              Wholesale Of Coffee, Cocoa And Tea  \n",
       "1  Wholesale Of Liquor, Soft Drinks And Beverages  \n",
       "2     Wholesale Of Children And Infants' Clothing  \n",
       "3  Wholesale Of Liquor, Soft Drinks And Beverages  \n",
       "4                          Wholesale Of Furniture  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Copy to avoid SettingWithCopyWarning ---\n",
    "acra_data_filtered_wholesale = acra_data_filtered_wholesale.copy()\n",
    "\n",
    "# --- UPDATE HERE: Remove rows if UEN exists in recordowl_results.xlsx ---\n",
    "recordowl_results = pd.read_excel(\"Fresh_Leads.xlsx\")\n",
    "# Ensure both dataframes have a 'UEN' column\n",
    "if \"UEN\" in recordowl_results.columns and \"UEN\" in acra_data_filtered_wholesale.columns:\n",
    "    filtered = acra_data_filtered_wholesale[~acra_data_filtered_wholesale[\"UEN\"].isin(recordowl_results[\"UEN\"])]\n",
    "else:\n",
    "    raise ValueError(\"Column 'UEN' not found in one of the dataframes.\")\n",
    "\n",
    "# sample data \n",
    "acra_data_filtered_wholesale = filtered.sample(n=200, random_state=42).reset_index(drop=True)\n",
    "\n",
    "acra_data_filtered_wholesale.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b530343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acra_data_filtered_wholesale_10 = pd.DataFrame({\n",
    "    \"UEN\": [\"197502143C\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040bb97",
   "metadata": {},
   "source": [
    "### Get Data from RecordOwl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b3cd46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Processing 197502143C (1/1)\n",
      "  📡 Starting Apify run for 197502143C...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:44:47.351Z ACTOR: Pulling container image of build g6G5r98rF5fM6ecm3 from registry.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:44:47.353Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:44:47.386Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:44:47.569Z Will run command: xvfb-run -a -s \"-ac -screen 0 1920x1080x24+32 -nolisten tcp\" /bin/sh -c ./start_xvfb_and_run_cmd.sh && npm run start:prod --silent\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:44:48.258Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.4\",\"apifyClientVersion\":\"2.16.0\",\"crawleeVersion\":\"3.14.1\",\"osType\":\"Linux\",\"nodeVersion\":\"v22.19.0\"}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:44:48.396Z \u001b[32mINFO\u001b[39m  Configuring Puppeteer Scraper.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:44:49.013Z \u001b[32mINFO\u001b[39m  Configuration completed. Starting the scrape.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:44:49.089Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:44:51.968Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked - received 403 status code.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 2.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:44:51.970Z \u001b[90m {\"id\":\"XsOj8IqwoXyWgRx\",\"url\":\"https://recordowl.com/\",\"retryCount\":1}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:45:00.520Z \u001b[33mWARN\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Reclaiming failed request back to the list or queue. Request blocked - received 403 status code.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:45:00.522Z \u001b[90m {\"id\":\"XsOj8IqwoXyWgRx\",\"url\":\"https://recordowl.com/\",\"retryCount\":2}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> Status: RUNNING, Message: Crawled 0/1 pages, 0 failed requests, desired concurrency 3.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:45:08.380Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Visiting RecordOwl for UEN: 197502143C\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:45:22.297Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:45:22.836Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":1,\"requestsFailed\":0,\"retryHistogram\":[null,null,1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":21267,\"requestsFinishedPerMinute\":2,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":21267,\"requestsTotal\":1,\"crawlerRuntimeMillis\":33891}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:45:22.838Z \u001b[32mINFO\u001b[39m \u001b[33m PuppeteerCrawler:\u001b[39m Finished! Total 1 requests: 1 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> 2025-11-04T07:45:22.865Z \u001b[32mINFO\u001b[39m  Puppeteer Scraper finished.\n",
      "\u001b[36m[apify.puppeteer-scraper runId:uD87ABcdYMsvpuYIK]\u001b[0m -> Status: SUCCEEDED, Message: Finished! Total 1 requests: 1 succeeded, 0 failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ⏳ Waiting for run to complete...\n",
      "  ⏳ Waiting for dataset to be ready...\n",
      "  ✅ Successfully scraped 197502143C\n",
      "  🔍 Searching for phone numbers...\n",
      "  📋 Found 25 dt tags\n",
      "  📝 Field 'contact number': 6339 1188\n",
      "  🔢 Extracted digits: 63391188\n",
      "  ✅ Added from dt/dd (8 digits): +6563391188\n",
      "  ✅ Total phones found: ['+6563391188']\n",
      "  ✅ Processed 197502143C: 1 emails, 1 phones\n",
      "  💤 Sleeping for 11s before next request...\n",
      "\n",
      "✅ Scraping complete!\n",
      "\n",
      "📊 Results summary:\n",
      "   Total processed: 1\n",
      "   With emails: 1\n",
      "   With phones: 1\n",
      "   With websites: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>Emails</th>\n",
       "      <th>Phones</th>\n",
       "      <th>Website</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Instagram</th>\n",
       "      <th>TikTok</th>\n",
       "      <th>RecordOwl_Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197502143C</td>\n",
       "      <td>[enquiry@eldric.sg]</td>\n",
       "      <td>[+6563391188]</td>\n",
       "      <td>https://eldric.sg</td>\n",
       "      <td>[https://www.facebook.com/eldricmarketing/]</td>\n",
       "      <td>[https://sg.linkedin.com/company/eldric-market...</td>\n",
       "      <td>[https://www.instagram.com/eldricmarketing/]</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/eldric-marketing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          UEN               Emails         Phones            Website  \\\n",
       "0  197502143C  [enquiry@eldric.sg]  [+6563391188]  https://eldric.sg   \n",
       "\n",
       "                                      Facebook  \\\n",
       "0  [https://www.facebook.com/eldricmarketing/]   \n",
       "\n",
       "                                            LinkedIn  \\\n",
       "0  [https://sg.linkedin.com/company/eldric-market...   \n",
       "\n",
       "                                      Instagram TikTok  \\\n",
       "0  [https://www.instagram.com/eldricmarketing/]   None   \n",
       "\n",
       "                                      RecordOwl_Link  \n",
       "0  https://recordowl.com/company/eldric-marketing...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client = ApifyClient(\"apify_api_yNR85etaHpLtBzPoVozVVXUsCZe54u2Ffog1\")\n",
    "\n",
    "SOCIAL_MEDIA_DOMAINS = [\n",
    "    \"facebook.com\", \"linkedin.com\", \"instagram.com\", \"youtube.com\",\n",
    "    \"tiktok.com\", \"twitter.com\", \"x.com\", \"pinterest.com\"\n",
    "]\n",
    "\n",
    "def fetch_dataset_items_safe(dataset_client, max_retries=5, initial_wait=3):\n",
    "    \"\"\"Safely fetch dataset items with multiple retry strategies.\"\"\"\n",
    "    dataset_items = []\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Strategy 1: Try using iterate_items() (streaming)\n",
    "            try:\n",
    "                dataset_items = list(dataset_client.iterate_items())\n",
    "                if dataset_items:\n",
    "                    return dataset_items\n",
    "            except (HTTPError, ConnectionError, ProtocolError, Exception) as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = initial_wait * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"  ⚠️ Iteration method failed (attempt {attempt + 1}/{max_retries}), trying direct fetch in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  ⚠️ Iteration method failed after all retries, trying direct fetch...\")\n",
    "            \n",
    "            # Strategy 2: Try using list_items() (direct pagination)\n",
    "            try:\n",
    "                offset = 0\n",
    "                limit = 100\n",
    "                while True:\n",
    "                    page = dataset_client.list_items(offset=offset, limit=limit, clean=True)\n",
    "                    if not page.items:\n",
    "                        break\n",
    "                    dataset_items.extend(page.items)\n",
    "                    if len(page.items) < limit:\n",
    "                        break\n",
    "                    offset += limit\n",
    "                \n",
    "                if dataset_items:\n",
    "                    return dataset_items\n",
    "            except (HTTPError, ConnectionError, ProtocolError, Exception) as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = initial_wait * (2 ** attempt)\n",
    "                    print(f\"  ⚠️ Direct fetch failed (attempt {attempt + 1}/{max_retries}), retrying in {wait_time}s...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"  ❌ All fetch methods failed: {e}\")\n",
    "                    return []\n",
    "                    \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = initial_wait * (2 ** attempt)\n",
    "                print(f\"  ⚠️ Unexpected error (attempt {attempt + 1}/{max_retries}), retrying in {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"  ❌ Failed after all retries: {e}\")\n",
    "                return []\n",
    "    \n",
    "    return dataset_items\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for idx, (i, row) in enumerate(acra_data_filtered_wholesale_10.iterrows(), 1):\n",
    "    uen = str(row[\"UEN\"]).strip()\n",
    "    print(f\"\\n🔎 Processing {uen} ({idx}/{len(acra_data_filtered_wholesale_10)})\")\n",
    "\n",
    "    # Build pageFunction with proper escaping\n",
    "    page_function = f\"\"\"\n",
    "    async function pageFunction(context) {{\n",
    "        const {{ page, log, request }} = context;\n",
    "        const uen = \"{uen}\";\n",
    "        log.info(\"Visiting RecordOwl for UEN: \" + uen);\n",
    "\n",
    "        try {{\n",
    "            await page.waitForSelector(\"input[placeholder='Search company name, industry, or address']\", {{ timeout: 30000 }});\n",
    "            const input = await page.$(\"input[placeholder='Search company name, industry, or address']\");\n",
    "            await input.click({{ clickCount: 3 }});\n",
    "            await input.type(uen, {{ delay: 100 }});\n",
    "\n",
    "            await Promise.all([\n",
    "                page.waitForNavigation({{ waitUntil: 'networkidle2', timeout: 60000 }}).catch(() => null),\n",
    "                page.click(\"button[type='submit']\")\n",
    "            ]);\n",
    "\n",
    "            // Wait for results with longer timeout\n",
    "            try {{\n",
    "                await page.waitForSelector(\"a[href*='/company/']\", {{ timeout: 45000 }});\n",
    "            }} catch (e) {{\n",
    "                log.info(\"No company links found, might be not found\");\n",
    "                return {{ status: 'not_found', uen }};\n",
    "            }}\n",
    "\n",
    "            const companyLink = await page.$$eval(\"a[href*='/company/']\", (links, uen) => {{\n",
    "                for (const a of links) {{\n",
    "                    const text = a.innerText || \"\";\n",
    "                    const href = a.href || \"\";\n",
    "                    if (text.includes(uen) || href.includes(uen.toLowerCase())) return a.href;\n",
    "                }}\n",
    "                return links.length > 0 ? links[0].href : null;\n",
    "            }}, uen);\n",
    "\n",
    "            if (!companyLink) return {{ status: 'not_found', uen }};\n",
    "\n",
    "            if (page.url() !== companyLink) {{\n",
    "                await page.goto(companyLink, {{ waitUntil: 'networkidle2', timeout: 60000 }});\n",
    "            }}\n",
    "\n",
    "            await new Promise(r => setTimeout(r, 3000)); // Increased wait time\n",
    "            const html_content = await page.content();\n",
    "            const title = await page.title();\n",
    "            const url = page.url();\n",
    "\n",
    "            return {{ status: 'success', uen, url, title, html_content }};\n",
    "        }} catch (err) {{\n",
    "            log.error(\"Error in pageFunction: \" + err.message);\n",
    "            return {{ status: 'error', uen, error: err.message }};\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    run_input = {\n",
    "        \"startUrls\": [{\"url\": \"https://recordowl.com/\"}],\n",
    "        \"useChrome\": True,\n",
    "        \"headless\": True,\n",
    "        \"stealth\": True,\n",
    "        \"pageFunction\": page_function,\n",
    "    }\n",
    "\n",
    "    run = None\n",
    "    try:\n",
    "        # Start the run (same as original working code)\n",
    "        print(f\"  📡 Starting Apify run for {uen}...\")\n",
    "        run = client.actor(\"apify/puppeteer-scraper\").call(run_input=run_input)\n",
    "        \n",
    "        # Wait for the run to finish (poll the status)\n",
    "        print(f\"  ⏳ Waiting for run to complete...\")\n",
    "        run_client = client.run(run[\"id\"])\n",
    "        run_client.wait_for_finish()\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Apify call failed for {uen}: {e}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": None,\n",
    "            \"Error\": f\"Apify call failed: {str(e)}\"\n",
    "        })\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "\n",
    "    if not run or \"defaultDatasetId\" not in run:\n",
    "        print(f\"  ⚠️ No valid dataset returned for {uen}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": None,\n",
    "            \"Error\": \"No dataset returned\"\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # Wait for dataset to be ready\n",
    "    print(f\"  ⏳ Waiting for dataset to be ready...\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    scraped_html, record_owl_url = None, None\n",
    "    \n",
    "    # Fetch dataset items with improved error handling\n",
    "    dataset_items = fetch_dataset_items_safe(\n",
    "        client.dataset(run[\"defaultDatasetId\"]),\n",
    "        max_retries=5,\n",
    "        initial_wait=3\n",
    "    )\n",
    "    \n",
    "    # Process items\n",
    "    for item in dataset_items:\n",
    "        if item.get(\"status\") == \"success\":\n",
    "            scraped_html = item.get(\"html_content\", \"\")\n",
    "            record_owl_url = item.get(\"url\")\n",
    "            print(f\"  ✅ Successfully scraped {uen}\")\n",
    "        elif item.get(\"status\") == \"not_found\":\n",
    "            print(f\"  ⚠️ Company not found for UEN {uen}\")\n",
    "        elif item.get(\"status\") == \"error\":\n",
    "            print(f\"  ❌ Error for {uen}: {item.get('error')}\")\n",
    "\n",
    "    if not scraped_html:\n",
    "        print(f\"  ⚠️ No HTML content retrieved for {uen}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": record_owl_url or None,\n",
    "            \"Error\": \"No HTML content retrieved\"\n",
    "        })\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "\n",
    "    # Parse HTML\n",
    "    try:\n",
    "        soup = BeautifulSoup(scraped_html, \"html.parser\")\n",
    "        parent = soup.select_one(\"div.max-w-7xl.mx-auto.lg\\\\:py-6.sm\\\\:px-6.lg\\\\:px-8\")\n",
    "\n",
    "        emails, phones, website = [], [], None\n",
    "        facebook_links, linkedin_links, instagram_links, tiktok_links = [], [], [], []\n",
    "\n",
    "        if parent:\n",
    "            # Extract emails\n",
    "            for a in parent.select(\"a[href^=mailto]\"):\n",
    "                email = a.get(\"href\", \"\").replace(\"mailto:\", \"\").strip()\n",
    "                if email and email not in emails and \"@\" in email:\n",
    "                    emails.append(email)\n",
    "\n",
    "            # ========== COMPREHENSIVE PHONE EXTRACTION ==========\n",
    "            # This extracts Singapore phone numbers with ANY spacing/formatting:\n",
    "            # - \"65 63 19 2960\" (spaces between digits)\n",
    "            # - \"6563192960\" (no spaces)\n",
    "            # - \"+65-6319-2960\" (dashes)\n",
    "            # - \"65 6 3 1 9 2 9 6 0\" (space between every digit)\n",
    "            # - \"(65) 6319 2960\" (with parentheses)\n",
    "            # Method: Extract ALL digits first, then validate pattern\n",
    "            print(f\"  🔍 Searching for phone numbers...\")\n",
    "            \n",
    "            # Method 1: Look for tel: links (most reliable)\n",
    "            tel_links = parent.select(\"a[href^='tel:'], a[href^='tel']\")\n",
    "            if tel_links:\n",
    "                print(f\"  📱 Found {len(tel_links)} tel: links\")\n",
    "            \n",
    "            for a in tel_links:\n",
    "                tel_href = a.get(\"href\", \"\").replace(\"tel:\", \"\").strip()\n",
    "                tel_text = a.get_text(strip=True)\n",
    "                print(f\"  📞 Tel link - href: '{tel_href}', text: '{tel_text}'\")\n",
    "                \n",
    "                # Extract all digits from tel link\n",
    "                digits_only = re.sub(r\"\\D\", \"\", tel_href)\n",
    "                print(f\"  🔢 Tel digits: {digits_only}\")\n",
    "                \n",
    "                # Handle different digit lengths\n",
    "                if len(digits_only) == 10 and digits_only.startswith(\"65\") and digits_only[2] in \"689\":\n",
    "                    # 10 digits starting with 65 (e.g., \"6563192960\")\n",
    "                    formatted = \"+\" + digits_only\n",
    "                    if formatted not in phones:\n",
    "                        phones.append(formatted)\n",
    "                        print(f\"  ✅ Added from tel link (10 digits): {formatted}\")\n",
    "                elif len(digits_only) == 8 and digits_only[0] in \"689\":\n",
    "                    # 8 digits starting with 6/8/9 (e.g., \"63192960\")\n",
    "                    formatted = \"+65\" + digits_only\n",
    "                    if formatted not in phones:\n",
    "                        phones.append(formatted)\n",
    "                        print(f\"  ✅ Added from tel link (8 digits): {formatted}\")\n",
    "                elif len(digits_only) > 10:\n",
    "                    # More than 10 digits, try to find valid pattern\n",
    "                    print(f\"  🔍 Searching within {len(digits_only)} digits for valid pattern...\")\n",
    "                    found = False\n",
    "                    # Look for 65 followed by 6/8/9\n",
    "                    for i in range(len(digits_only) - 9):\n",
    "                        if digits_only[i:i+2] == \"65\" and digits_only[i+2] in \"689\":\n",
    "                            formatted = \"+\" + digits_only[i:i+10]\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from tel link (extracted): {formatted}\")\n",
    "                            found = True\n",
    "                            break\n",
    "                    if not found:\n",
    "                        # Try last 8 digits if they start with 6/8/9\n",
    "                        if digits_only[-8] in \"689\":\n",
    "                            formatted = \"+65\" + digits_only[-8:]\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from tel link (last 8 digits): {formatted}\")\n",
    "            \n",
    "            # Method 2: Look in dt/dd structure with broader keywords\n",
    "            dt_tags = parent.select(\"dt\")\n",
    "            if dt_tags:\n",
    "                print(f\"  📋 Found {len(dt_tags)} dt tags\")\n",
    "            \n",
    "            for dt in dt_tags:\n",
    "                dt_text = dt.get_text(strip=True).lower()\n",
    "                # Check for phone-related keywords but exclude non-phone fields\n",
    "                exclude_keywords = [\"officer\", \"charge\", \"employee\", \"shareholder\", \"director\", \"registration\"]\n",
    "                phone_keywords = [\"contact number\", \"phone\", \"tel\", \"mobile\", \"call\", \"contact no\"]\n",
    "                \n",
    "                is_phone_field = any(kw in dt_text for kw in phone_keywords)\n",
    "                is_excluded = any(excl in dt_text for excl in exclude_keywords)\n",
    "                \n",
    "                if is_phone_field and not is_excluded:\n",
    "                    dd = dt.find_next_sibling(\"dd\")\n",
    "                    if dd:\n",
    "                        number_text = dd.get_text(\" \", strip=True)\n",
    "                        print(f\"  📝 Field '{dt_text}': {number_text}\")\n",
    "                        \n",
    "                        # Extract all digits and check if it forms a valid phone number\n",
    "                        all_digits = re.sub(r\"\\D\", \"\", number_text)\n",
    "                        print(f\"  🔢 Extracted digits: {all_digits}\")\n",
    "                        \n",
    "                        # Check for Singapore phone patterns in the digits\n",
    "                        # Pattern 1: 10 digits starting with 65\n",
    "                        if len(all_digits) == 10 and all_digits.startswith(\"65\") and all_digits[2] in \"689\":\n",
    "                            formatted = \"+\" + all_digits\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from dt/dd (10 digits): {formatted}\")\n",
    "                        # Pattern 2: 8 digits starting with 6, 8, or 9\n",
    "                        elif len(all_digits) == 8 and all_digits[0] in \"689\":\n",
    "                            formatted = \"+65\" + all_digits\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from dt/dd (8 digits): {formatted}\")\n",
    "                        # Pattern 3: More than 10 digits, try to extract 10-digit number starting with 65\n",
    "                        elif len(all_digits) > 10:\n",
    "                            # Look for 65 followed by 6/8/9 in the digit string\n",
    "                            for i in range(len(all_digits) - 9):\n",
    "                                if all_digits[i:i+2] == \"65\" and all_digits[i+2] in \"689\":\n",
    "                                    potential_number = all_digits[i:i+10]\n",
    "                                    formatted = \"+\" + potential_number\n",
    "                                    if formatted not in phones:\n",
    "                                        phones.append(formatted)\n",
    "                                        print(f\"  ✅ Added from dt/dd (extracted): {formatted}\")\n",
    "                                    break\n",
    "            \n",
    "            # Method 3: Search entire parent for phone patterns if none found\n",
    "            if not phones:\n",
    "                print(f\"  🔎 No phones found yet, searching entire content...\")\n",
    "                full_text = parent.get_text()\n",
    "                \n",
    "                # Ultra-comprehensive patterns to catch ALL spacing variations\n",
    "                # These patterns allow unlimited spaces/dashes between digits\n",
    "                patterns = [\n",
    "                    # Pattern 1: +65 with any spacing (e.g., \"+65 6 3 1 9 2 9 6 0\", \"+65-6319-2960\")\n",
    "                    r\"\\+[\\s\\-]*65[\\s\\-]+[689][\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d\",\n",
    "                    # Pattern 2: (65) with any spacing\n",
    "                    r\"\\([\\s\\-]*65[\\s\\-]*\\)[\\s\\-]*[689][\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d\",\n",
    "                    # Pattern 3: 65 without + or () but with space/dash (e.g., \"65 6 3 1 9 2 9 6 0\", \"65-6319-2960\")\n",
    "                    r\"(?<!\\d)65[\\s\\-]+[689][\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d(?!\\d)\",\n",
    "                    # Pattern 4: Just 8 digits starting with 6/8/9 with any spacing\n",
    "                    r\"(?<!\\d)[689][\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d[\\s\\-]*\\d(?!\\d)\",\n",
    "                ]\n",
    "                \n",
    "                for pattern_idx, pattern in enumerate(patterns, 1):\n",
    "                    matches = re.findall(pattern, full_text)\n",
    "                    if matches:\n",
    "                        print(f\"  🔍 Pattern {pattern_idx} found {len(matches)} potential matches\")\n",
    "                    \n",
    "                    for match in matches:\n",
    "                        # Extract only digits\n",
    "                        digits = re.sub(r\"\\D\", \"\", match)\n",
    "                        print(f\"  🔢 Pattern {pattern_idx} match: '{match.strip()}' → digits: '{digits}'\")\n",
    "                        \n",
    "                        # Validate and format\n",
    "                        if len(digits) == 10 and digits.startswith(\"65\") and digits[2] in \"689\":\n",
    "                            formatted = \"+\" + digits\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from pattern {pattern_idx} (10 digits): {formatted}\")\n",
    "                        elif len(digits) == 8 and digits[0] in \"689\":\n",
    "                            formatted = \"+65\" + digits\n",
    "                            if formatted not in phones:\n",
    "                                phones.append(formatted)\n",
    "                                print(f\"  ✅ Added from pattern {pattern_idx} (8 digits): {formatted}\")\n",
    "                        elif len(digits) > 10:\n",
    "                            # Try to find a valid 10-digit number within\n",
    "                            for i in range(len(digits) - 9):\n",
    "                                if digits[i:i+2] == \"65\" and digits[i+2] in \"689\":\n",
    "                                    potential = digits[i:i+10]\n",
    "                                    formatted = \"+\" + potential\n",
    "                                    if formatted not in phones:\n",
    "                                        phones.append(formatted)\n",
    "                                        print(f\"  ✅ Added from pattern {pattern_idx} (extracted): {formatted}\")\n",
    "                                    break\n",
    "            \n",
    "            if phones:\n",
    "                print(f\"  ✅ Total phones found: {phones}\")\n",
    "            else:\n",
    "                print(f\"  ⚠️ WARNING: No phone numbers found for {uen}\")\n",
    "                print(f\"  📄 Showing first 500 chars of parent HTML for debugging:\")\n",
    "                print(parent.prettify()[:500] + \"...\")\n",
    "            # ========== END PHONE EXTRACTION ==========\n",
    "\n",
    "            # Extract website\n",
    "            valid_websites = []\n",
    "            for a in parent.select(\"a[href^=http]\"):\n",
    "                href = a.get(\"href\", \"\").strip()\n",
    "                href_lower = href.lower()\n",
    "                if not any(domain in href_lower for domain in SOCIAL_MEDIA_DOMAINS):\n",
    "                    if not any(skip in href_lower for skip in [\"recordowl\", \"apify.com\"]):\n",
    "                        if any(tld in href for tld in [\".com\", \".sg\", \".net\", \".org\", \".co\"]):\n",
    "                            valid_websites.append(href)\n",
    "            website = valid_websites[0] if valid_websites else None\n",
    "\n",
    "        # Extract social media links from entire page\n",
    "        for a in soup.find_all(\"a\", href=True):\n",
    "            href = a[\"href\"].strip().lower()\n",
    "            if \"facebook.com\" in href and href not in facebook_links:\n",
    "                facebook_links.append(href)\n",
    "            elif \"linkedin.com\" in href and href not in linkedin_links:\n",
    "                linkedin_links.append(href)\n",
    "            elif \"instagram.com\" in href and href not in instagram_links:\n",
    "                instagram_links.append(href)\n",
    "            elif \"tiktok.com\" in href and href not in tiktok_links:\n",
    "                tiktok_links.append(href)\n",
    "\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": emails if emails else None,\n",
    "            \"Phones\": phones if phones else None,\n",
    "            \"Website\": website,\n",
    "            \"Facebook\": list(set(facebook_links)) if facebook_links else None,\n",
    "            \"LinkedIn\": list(set(linkedin_links)) if linkedin_links else None,\n",
    "            \"Instagram\": list(set(instagram_links)) if instagram_links else None,\n",
    "            \"TikTok\": list(set(tiktok_links)) if tiktok_links else None,\n",
    "            \"RecordOwl_Link\": record_owl_url,\n",
    "        })\n",
    "        print(f\"  ✅ Processed {uen}: {len(emails) if emails else 0} emails, {len(phones) if phones else 0} phones\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error parsing HTML for {uen}: {e}\")\n",
    "        all_results.append({\n",
    "            \"UEN\": uen,\n",
    "            \"Emails\": None,\n",
    "            \"Phones\": None,\n",
    "            \"Website\": None,\n",
    "            \"Facebook\": None,\n",
    "            \"LinkedIn\": None,\n",
    "            \"Instagram\": None,\n",
    "            \"TikTok\": None,\n",
    "            \"RecordOwl_Link\": record_owl_url or None,\n",
    "            \"Error\": f\"HTML parsing error: {str(e)}\"\n",
    "        })\n",
    "\n",
    "    # Dynamic sleep time to avoid rate limiting\n",
    "    sleep_time = 10 + (idx % 5)  # 10-14 seconds\n",
    "    print(f\"  💤 Sleeping for {sleep_time}s before next request...\")\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "New_Fresh_Leads = pd.DataFrame(all_results)\n",
    "print(\"\\n✅ Scraping complete!\")\n",
    "print(f\"\\n📊 Results summary:\")\n",
    "print(f\"   Total processed: {len(New_Fresh_Leads)}\")\n",
    "print(f\"   With emails: {New_Fresh_Leads['Emails'].notna().sum()}\")\n",
    "print(f\"   With phones: {New_Fresh_Leads['Phones'].notna().sum()}\")\n",
    "print(f\"   With websites: {New_Fresh_Leads['Website'].notna().sum()}\")\n",
    "New_Fresh_Leads.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce63aaf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UEN</th>\n",
       "      <th>Emails</th>\n",
       "      <th>Phones</th>\n",
       "      <th>Website</th>\n",
       "      <th>Facebook</th>\n",
       "      <th>LinkedIn</th>\n",
       "      <th>Instagram</th>\n",
       "      <th>TikTok</th>\n",
       "      <th>RecordOwl_Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197502143C</td>\n",
       "      <td>[enquiry@eldric.sg]</td>\n",
       "      <td>[+6563391188]</td>\n",
       "      <td>https://eldric.sg</td>\n",
       "      <td>[https://www.facebook.com/eldricmarketing/]</td>\n",
       "      <td>[https://sg.linkedin.com/company/eldric-market...</td>\n",
       "      <td>[https://www.instagram.com/eldricmarketing/]</td>\n",
       "      <td>None</td>\n",
       "      <td>https://recordowl.com/company/eldric-marketing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          UEN               Emails         Phones            Website  \\\n",
       "0  197502143C  [enquiry@eldric.sg]  [+6563391188]  https://eldric.sg   \n",
       "\n",
       "                                      Facebook  \\\n",
       "0  [https://www.facebook.com/eldricmarketing/]   \n",
       "\n",
       "                                            LinkedIn  \\\n",
       "0  [https://sg.linkedin.com/company/eldric-market...   \n",
       "\n",
       "                                      Instagram TikTok  \\\n",
       "0  [https://www.instagram.com/eldricmarketing/]   None   \n",
       "\n",
       "                                      RecordOwl_Link  \n",
       "0  https://recordowl.com/company/eldric-marketing...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_Fresh_Leads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78537b1",
   "metadata": {},
   "source": [
    "### Append and save into exel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c4e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Load both Excel files\n",
    "# file_path_1 = \"Fresh_Leads.xlsx\"\n",
    "# Fresh_Leads = pd.read_excel(file_path_1)\n",
    "\n",
    "# # file_path_2 = \"recordowl_results_4.xlsx\"\n",
    "# # recordowl_results_4 = pd.read_excel(file_path_2)\n",
    "\n",
    "# # Append (combine) them\n",
    "# combined_df = pd.concat([Fresh_Leads, Fresh_Leads_with_phones], ignore_index=True)\n",
    "\n",
    "# # Optional: Save to a new Excel file\n",
    "# combined_df.to_excel(\"Fresh_Leads_New.xlsx\", index=False)\n",
    "\n",
    "# # Preview\n",
    "# combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257fbbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_non_nan = combined_df['Phones'].notna().sum()\n",
    "# print(count_non_nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a4e0f",
   "metadata": {},
   "source": [
    "### Website Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccaea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import asyncio\n",
    "\n",
    "# =====================================================\n",
    "# Validate Website (only if no phone number)\n",
    "# =====================================================\n",
    "async def check_url(url: str) -> bool:\n",
    "    \"\"\"Return True if the URL is reachable (status < 400).\"\"\"\n",
    "    if not url:\n",
    "        return False\n",
    "    try:\n",
    "        async with httpx.AsyncClient(follow_redirects=True, timeout=5) as client:\n",
    "            response = await client.head(url)\n",
    "            return response.status_code < 400\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "async def validate_if_needed(df):\n",
    "    \"\"\"Validate websites only if phone number is missing.\"\"\"\n",
    "    for i, row in df.iterrows():\n",
    "        url = row.get(\"Website\")\n",
    "        phone = row.get(\"Phones\")\n",
    "\n",
    "        # Skip validation if phone exists\n",
    "        if phone:\n",
    "            df.at[i, \"Website_Valid\"] = None\n",
    "            continue\n",
    "\n",
    "        # Validate website if no phone\n",
    "        if url:\n",
    "            is_valid = await check_url(url)\n",
    "            df.at[i, \"Website_Valid\"] = \"valid\" if is_valid else \"invalid\"\n",
    "        else:\n",
    "            df.at[i, \"Website_Valid\"] = \"invalid\"\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =====================================================\n",
    "# Run async validation safely inside Jupyter\n",
    "# =====================================================\n",
    "result_df = await validate_if_needed(result_df)\n",
    "\n",
    "# =====================================================\n",
    "# Final output\n",
    "# =====================================================\n",
    "display(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c268400",
   "metadata": {},
   "source": [
    "### If contact number is invalid, then webscrapped website to get contact number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e742795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from apify_client import ApifyClient\n",
    "\n",
    "# --- Initialize Apify client ---\n",
    "APIFY_TOKEN = os.getenv(\"APIFY_TOKEN\", \"apify_api_0HQ8fc5fw5T1aosdacxKQNQYVBAEwi3tXaJc\")\n",
    "client = ApifyClient(APIFY_TOKEN)\n",
    "\n",
    "# --- Async wrapper so you can run in Jupyter ---\n",
    "async def enrich_with_contact_info(df):\n",
    "    \"\"\"Scrape contact info for rows where Website_Valid == 'valid' and Phones is empty.\"\"\"\n",
    "    updated_df = df.copy()\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        website = row.get(\"Website\")\n",
    "        status = row.get(\"Website_Valid\")\n",
    "        phone = row.get(\"Phones\")\n",
    "\n",
    "        if not website or status != \"valid\" or phone:\n",
    "            continue  # Skip invalid or already complete rows\n",
    "\n",
    "        print(f\"🔍 Scraping contact page for: {website}\")\n",
    "\n",
    "        # --- Apify scraping run input ---\n",
    "        run_input = {\n",
    "            \"startUrls\": [{\"url\": website}],\n",
    "            \"pageFunction\": r\"\"\"\n",
    "                async function pageFunction(context) {\n",
    "                    const $ = context.jQuery;\n",
    "                    const isContact = context.request.userData?.isContact || false;\n",
    "\n",
    "                    if (!isContact) {\n",
    "                        let contactUrl = null;\n",
    "                        $('a[href]').each((i, el) => {\n",
    "                            const href = $(el).attr('href').toLowerCase();\n",
    "                            if (href.includes('contact')) {\n",
    "                                contactUrl = href.startsWith('http') ? href : window.location.origin + href;\n",
    "                                return false;\n",
    "                            }\n",
    "                        });\n",
    "\n",
    "                        if (contactUrl) {\n",
    "                            await context.enqueueRequest({ url: contactUrl, userData: { isContact: true } });\n",
    "                            context.log.info(`Enqueued contact page: ${contactUrl}`);\n",
    "                        }\n",
    "                        return null;\n",
    "                    }\n",
    "\n",
    "                    function isVisible(el) {\n",
    "                        return el.offsetParent !== null;\n",
    "                    }\n",
    "\n",
    "                    let emails = $('a[href^=\"mailto\"]').filter((i, el) => isVisible(el))\n",
    "                        .map((i, el) => $(el).attr('href').replace('mailto:', '').trim())\n",
    "                        .get();\n",
    "\n",
    "                    let phones = $('a[href^=\"tel\"]').filter((i, el) => isVisible(el))\n",
    "                        .map((i, el) => $(el).attr('href').replace(/[^0-9]/g, ''))\n",
    "                        .get();\n",
    "\n",
    "                    emails = [...new Set(emails)];\n",
    "                    phones = [...new Set(phones)];\n",
    "\n",
    "                    return {\n",
    "                        contactUrl: context.request.url,\n",
    "                        emails: emails.length ? emails : [],\n",
    "                        phones: phones.length ? phones : []\n",
    "                    };\n",
    "                }\n",
    "            \"\"\",\n",
    "            \"injectJQuery\": True,\n",
    "            \"useChrome\": True,\n",
    "            \"headless\": True,\n",
    "            \"proxyConfiguration\": {\"useApifyProxy\": True},\n",
    "        }\n",
    "\n",
    "        # --- Run the Apify scraper ---\n",
    "        try:\n",
    "            run = client.actor(\"moJRLRc85AitArpNN\").call(run_input=run_input)\n",
    "            dataset = client.dataset(run[\"defaultDatasetId\"])\n",
    "            results = list(dataset.iterate_items())\n",
    "            contact_results = [r for r in results if r and (r.get(\"emails\") or r.get(\"phones\"))]\n",
    "\n",
    "            if contact_results:\n",
    "                scraped = contact_results[0]\n",
    "                updated_df.at[i, \"Emails\"] = scraped.get(\"emails\", None)\n",
    "                updated_df.at[i, \"Phones\"] = scraped.get(\"phones\", None)\n",
    "                updated_df.at[i, \"Contact_Page\"] = scraped.get(\"contactUrl\", None)\n",
    "                print(f\"✅ Found: {scraped.get('phones', [])} / {scraped.get('emails', [])}\")\n",
    "            else:\n",
    "                print(\"⚠️ No contact data found.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error scraping {website}: {e}\")\n",
    "\n",
    "    return updated_df\n",
    "\n",
    "\n",
    "# --- Run the scraper for valid websites ---\n",
    "result_df = await enrich_with_contact_info(result_df)\n",
    "\n",
    "# --- Display updated results ---\n",
    "display(result_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad033e9f",
   "metadata": {},
   "source": [
    "### Facebook Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9c9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> Status: RUNNING, Message: \n",
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> 2025-11-04T08:10:05.959Z ACTOR: Pulling container image of build hAtXVuN3UKeSX06iI from registry.\n",
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> 2025-11-04T08:10:05.961Z ACTOR: Creating container.\n",
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> 2025-11-04T08:10:06.242Z ACTOR: Starting container.\n",
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> 2025-11-04T08:10:07.636Z \u001b[32mINFO\u001b[39m  System info\u001b[90m {\"apifyVersion\":\"3.4.3\",\"apifyClientVersion\":\"2.12.5\",\"crawleeVersion\":\"3.13.7\",\"osType\":\"Linux\",\"nodeVersion\":\"v20.19.5\"}\u001b[39m\n",
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> 2025-11-04T08:10:07.806Z \u001b[32mINFO\u001b[39m  Results Limit undefined\n",
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> 2025-11-04T08:10:07.812Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Using the old RequestQueue implementation without request locking.\n",
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> Status: RUNNING, Message: Starting the crawler.\n",
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> 2025-11-04T08:10:08.121Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Starting the crawler.\n",
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> 2025-11-04T08:10:13.157Z \u001b[32mINFO\u001b[39m  [PROGRESS]: Found 1 new page_contact_information, 1 for URL https://www.facebook.com/KPECTHub/\n",
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> 2025-11-04T08:10:13.316Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m All requests from the queue have been processed, the crawler will shut down.\n",
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> 2025-11-04T08:10:13.403Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Final request statistics:\u001b[90m {\"requestsFinished\":1,\"requestsFailed\":0,\"retryHistogram\":[1],\"requestAvgFailedDurationMillis\":null,\"requestAvgFinishedDurationMillis\":5062,\"requestsFinishedPerMinute\":11,\"requestsFailedPerMinute\":0,\"requestTotalDurationMillis\":5062,\"requestsTotal\":1,\"crawlerRuntimeMillis\":5592}\u001b[39m\n",
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> 2025-11-04T08:10:13.406Z \u001b[32mINFO\u001b[39m \u001b[33m CheerioCrawler:\u001b[39m Finished! Total 1 requests: 1 succeeded, 0 failed.\u001b[90m {\"terminal\":true}\u001b[39m\n",
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> Status: RUNNING, Message: Finished! Total 1 requests: 1 succeeded, 0 failed.\n",
      "\u001b[36m[apify.facebook-page-contact-information runId:NuFdyfMTFapYz30sz]\u001b[0m -> 2025-11-04T08:10:13.469Z \u001b[32mINFO\u001b[39m  *** DONE ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facebook_url</th>\n",
       "      <th>page_name</th>\n",
       "      <th>phone</th>\n",
       "      <th>email</th>\n",
       "      <th>website</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.facebook.com/KPECTHub/</td>\n",
       "      <td>KPECTHub</td>\n",
       "      <td>+65 9799 9960</td>\n",
       "      <td>clubxy@icloud.com</td>\n",
       "      <td>https://maps.google.com/maps?q=2+Kallang+Avenu...</td>\n",
       "      <td>2 Kallang Avenue #01-04 CT Hub S339407, Singap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         facebook_url page_name          phone  \\\n",
       "0  https://www.facebook.com/KPECTHub/  KPECTHub  +65 9799 9960   \n",
       "\n",
       "               email                                            website  \\\n",
       "0  clubxy@icloud.com  https://maps.google.com/maps?q=2+Kallang+Avenu...   \n",
       "\n",
       "                                             address  \n",
       "0  2 Kallang Avenue #01-04 CT Hub S339407, Singap...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the ApifyClient with your API token\n",
    "client = ApifyClient(\"apify_api_yNR85etaHpLtBzPoVozVVXUsCZe54u2Ffog1\")\n",
    "\n",
    "# Function to validate Singapore phone numbers (MUST have country code)\n",
    "def validate_singapore_number(phone):\n",
    "    if not phone:\n",
    "        return None\n",
    "    \n",
    "    # Remove all spaces, dashes, parentheses\n",
    "    cleaned = re.sub(r'[\\s\\-\\(\\)]', '', str(phone))\n",
    "    \n",
    "    # MUST have country code: +65XXXXXXXX or 65XXXXXXXX\n",
    "    # First digit after country code must be 6, 8, or 9\n",
    "    # Total of 8 digits after country code\n",
    "    if re.match(r'^\\+?65[689]\\d{7}$', cleaned):\n",
    "        return phone  # Return original format\n",
    "    \n",
    "    # Not a valid Singapore number with country code\n",
    "    return None\n",
    "\n",
    "# Prepare the Actor input\n",
    "run_input = {\n",
    "    \"pages\": [\n",
    "        \"https://www.facebook.com/KPECTHub/\",\n",
    "    ],\n",
    "    \"language\": \"en-US\",\n",
    "}\n",
    "\n",
    "# Run the Actor and wait for it to finish\n",
    "run = client.actor(\"oJ48ceKNY7ueGPGL0\").call(run_input=run_input)\n",
    "\n",
    "# Collect results\n",
    "results = []\n",
    "for item in client.dataset(run[\"defaultDatasetId\"]).iterate_items():\n",
    "    # Extract phone from multiple possible fields\n",
    "    raw_phone = item.get('phone', None) or item.get('wa_number', None)\n",
    "    \n",
    "    # Validate it's a Singapore number WITH country code\n",
    "    phone = validate_singapore_number(raw_phone)\n",
    "    \n",
    "    # Extract email\n",
    "    email = item.get('email', None)\n",
    "    \n",
    "    # Extract website from the websites list (take first non-Google Maps link if available)\n",
    "    websites = item.get('websites', [])\n",
    "    website = None\n",
    "    if websites:\n",
    "        # Filter out Google Maps links and take the first real website\n",
    "        real_websites = [w for w in websites if 'maps.google.com' not in w]\n",
    "        website = real_websites[0] if real_websites else websites[0]\n",
    "    \n",
    "    results.append({\n",
    "        'facebook_url': item.get('facebookUrl', None),\n",
    "        'page_name': item.get('pageName', None),\n",
    "        'phone': phone,  # Only Singapore numbers WITH country code or None\n",
    "        'email': email,\n",
    "        'website': website,\n",
    "        'address': item.get('address', None)\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
